{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 📄 PDF 문서 변환 및 처리 초기화\n",
    "\n",
    "이 노트북은 arXiv 논문에서 QA(질문-답변) 시스템을 구축하는 과정을 보여줍니다. 먼저 PDF 문서를 마크다운 형태로 변환하고 이미지를 추출하여 처리하는 작업부터 시작합니다.\n",
    "\n",
    "#### 🔧 Docling 라이브러리를 사용한 PDF 변환\n",
    "\n",
    "표준 모델에서 뮤온의 이상 자기 모멘트에 관한 물리학 논문을 대상으로, 고품질 이미지 추출과 수식 인식이 가능한 고급 PDF 파이프라인을 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash 30758e3e50e33b1c127abb388dad2ec7\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered picture descriptions: ['vlm', 'api']\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document The anomalous magnetic moment of the muon in the Standard Model.pdf\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py:262: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(\n",
      "INFO:docling.document_converter:Finished converting document The anomalous magnetic moment of the muon in the Standard Model.pdf in 954.05 sec.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "# 로깅 설정 - INFO 레벨로 변환 과정을 모니터링\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "# 입력 PDF 파일 경로와 출력 디렉토리 설정\n",
    "input_doc_path = Path(\"data/The anomalous magnetic moment of the muon in the Standard Model.pdf\")\n",
    "output_dir = Path(\"standard_model\")\n",
    "\n",
    "# PDF 파이프라인 옵션 구성\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.images_scale = 2.0  # 이미지 해상도 스케일 설정\n",
    "pipeline_options.generate_picture_images = True         # 그림 이미지 생성 활성화\n",
    "pipeline_options.do_formula_enrichment = True\n",
    "pipeline_options.do_picture_classification = True\n",
    "\n",
    "# 문서 변환기 초기화 - PDF 형식 옵션과 함께 설정\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 변환 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "# PDF 문서 변환 실행\n",
    "conv_res = doc_converter.convert(input_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 🔍 문서 구조 분석\n",
    "\n",
    "변환된 문서에서 어떤 유형의 요소들이 발견되는지 확인합니다. 이를 통해 텍스트, 이미지, 표, 수식 등의 분포를 파악할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서에서 발견된 고유한 element 타입들:\n",
      "- FormulaItem\n",
      "- ListItem\n",
      "- PictureItem\n",
      "- SectionHeaderItem\n",
      "- TableItem\n",
      "- TextItem\n"
     ]
    }
   ],
   "source": [
    "# 문서에서 발견되는 고유한 element 타입들을 확인\n",
    "element_types = set()\n",
    "for element, _level in conv_res.document.iterate_items():\n",
    "    element_types.add(type(element).__name__)\n",
    "\n",
    "print(\"문서에서 발견된 고유한 element 타입들:\")\n",
    "for element_type in sorted(element_types):\n",
    "    print(f\"- {element_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 💾 마크다운 파일 저장 및 완료\n",
    "\n",
    "변환된 문서를 이미지 참조가 포함된 마크다운 형식으로 저장합니다. 이미지들은 별도 디렉토리에 저장되며, 마크다운에서는 상대 경로로 참조됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Document converted and figures exported in 1107.61 seconds.\n"
     ]
    }
   ],
   "source": [
    "doc_filename = \"physics_muon_paper\"\n",
    "\n",
    "# 출력 디렉토리가 존재하지 않으면 생성\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 이미지 참조가 포함된 마크다운 파일 저장 \n",
    "md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "# 변환 완료 시간 계산\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "# 변환 완료 로그 출력\n",
    "_log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 🖼️ 이미지 캡션 생성 및 VLM 활용\n",
    "\n",
    "논문의 이미지들을 텍스트로 변환하기 위해 Vision Language Model(VLM)을 사용합니다. \n",
    "\n",
    "#### 🧪 개별 이미지 테스트\n",
    "\n",
    "Gemini 2.5 Flash 모델을 사용하여 단일 이미지에 대한 캡션 생성을 테스트해봅니다. 이미지를 base64로 인코딩하여 API에 전송합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for local image: 이 이미지는 두 개의 나란히 배치된 그래프로, η (에타) 및 η' (에타 프라임) 중간자의 Q² 의존적인 전이 형태 인자(form factor)를 보여줍니다. 두 그래프 모두 가로축은 Q² (운동량 전달 제곱)를 GeV² 단위로, 세로축은 형태 인자 값을 GeV 단위로 표시합니다. 그래프는 여러 이론적 계산 결과(\"This work\", \"DSE\", \"CA\")와 실험 데이터(\"CLEO\", \"CELLO\", \"L3\")를 비교합니다.\n",
      "\n",
      "**왼쪽 그래프: Q² Fηγ*γ*(-Q², 0)**\n",
      "*   **제목:** η 중간자의 전이 형태 인자 Q² Fηγ*γ*(-Q², 0)를 나타냅니다.\n",
      "*   **축 범위:** 가로축 Q²는 0에서 2 GeV²까지, 세로축은 0에서 0.2 GeV까지 범위입니다.\n",
      "*   **범례:**\n",
      "    *   **This work:** 연한 파란색 음영 영역과 그 중앙의 파란색 실선으로 표시된 현재 연구의 이론적 예측입니다.\n",
      "    *   **CLEO:** 녹색 원형 점으로 표시된 실험 데이터입니다.\n",
      "    *   **CELLO:** 파란색 사각형 점으로 표시된 실험 데이터입니다.\n",
      "    *   **DSE:** 녹색 음영 영역으로 표시된 이론적 모델(Dyson-Schwinger Equations)입니다.\n",
      "    *   **CA:** 주황색 음영 영역으로 표시된 이론적 모델(Chiral Anomaly)입니다.\n",
      "*   **데이터 경향:**\n",
      "    *   모든 곡선과 데이터는 Q²가 증가함에 따라 0에서 시작하여 점진적으로 증가하는 경향을 보입니다.\n",
      "    *   \"This work\"의 파란색 예측 밴드는 \"CELLO\" 실험 데이터 포인트와 잘 일치하는 것으로 보입니다.\n",
      "    *   \"CLEO\" 실험 데이터 포인트는 \"DSE\" 및 \"CA\" 이론적 예측 밴드와 더 가깝게 위치합니다.\n",
      "    *   이론적 예측의 음영 영역은 불확실성을 나타내며, Q²가 커질수록 이 불확실성 영역도 넓어집니다.\n",
      "    *   모든 실험 데이터 포인트에는 가로 및 세로 오차 막대가 표시되어 측정 불확실성을 나타냅니다.\n",
      "\n",
      "**오른쪽 그래프: Q² Fη'γ*γ*(-Q², 0)**\n",
      "*   **제목:** η' 중간자의 전이 형태 인자 Q² Fη'γ*γ*(-Q², 0)를 나타냅니다.\n",
      "*   **축 범위:** 가로축 Q² 범위는 왼쪽과 동일하며, 세로축은 0에서 0.25 GeV까지 확장되어 있습니다.\n",
      "*   **범례:** 왼쪽 그래프의 범례에 더해 \"L3\"(빨간색 삼각형 점) 실험 데이터가 추가되었습니다. 나머지 범례 항목은 동일합니다.\n",
      "*   **데이터 경향:**\n",
      "    *   이 그래프 역시 Q²가 증가함에 따라 형태 인자가 증가하는 경향을 보입니다.\n",
      "    *   \"This work\"의 파란색 예측 밴드는 \"CELLO\" 실험 데이터와 저 Q² 영역의 \"L3\" 실험 데이터와 잘 부합하는 것으로 나타납니다.\n",
      "    *   \"L3\" 데이터는 특히 Q²가 낮은 영역(0.2 GeV² 미만)에서 \"This work\", \"DSE\", \"CA\" 예측과 일치합니다.\n",
      "    *   \"CLEO\" 실험 데이터는 높은 Q²에서 \"This work\" 곡선의 상단 또는 그보다 약간 높은 위치에 있으며, \"DSE\" 및 \"CA\" 예측보다 높게 나타납니다.\n",
      "    *   모든 실험 데이터에는 오차 막대가 표시되어 측정 불확실성을 나타냅니다.\n",
      "\n",
      "**전반적인 요약:**\n",
      "두 그래프 모두 \"This work\"의 이론적 계산이 η 및 η' 중간자의 Q² 의존적인 전이 형태 인자에 대한 다양한 실험 데이터를 비교적 잘 설명하고 있음을 보여줍니다. 동시에 \"DSE\" 및 \"CA\"와 같은 다른 이론적 모델과의 비교 및 다양한 실험 데이터(CLEO, CELLO, L3)의 차이를 시각적으로 나타냅니다.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "# 로컬 이미지 파일 경로\n",
    "image_path = \"standard_model\\physics_muon_paper-with-image-refs_artifacts\\image_000113_5d0f0f98dd32385cc160b1f470c6fe41e41cd81e6795a6af111ac6f2d451f1a0.png\"\n",
    "\n",
    "# 로컬 이미지 파일을 base64로 인코딩\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "message_local = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"이 이미지를 텍스트로 대체하고자 합니다. 해당 이미지에 대한 설명을 한글로 생성해주세요.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{encoded_image}\"},\n",
    "    ]\n",
    ")\n",
    "result_local = llm.invoke([message_local])\n",
    "print(f\"Response for local image: {result_local.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ⚡ 배치 처리를 통한 대량 이미지 캡션 생성\n",
    "\n",
    "논문에 포함된 모든 이미지(124개)에 대해 자동으로 캡션을 생성하는 고급 시스템입니다.\n",
    "\n",
    "주요 기능:\n",
    "- 이미지 주변 텍스트 컨텍스트 추출 및 활용\n",
    "- Rate limit을 준수하는 배치 처리\n",
    "- 실패한 이미지에 대한 개별 재처리\n",
    "- 생성된 캡션으로 이미지 참조 자동 대체\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마크다운 파일에서 이미지 참조를 찾아서 VLM으로 캡션 생성 후 대체하는 코드\n",
    "\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "def extract_surrounding_context(content, image_ref, context_lines=3):\n",
    "    \"\"\"\n",
    "    이미지 참조 주변의 텍스트 컨텍스트를 추출\n",
    "    \"\"\"\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    # 이미지 참조가 있는 라인 찾기\n",
    "    image_line_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_ref in line:\n",
    "            image_line_idx = i\n",
    "            break\n",
    "    \n",
    "    if image_line_idx is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # 앞뒤 context_lines만큼의 라인 추출\n",
    "    start_idx = max(0, image_line_idx - context_lines)\n",
    "    end_idx = min(len(lines), image_line_idx + context_lines + 1)\n",
    "    \n",
    "    context_lines_list = lines[start_idx:end_idx]\n",
    "    \n",
    "    # 이미지 참조 라인 제외하고 컨텍스트만 추출\n",
    "    context_lines_list = [line for line in context_lines_list if image_ref not in line]\n",
    "    \n",
    "    # 빈 라인과 마크다운 헤더 등 정리\n",
    "    context_text = '\\n'.join(context_lines_list).strip()\n",
    "    \n",
    "    return context_text\n",
    "\n",
    "def create_caption_message(image_path: Path, context: str) -> HumanMessage:\n",
    "    \"\"\"\n",
    "    VLM 캡션 생성을 위한 메시지 생성\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 이미지를 base64로 인코딩\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "        # 컨텍스트를 포함한 프롬프트 생성\n",
    "        prompt = f\"\"\"다음은 학술 논문의 일부입니다. 이미지 주변의 텍스트 컨텍스트를 참고하여 이미지를 설명해주세요.\n",
    "\n",
    "주변 텍스트:\n",
    "{context}\n",
    "\n",
    "위 텍스트와 관련된 이미지를 보고 적절한 캡션을 한글로 생성해주세요. \n",
    "캡션은 간결하고 정확하며, 주변 텍스트의 맥락에 맞게 작성해주세요.\"\"\"\n",
    "\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{encoded_image}\"},\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return message\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"메시지 생성 중 오류 발생: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_images_with_lcel_batch(image_data_list: List[Tuple[str, str, Path, str]], batch_size: int = 5):\n",
    "    \"\"\"\n",
    "    LCEL batch를 사용하여 이미지들을 배치로 처리\n",
    "    Gemini 2.5 Flash Preview 05-20: 10 RPM, 250,000 TPM, 500 RPD\n",
    "    \"\"\"\n",
    "    captions = {}\n",
    "    total_batches = (len(image_data_list) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"총 {len(image_data_list)}개 이미지를 {total_batches}개 배치로 처리합니다.\")\n",
    "    \n",
    "    for batch_idx in range(0, len(image_data_list), batch_size):\n",
    "        batch = image_data_list[batch_idx:batch_idx + batch_size]\n",
    "        batch_num = batch_idx // batch_size + 1\n",
    "        \n",
    "        print(f\"배치 {batch_num}/{total_batches} 처리 중... ({len(batch)}개 이미지)\")\n",
    "        \n",
    "        # 배치용 메시지 리스트 생성\n",
    "        batch_messages = []\n",
    "        batch_refs = []\n",
    "        \n",
    "        for alt_text, image_path, full_image_path, context in batch:\n",
    "            print(f\"  - 메시지 준비 중: {image_path}\")\n",
    "            message = create_caption_message(full_image_path, context)\n",
    "            if message:\n",
    "                batch_messages.append([message])  # LCEL batch는 각 입력이 리스트여야 함\n",
    "                batch_refs.append(f\"![{alt_text}]({image_path})\")\n",
    "            else:\n",
    "                print(f\"  - 메시지 생성 실패: {image_path}\")\n",
    "                batch_refs.append(f\"![{alt_text}]({image_path})\")\n",
    "                captions[f\"![{alt_text}]({image_path})\"] = f\"[이미지 캡션 생성 실패: {image_path}]\"\n",
    "        \n",
    "        # LCEL batch 처리\n",
    "        if batch_messages:\n",
    "            try:\n",
    "                print(f\"  - LCEL batch 실행 중... ({len(batch_messages)}개 메시지)\")\n",
    "                batch_results = llm.batch(batch_messages)\n",
    "                \n",
    "                # 결과 처리\n",
    "                for i, result in enumerate(batch_results):\n",
    "                    if i < len(batch_refs):\n",
    "                        caption = result.content.strip() if hasattr(result, 'content') else str(result).strip()\n",
    "                        captions[batch_refs[i]] = caption\n",
    "                        print(f\"  - 캡션 생성 완료: {batch_refs[i][:50]}...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  - 배치 처리 중 오류 발생: {e}\")\n",
    "                # 오류 발생 시 개별 처리로 폴백\n",
    "                for i, message_list in enumerate(batch_messages):\n",
    "                    try:\n",
    "                        result = llm.invoke(message_list)\n",
    "                        caption = result.content.strip()\n",
    "                        captions[batch_refs[i]] = caption\n",
    "                        print(f\"  - 개별 처리 완료: {batch_refs[i][:50]}...\")\n",
    "                        time.sleep(6.5)  # Rate limit 준수\n",
    "                    except Exception as individual_error:\n",
    "                        print(f\"  - 개별 처리 실패: {individual_error}\")\n",
    "                        captions[batch_refs[i]] = f\"[이미지 캡션 생성 실패]\"\n",
    "        \n",
    "        # 배치 간 Rate limit 준수를 위한 대기\n",
    "        # RPM 10 제한: 배치 크기가 5라면 30초 대기 (6초 * 5)\n",
    "        if batch_num < total_batches:\n",
    "            wait_time = batch_size * 6.5\n",
    "            print(f\"배치 {batch_num} 완료. Rate limit 준수를 위해 {wait_time}초 대기...\")\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    return captions\n",
    "\n",
    "def replace_image_refs_with_captions(md_file_path, output_dir, doc_filename):\n",
    "    \"\"\"\n",
    "    마크다운 파일의 이미지 참조를 VLM 생성 캡션으로 대체하여 새로운 파일로 저장\n",
    "    \"\"\"\n",
    "    # 마크다운 파일 읽기\n",
    "    with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # 이미지 참조 패턴 찾기 (![alt_text](image_path) 형식)\n",
    "    image_pattern = r'!\\[([^\\]]*)\\]\\(([^)]+)\\)'\n",
    "    matches = re.findall(image_pattern, content)\n",
    "    \n",
    "    print(f\"발견된 이미지 참조 개수: {len(matches)}\")\n",
    "    \n",
    "    # 처리할 이미지 데이터 준비\n",
    "    image_data_list = []\n",
    "    \n",
    "    for alt_text, image_path in matches:\n",
    "        # 상대 경로를 절대 경로로 변환\n",
    "        if not Path(image_path).is_absolute():\n",
    "            full_image_path = output_dir / image_path\n",
    "        else:\n",
    "            full_image_path = Path(image_path)\n",
    "        \n",
    "        if full_image_path.exists():\n",
    "            # 이미지 참조 주변의 컨텍스트 추출\n",
    "            image_ref = f\"![{alt_text}]({image_path})\"\n",
    "            surrounding_context = extract_surrounding_context(content, image_ref, context_lines=3)\n",
    "            \n",
    "            image_data_list.append((alt_text, image_path, full_image_path, surrounding_context))\n",
    "            print(f\"이미지 추가: {image_path}\")\n",
    "            print(f\"컨텍스트: {surrounding_context[:100]}{'...' if len(surrounding_context) > 100 else ''}\\n\")\n",
    "        else:\n",
    "            print(f\"이미지 파일을 찾을 수 없음: {full_image_path}\")\n",
    "    \n",
    "    if not image_data_list:\n",
    "        print(\"처리할 이미지가 없습니다.\")\n",
    "        return md_file_path\n",
    "    \n",
    "    # LCEL batch 처리로 캡션 생성\n",
    "    print(\"LCEL batch를 사용한 캡션 생성을 시작합니다...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    captions = process_images_with_lcel_batch(image_data_list, batch_size=5)\n",
    "    \n",
    "    # 이미지 참조를 캡션으로 대체\n",
    "    for image_ref, caption in captions.items():\n",
    "        content = content.replace(image_ref, f\"[이미지 캡션: {caption}]\")\n",
    "        print(f\"대체 완료: {image_ref[:50]}... -> {caption[:50]}...\")\n",
    "    \n",
    "    # 캡션이 적용된 새로운 마크다운 파일 저장\n",
    "    captioned_md_filename = output_dir / f\"{doc_filename}-with-captions.md\"\n",
    "    with open(captioned_md_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"캡션 생성 완료! 총 소요 시간: {end_time:.2f}초\")\n",
    "    print(f\"총 {len(captions)}개 이미지 캡션 생성됨\")\n",
    "    print(f\"캡션이 적용된 새로운 파일 저장: {captioned_md_filename}\")\n",
    "    \n",
    "    return captioned_md_filename\n",
    "\n",
    "# 이미지 참조를 캡션으로 대체하여 새로운 파일로 저장\n",
    "captioned_file = replace_image_refs_with_captions(md_filename, output_dir, doc_filename)\n",
    "# End of Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 📚 문서 분할 및 임베딩 준비\n",
    "\n",
    "#### ✂️ 텍스트 청킹\n",
    "\n",
    "캡션이 생성된 마크다운 문서를 RAG 시스템에 적합한 크기의 청크로 분할합니다. RecursiveCharacterTextSplitter를 사용하여 의미 있는 구조를 유지하면서 분할합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"##\\n\",\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# 캡션이 적용된 파일 내용 읽기\n",
    "with open(captioned_file, 'r', encoding='utf-8') as f:\n",
    "    captioned_content = f.read()\n",
    "\n",
    "# Document 객체로 생성\n",
    "document = Document(page_content=captioned_content, metadata={\"source\": str(captioned_file)})\n",
    "\n",
    "# split_documents를 사용하여 Document 객체들로 분할\n",
    "splits = text_splitter.split_documents([document])\n",
    "\n",
    "# splits 길이 분포 파악\n",
    "split_lengths = [len(split.page_content) for split in splits]\n",
    "print(f\"총 분할된 청크 수: {len(splits)}\")\n",
    "print(f\"평균 청크 길이: {sum(split_lengths) / len(split_lengths):.1f} 문자\")\n",
    "print(f\"최소 청크 길이: {min(split_lengths)} 문자\")\n",
    "print(f\"최대 청크 길이: {max(split_lengths)} 문자\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 👀 분할 결과 확인\n",
    "\n",
    "분할된 첫 번째 청크의 내용을 확인하여 청킹이 올바르게 수행되었는지 검토합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 🗄️ 벡터 데이터베이스 설정 및 하이브리드 검색\n",
    "\n",
    "#### 💾 Qdrant 벡터 스토어 구축\n",
    "\n",
    "Dense embedding과 Sparse embedding을 결합한 하이브리드 검색 시스템을 구축합니다:\n",
    "- **Dense embedding**: BGE-M3 모델을 사용한 의미적 유사도 검색\n",
    "- **Sparse embedding**: BM25 기반 키워드 검색\n",
    "- **하이브리드 검색**: 두 방식을 결합하여 더 정확한 검색 성능 확보\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/arxiv_physics_muon_paper \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/arxiv_physics_muon_paper \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "새 컬렉션 'arxiv_physics_muon_paper' 생성됨\n",
      "문서를 벡터 스토어에 추가 중...\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import Distance, SparseVectorParams, VectorParams\n",
    "\n",
    "# Qdrant 클라이언트 설정\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "dense_embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# 컬렉션 이름 설정\n",
    "collection_name = f\"arxiv_{doc_filename}\"\n",
    "# try:\n",
    "    # client.create_collection(\n",
    "    #     collection_name=collection_name,\n",
    "    #     vectors_config={\"dense\": VectorParams(size=1024, distance=Distance.COSINE)},\n",
    "    #     sparse_vectors_config={\n",
    "    #         \"sparse\": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))\n",
    "    #     },\n",
    "    # )\n",
    "# print(f\"새 컬렉션 '{collection_name}' 생성됨\")\n",
    "    # 문서를 벡터 스토어에 추가\n",
    "# print(\"문서를 벡터 스토어에 추가 중...\")\n",
    "qdrant = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=dense_embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    vector_name=\"dense\",\n",
    "    sparse_vector_name=\"sparse\",\n",
    ")\n",
    "    # qdrant.add_documents(splits)\n",
    "    # print(f\"✅ {len(splits)}개의 문서가 Qdrant에 저장되었습니다.\")\n",
    "\n",
    "# except:\n",
    "#     qdrant = QdrantVectorStore(\n",
    "#         client=client,\n",
    "#         collection_name=collection_name,\n",
    "#         embedding=dense_embeddings,\n",
    "#         sparse_embedding=sparse_embeddings,\n",
    "#         retrieval_mode=RetrievalMode.HYBRID,\n",
    "#         vector_name=\"dense\",\n",
    "#         sparse_vector_name=\"sparse\",\n",
    "#     )\n",
    "#     print(f\"✅ {len(splits)}개의 문서가 Qdrant에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 🔍 리트리버 초기화\n",
    "\n",
    "벡터 스토어를 기반으로 한 리트리버를 설정합니다. 상위 10개 문서를 검색하도록 구성합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = qdrant.as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 🎨 검색 결과 출력 함수\n",
    "\n",
    "검색된 문서들을 깔끔하게 포맷팅하여 출력하는 유틸리티 함수입니다. 문서의 메타데이터와 내용을 구조화된 형태로 보여줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search_results(docs, title):\n",
    "    \"\"\"검색 결과를 이쁘게 출력하는 함수\"\"\"\n",
    "    print(f\"{title}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"검색된 문서 수: {len(docs)}개\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"📄 문서 {i}\")\n",
    "        print(f\"📂 출처: {doc.metadata.get('source', 'N/A')}\")\n",
    "        print(f\"📃 페이지: {doc.metadata.get(' page', 'N/A')}\")\n",
    "        print(f\"📝 내용 미리보기:\")\n",
    "        print(doc.page_content)\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 🧪 기본 검색 테스트\n",
    "\n",
    "HLbL(Hadronic Light-by-Light) 불확실성에 관한 질문으로 검색 시스템을 테스트합니다. 이는 뮤온 g-2 실험의 핵심 주제 중 하나입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/arxiv_physics_muon_paper/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 기본 Retriever 검색 결과:\n",
      "================================================================================\n",
      "검색된 문서 수: 10개\n",
      "\n",
      "📄 문서 1\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "Table 33: Comparison of the key results from this work (WP25), as given in Table 1, to the corresponding numbers from WP20 [1] (in units of 10 -11 ). Note that the 'HLbL (lattice)' result from WP20 has been adapted to include the charm-loop contribution. The entry 'HVP (LO + NLO + NNLO)' derives from HVP LO (lattice) [WP25] and HVP LO ( e + e -) [WP20], respectively. The asterisk indicates that the LO HVP value from WP20 was based on e + e -data only, while in Table 5 we also include the current status for τ -based evaluations.\n",
      "\n",
      "## 9. Conclusions and outlook\n",
      "\n",
      "In this second edition of the White Paper on the muon g -2, we have charted the progress that has been achieved since 2020 in evaluating the contributions from the electromagnetic (QED), electroweak (EW), and strong (QCD) interactions to a µ .\n",
      "----------------------------------------\n",
      "📄 문서 2\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "In recent years, the theoretical and experimental work aimed at reducing the uncertainties of the SM prediction has been particularly intense and relied on higher-order calculations, dispersive methods, lattice QCD, e ff ective field theories, as well as new data inputs from experiments. For HLbL these e ff orts have indeed been successful and the change from WP20 to the present review is that the uncertainty has been reduced by about a factor of two. Concerning HVP the situation is more complicated as reflected by the fact that the present review does not present a number for a data-driven estimate of this contribution, since not yet understood discrepancies among di ff erent experiments have emerged. On the other hand, there has been significant progress in lattice-QCD calculations of this quantity, and the consensus number for the HVP contribution presented in this review is based on them. The change from a data-driven to a lattice estimate of this contribution also means that the\n",
      "----------------------------------------\n",
      "📄 문서 3\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "$$a _ { \\mu } ^ { \\text{HLbL} } = a _ { \\mu } ^ { \\text{HLbL,c} } + a _ { \\mu } ^ { \\text{HLbL,s} } + a _ { \\mu } ^ { \\text{HLbL,c} } + a _ { \\mu } ^ { \\text{HLbL,rest} } \\,,$$\n",
      "\n",
      "where\n",
      "----------------------------------------\n",
      "📄 문서 4\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "For the hadronic light-by-light (HLbL) contribution, significant progress since WP20 has been made in both the dispersive method and lattice QCD. On the data-driven side, improved calculations of short-distance constraints and a number of subleading contributions have become available, leading to a reduction of the uncertainty by about a factor of two compared to WP20. At the same time, new lattice-QCD calculations have reached a similar level of precision. The two averages, from phenomenology and lattice QCD, are combined into a final average with a precision below 10%.\n",
      "\n",
      "Table 1 gives a summary of the contributions to the SM prediction, along with the locations in this White Paper (WP25) where the results are discussed.\n",
      "\n",
      "## 1. Introduction\n",
      "----------------------------------------\n",
      "📄 문서 5\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "$$a _ { \\mu } ^ { \\text{HVP}, \\text{LO} } ( \\text{WP} 2 0 ) = 7 1 1. 6 ( 1 8. 4 ) \\times 1 0 ^ { - 1 0 } \\,,$$\n",
      "\n",
      "with an uncertainty of 2.6%. As a consequence, the lattice world average was consistent with both the dispersive data-driven estimate and the 'no new physics' scenario. The uncertainty was a factor of 4.5 larger than that of the data-driven estimate, and the lattice average was not included in the final SM value for a HVP, LO µ . We also note that the BMW-20 [15] lattice calculation, which reported a precision of 0.8%, was posted on arXiv after the WP20 deadline and published in April 2021. Consequently, it was not included in the WP20 lattice world average of Eq. (3.7).\n",
      "----------------------------------------\n",
      "📄 문서 6\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "| 6   | Lattice approaches to HLbL                                               | Lattice approaches to HLbL                                                      | 140     |\n",
      "| 6.1 | Introduction . . . . .                                                   | . . . . . . . . . . . . . . . . . . . . .                                       | 140     |\n",
      "| 6.2 | Direct                                                                   | lattice calculations of the hadronic light-by-light contribution                | 140     |\n",
      "|     | 6.2.1                                                                    | a HLbL ,ℓ µ : the Mainz / CLS calculation . . . . . . . . . HLbL                | 142     |\n",
      "|     | 6.2.2 6.2.3                                                              | a ,ℓ µ : the RBC / UKQCD calculation . . . . . . . HLbL . . . . . . . . . . . . | 144 148 |\n",
      "----------------------------------------\n",
      "📄 문서 7\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "Table 32: Current lattice results for the direct calculation of a HLbL , where statistical and systematic errors have been added in quadrature.\n",
      "\n",
      "| Contribution                                                    | Average [10 - 11 ]                                                                                                       | Sources                                                                                 |\n",
      "|-----------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|\n",
      "| a HLbL ,ℓ µ a HLbL , s µ a HLbL , c µ a HLbL , 3 + 1 µ a HLbL µ | 119 . 6(7 . 1) stat (5 . 5) syst [9 . 0] tot - 1 . 4(8) 3 . 5(5) 0 . 82(25) 122 . 5(7 . 1) stat (5 . 6) syst [9 . 0] tot | Eq. (6.24), Table 31 Eqs. (6.27) and (6.28) Eqs. (6.29) to (6.31) Eq. (6.32) Eq. (6.34) |\n",
      "\n",
      "µ\n",
      "----------------------------------------\n",
      "📄 문서 8\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "$$a _ { \\mu } ^ { \\text{charm} \\cdot } = 3 ( 1 ) \\times 1 0 ^ { - 1 1 } \\,.$$\n",
      "\n",
      "Adding all the errors quadratically and the contributions gives a total (LO) HLbL contribution of\n",
      "\n",
      "$$a _ { \\mu } ^ { H L b L } = 1 0 3. 3 ( 8. 8 ) \\times 1 0 ^ { - 1 1 }.$$\n",
      "\n",
      "This should be compared with the WP20 result of 92(19) × 10 -11 . Our new number is perfectly compatible with the previous number within errors and has a significantly improved precision due to improvements of many hadronic contributions as well as improvements in short-distance calculations and matching.\n",
      "\n",
      "Finally, there is the estimate of the NLO HLbL contribution from Ref. [57], which we update along the lines of Ref. [1]:\n",
      "\n",
      "$$a _ { \\mu } ^ { H L b L, N L O } = 2. 6 ( 6 ) \\times 1 0 ^ { - 1 1 } \\,.$$\n",
      "\n",
      "## 5.11. Prospects for future improvements\n",
      "\n",
      "## 5.11.1. Theory\n",
      "----------------------------------------\n",
      "📄 문서 9\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "The flavor structure of i b Π plays an important role. In terms of the isospin decomposition j µ = j 3 µ + j 8 µ / 3 of the EMcurrent in the ( u d , , s ) sector, i b Π can be decomposed into three terms, involving either zero, two, or four isovector currents j 3 µ , which lead respectively to the contributions a HLbL { j 8 } µ , a HLbL { j 3 , j 8 } µ , and a HLbL { j 3 } µ . On the other hand, for a given quark current there are five classes of Wick contractions, the connected (4) as well as the (2 + 2), the (3 + 1), the (2 + + 1 1), and the (1 + + + 1 1 1) disconnected diagrams. For instance, we denote the (2 + 2) contribution to a HLbL µ from the u d , quarks a HLbL (2 , ℓ + 2 ) ℓ µ . In particular, the contribution involving four isovector currents j 3 µ corresponds to a linear combination of the two leading quark-level contractions, a HLbL (4) , ℓ µ and a HLbL (2 , + 2) ℓ µ . We write\n",
      "----------------------------------------\n",
      "📄 문서 10\n",
      "📂 출처: standard_model\\physics_muon_paper-with-captions.md\n",
      "📃 페이지: N/A\n",
      "📝 내용 미리보기:\n",
      "2020 (WP20) [1]. Since then, new measurements have been announced by the Fermilab g -2 experiment, the first result in 2021 [6] with a precision of 460 ppb, and the second result in 2023 [7] with 200 ppb. These new measurements are consistent with, but more precise than, the ones of the BNL experiment, and provide the basis of the current world average. The agreement of the two most precise experiments lends a high degree of reliability to this world average. At present, the Fermilab E989 experiment is preparing to announce its final results with the full set of all experimental data collected. Another experiment with a largely di ff erent experimental method is currently under preparation at J-PARC [8], allowing an independent cross-check of these results.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 검색 쿼리\n",
    "query = \"HLbL 불확실성이 2020 WP 대비 얼마나 줄었는가?\"\n",
    "\n",
    "# 기본 retriever 검색\n",
    "basic_docs = retriever.invoke(query)\n",
    "print_search_results(basic_docs, \"🔍 기본 Retriever 검색 결과:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 🤖 LangGraph를 활용한 RAG 시스템 구축\n",
    "\n",
    "#### ⚙️ RAG 워크플로우 설정\n",
    "\n",
    "LangGraph를 사용하여 체계적인 RAG(Retrieval-Augmented Generation) 파이프라인을 구축합니다:\n",
    "\n",
    "1. **State 정의**: 질문, 검색된 문서, 생성된 답변을 관리\n",
    "2. **LLM 설정**: Gemma3 4B 모델을 사용한 답변 생성\n",
    "3. **프롬프트 템플릿**: 한국어 답변을 위한 최적화된 프롬프트\n",
    "4. **워크플로우 노드**: 문서 검색과 답변 생성의 단계별 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# State 정의\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:4b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# RAG 프롬프트 템플릿\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "다음 문서들을 참고하여 질문에 답변해주세요.\n",
    "\n",
    "문서들:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변은 한국어로 작성하고, 문서의 내용을 바탕으로 정확하고 자세하게 답변해주세요.\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "def retrieve_documents(state: RAGState) -> RAGState:\n",
    "    \"\"\"문서 검색 단계\"\"\"\n",
    "    print(\"📚 문서 검색 중...\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    print(f\"✅ {len(documents)}개의 문서를 검색했습니다.\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "\n",
    "def generate_answer(state: RAGState) -> RAGState:\n",
    "    \"\"\"답변 생성 단계\"\"\"\n",
    "    print(\"🤖 답변 생성 중...\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # 문서 내용을 컨텍스트로 결합\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    # LLM 체인 구성\n",
    "    chain = rag_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # 답변 생성\n",
    "    answer = chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    print(\"✅ 답변이 생성되었습니다.\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "# LangGraph 워크플로우 구성\n",
    "workflow = StateGraph(RAGState)\n",
    "\n",
    "# 노드 추가\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# 엣지 추가\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# 그래프 컴파일\n",
    "rag_app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### 🚀 완전한 RAG 시스템 실행\n",
    "\n",
    "구축된 RAG 시스템을 사용하여 실제 질문에 대한 답변을 생성합니다. \n",
    "- 문서 검색과 답변 생성 과정을 실시간으로 모니터링\n",
    "- 스트리밍 모드로 답변 생성 과정을 단계별로 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/arxiv_physics_muon_paper/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 문서 검색 중...\n",
      "✅ 10개의 문서를 검색했습니다.\n",
      "🤖 답변 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서에 따르면, HLbL의 불확실성이 2020 WP(WP20) 대비 약 두 배 감소했습니다. 2020 WP20의 결과는 92(19) × 10 -11 였지만, 새로운 측정 결과들이 발표되면서 현재의 세계 평균값은 이보다 훨씬 더 정밀해졌습니다. 특히, 2021년에 발표된 Fermilab g-2 실험 결과(460 ppb)와 2023년에 발표된 결과(200 ppb)는 이전 결과보다 훨씬 더 높은 정밀도를 제공하며, 이로 인해 HLbL의 불확실성이 크게 개선되었습니다. 또한, J-PARC 실험도 준비 중이며, 이 실험 결과 또한 최종적으로 세계 평균값의 신뢰도를 높일 것으로 기대됩니다.\n",
      "✅ 답변이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "question = \"HLbL 불확실성이 2020 WP 대비 얼마나 줄었는가?\"\n",
    "initial_state = {\"question\": question, \"documents\": [], \"answer\": \"\"}\n",
    "result=[]\n",
    "for chunk, metadata in rag_app.stream(initial_state, stream_mode=\"messages\"):\n",
    "    if chunk.content:\n",
    "        result.append(chunk)\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### 🎯 RAG 시스템 완성\n",
    "\n",
    "이 노트북을 통해 다음과 같은 완전한 RAG 시스템을 구축했습니다:\n",
    "\n",
    "1. **📄 PDF 처리**: Docling을 통한 고품질 문서 변환\n",
    "2. **🖼️ 이미지 처리**: VLM을 활용한 자동 캡션 생성\n",
    "3. **📚 문서 분할**: 의미 있는 청크 단위로 분할\n",
    "4. **🗄️ 벡터 DB**: 하이브리드 검색이 가능한 Qdrant 설정\n",
    "5. **🤖 QA 시스템**: LangGraph 기반 체계적 답변 생성\n",
    "\n",
    "이제 arXiv 논문에 대한 정확하고 상세한 질문-답변이 가능합니다!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
