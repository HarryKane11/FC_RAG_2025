{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ“„ PDF ë¬¸ì„œ ë³€í™˜ ë° ì²˜ë¦¬ ì´ˆê¸°í™”\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ arXiv ë…¼ë¬¸ì—ì„œ QA(ì§ˆë¬¸-ë‹µë³€) ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ê³¼ì •ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¨¼ì € PDF ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ë³€í™˜í•˜ê³  ì´ë¯¸ì§€ë¥¼ ì¶”ì¶œí•˜ì—¬ ì²˜ë¦¬í•˜ëŠ” ì‘ì—…ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ”§ Docling ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•œ PDF ë³€í™˜\n",
    "\n",
    "í‘œì¤€ ëª¨ë¸ì—ì„œ ë®¤ì˜¨ì˜ ì´ìƒ ìê¸° ëª¨ë©˜íŠ¸ì— ê´€í•œ ë¬¼ë¦¬í•™ ë…¼ë¬¸ì„ ëŒ€ìƒìœ¼ë¡œ, ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì¶”ì¶œê³¼ ìˆ˜ì‹ ì¸ì‹ì´ ê°€ëŠ¥í•œ ê³ ê¸‰ PDF íŒŒì´í”„ë¼ì¸ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash 30758e3e50e33b1c127abb388dad2ec7\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered picture descriptions: ['vlm', 'api']\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.pipeline.base_pipeline:Processing document The anomalous magnetic moment of the muon in the Standard Model.pdf\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\pipeline\\standard_pdf_pipeline.py:262: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(\n",
      "INFO:docling.document_converter:Finished converting document The anomalous magnetic moment of the muon in the Standard Model.pdf in 954.05 sec.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "# ë¡œê¹… ì„¤ì • - INFO ë ˆë²¨ë¡œ ë³€í™˜ ê³¼ì •ì„ ëª¨ë‹ˆí„°ë§\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "# ì…ë ¥ PDF íŒŒì¼ ê²½ë¡œì™€ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "input_doc_path = Path(\"data/The anomalous magnetic moment of the muon in the Standard Model.pdf\")\n",
    "output_dir = Path(\"standard_model\")\n",
    "\n",
    "# PDF íŒŒì´í”„ë¼ì¸ ì˜µì…˜ êµ¬ì„±\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.images_scale = 2.0  # ì´ë¯¸ì§€ í•´ìƒë„ ìŠ¤ì¼€ì¼ ì„¤ì •\n",
    "pipeline_options.generate_picture_images = True         # ê·¸ë¦¼ ì´ë¯¸ì§€ ìƒì„± í™œì„±í™”\n",
    "pipeline_options.do_formula_enrichment = True\n",
    "pipeline_options.do_picture_classification = True\n",
    "\n",
    "# ë¬¸ì„œ ë³€í™˜ê¸° ì´ˆê¸°í™” - PDF í˜•ì‹ ì˜µì…˜ê³¼ í•¨ê»˜ ì„¤ì •\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# ë³€í™˜ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "start_time = time.time()\n",
    "\n",
    "# PDF ë¬¸ì„œ ë³€í™˜ ì‹¤í–‰\n",
    "conv_res = doc_converter.convert(input_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ” ë¬¸ì„œ êµ¬ì¡° ë¶„ì„\n",
    "\n",
    "ë³€í™˜ëœ ë¬¸ì„œì—ì„œ ì–´ë–¤ ìœ í˜•ì˜ ìš”ì†Œë“¤ì´ ë°œê²¬ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, í‘œ, ìˆ˜ì‹ ë“±ì˜ ë¶„í¬ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ê³ ìœ í•œ element íƒ€ì…ë“¤:\n",
      "- FormulaItem\n",
      "- ListItem\n",
      "- PictureItem\n",
      "- SectionHeaderItem\n",
      "- TableItem\n",
      "- TextItem\n"
     ]
    }
   ],
   "source": [
    "# ë¬¸ì„œì—ì„œ ë°œê²¬ë˜ëŠ” ê³ ìœ í•œ element íƒ€ì…ë“¤ì„ í™•ì¸\n",
    "element_types = set()\n",
    "for element, _level in conv_res.document.iterate_items():\n",
    "    element_types.add(type(element).__name__)\n",
    "\n",
    "print(\"ë¬¸ì„œì—ì„œ ë°œê²¬ëœ ê³ ìœ í•œ element íƒ€ì…ë“¤:\")\n",
    "for element_type in sorted(element_types):\n",
    "    print(f\"- {element_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ’¾ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ ë° ì™„ë£Œ\n",
    "\n",
    "ë³€í™˜ëœ ë¬¸ì„œë¥¼ ì´ë¯¸ì§€ ì°¸ì¡°ê°€ í¬í•¨ëœ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë“¤ì€ ë³„ë„ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ë©°, ë§ˆí¬ë‹¤ìš´ì—ì„œëŠ” ìƒëŒ€ ê²½ë¡œë¡œ ì°¸ì¡°ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Document converted and figures exported in 1107.61 seconds.\n"
     ]
    }
   ],
   "source": [
    "doc_filename = \"physics_muon_paper\"\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ì´ë¯¸ì§€ ì°¸ì¡°ê°€ í¬í•¨ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ \n",
    "md_filename = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "conv_res.document.save_as_markdown(md_filename, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "# ë³€í™˜ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "# ë³€í™˜ ì™„ë£Œ ë¡œê·¸ ì¶œë ¥\n",
    "_log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ–¼ï¸ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ë° VLM í™œìš©\n",
    "\n",
    "ë…¼ë¬¸ì˜ ì´ë¯¸ì§€ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ Vision Language Model(VLM)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. \n",
    "\n",
    "#### ğŸ§ª ê°œë³„ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "Gemini 2.5 Flash ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ ì´ë¯¸ì§€ì— ëŒ€í•œ ìº¡ì…˜ ìƒì„±ì„ í…ŒìŠ¤íŠ¸í•´ë´…ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ APIì— ì „ì†¡í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for local image: ì´ ì´ë¯¸ì§€ëŠ” ë‘ ê°œì˜ ë‚˜ë€íˆ ë°°ì¹˜ëœ ê·¸ë˜í”„ë¡œ, Î· (ì—íƒ€) ë° Î·' (ì—íƒ€ í”„ë¼ì„) ì¤‘ê°„ìì˜ QÂ² ì˜ì¡´ì ì¸ ì „ì´ í˜•íƒœ ì¸ì(form factor)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ë‘ ê·¸ë˜í”„ ëª¨ë‘ ê°€ë¡œì¶•ì€ QÂ² (ìš´ë™ëŸ‰ ì „ë‹¬ ì œê³±)ë¥¼ GeVÂ² ë‹¨ìœ„ë¡œ, ì„¸ë¡œì¶•ì€ í˜•íƒœ ì¸ì ê°’ì„ GeV ë‹¨ìœ„ë¡œ í‘œì‹œí•©ë‹ˆë‹¤. ê·¸ë˜í”„ëŠ” ì—¬ëŸ¬ ì´ë¡ ì  ê³„ì‚° ê²°ê³¼(\"This work\", \"DSE\", \"CA\")ì™€ ì‹¤í—˜ ë°ì´í„°(\"CLEO\", \"CELLO\", \"L3\")ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.\n",
      "\n",
      "**ì™¼ìª½ ê·¸ë˜í”„: QÂ² FÎ·Î³*Î³*(-QÂ², 0)**\n",
      "*   **ì œëª©:** Î· ì¤‘ê°„ìì˜ ì „ì´ í˜•íƒœ ì¸ì QÂ² FÎ·Î³*Î³*(-QÂ², 0)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "*   **ì¶• ë²”ìœ„:** ê°€ë¡œì¶• QÂ²ëŠ” 0ì—ì„œ 2 GeVÂ²ê¹Œì§€, ì„¸ë¡œì¶•ì€ 0ì—ì„œ 0.2 GeVê¹Œì§€ ë²”ìœ„ì…ë‹ˆë‹¤.\n",
      "*   **ë²”ë¡€:**\n",
      "    *   **This work:** ì—°í•œ íŒŒë€ìƒ‰ ìŒì˜ ì˜ì—­ê³¼ ê·¸ ì¤‘ì•™ì˜ íŒŒë€ìƒ‰ ì‹¤ì„ ìœ¼ë¡œ í‘œì‹œëœ í˜„ì¬ ì—°êµ¬ì˜ ì´ë¡ ì  ì˜ˆì¸¡ì…ë‹ˆë‹¤.\n",
      "    *   **CLEO:** ë…¹ìƒ‰ ì›í˜• ì ìœ¼ë¡œ í‘œì‹œëœ ì‹¤í—˜ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
      "    *   **CELLO:** íŒŒë€ìƒ‰ ì‚¬ê°í˜• ì ìœ¼ë¡œ í‘œì‹œëœ ì‹¤í—˜ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
      "    *   **DSE:** ë…¹ìƒ‰ ìŒì˜ ì˜ì—­ìœ¼ë¡œ í‘œì‹œëœ ì´ë¡ ì  ëª¨ë¸(Dyson-Schwinger Equations)ì…ë‹ˆë‹¤.\n",
      "    *   **CA:** ì£¼í™©ìƒ‰ ìŒì˜ ì˜ì—­ìœ¼ë¡œ í‘œì‹œëœ ì´ë¡ ì  ëª¨ë¸(Chiral Anomaly)ì…ë‹ˆë‹¤.\n",
      "*   **ë°ì´í„° ê²½í–¥:**\n",
      "    *   ëª¨ë“  ê³¡ì„ ê³¼ ë°ì´í„°ëŠ” QÂ²ê°€ ì¦ê°€í•¨ì— ë”°ë¼ 0ì—ì„œ ì‹œì‘í•˜ì—¬ ì ì§„ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
      "    *   \"This work\"ì˜ íŒŒë€ìƒ‰ ì˜ˆì¸¡ ë°´ë“œëŠ” \"CELLO\" ì‹¤í—˜ ë°ì´í„° í¬ì¸íŠ¸ì™€ ì˜ ì¼ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n",
      "    *   \"CLEO\" ì‹¤í—˜ ë°ì´í„° í¬ì¸íŠ¸ëŠ” \"DSE\" ë° \"CA\" ì´ë¡ ì  ì˜ˆì¸¡ ë°´ë“œì™€ ë” ê°€ê¹ê²Œ ìœ„ì¹˜í•©ë‹ˆë‹¤.\n",
      "    *   ì´ë¡ ì  ì˜ˆì¸¡ì˜ ìŒì˜ ì˜ì—­ì€ ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ë‚´ë©°, QÂ²ê°€ ì»¤ì§ˆìˆ˜ë¡ ì´ ë¶ˆí™•ì‹¤ì„± ì˜ì—­ë„ ë„“ì–´ì§‘ë‹ˆë‹¤.\n",
      "    *   ëª¨ë“  ì‹¤í—˜ ë°ì´í„° í¬ì¸íŠ¸ì—ëŠ” ê°€ë¡œ ë° ì„¸ë¡œ ì˜¤ì°¨ ë§‰ëŒ€ê°€ í‘œì‹œë˜ì–´ ì¸¡ì • ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "**ì˜¤ë¥¸ìª½ ê·¸ë˜í”„: QÂ² FÎ·'Î³*Î³*(-QÂ², 0)**\n",
      "*   **ì œëª©:** Î·' ì¤‘ê°„ìì˜ ì „ì´ í˜•íƒœ ì¸ì QÂ² FÎ·'Î³*Î³*(-QÂ², 0)ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "*   **ì¶• ë²”ìœ„:** ê°€ë¡œì¶• QÂ² ë²”ìœ„ëŠ” ì™¼ìª½ê³¼ ë™ì¼í•˜ë©°, ì„¸ë¡œì¶•ì€ 0ì—ì„œ 0.25 GeVê¹Œì§€ í™•ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "*   **ë²”ë¡€:** ì™¼ìª½ ê·¸ë˜í”„ì˜ ë²”ë¡€ì— ë”í•´ \"L3\"(ë¹¨ê°„ìƒ‰ ì‚¼ê°í˜• ì ) ì‹¤í—˜ ë°ì´í„°ê°€ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ë²”ë¡€ í•­ëª©ì€ ë™ì¼í•©ë‹ˆë‹¤.\n",
      "*   **ë°ì´í„° ê²½í–¥:**\n",
      "    *   ì´ ê·¸ë˜í”„ ì—­ì‹œ QÂ²ê°€ ì¦ê°€í•¨ì— ë”°ë¼ í˜•íƒœ ì¸ìê°€ ì¦ê°€í•˜ëŠ” ê²½í–¥ì„ ë³´ì…ë‹ˆë‹¤.\n",
      "    *   \"This work\"ì˜ íŒŒë€ìƒ‰ ì˜ˆì¸¡ ë°´ë“œëŠ” \"CELLO\" ì‹¤í—˜ ë°ì´í„°ì™€ ì € QÂ² ì˜ì—­ì˜ \"L3\" ì‹¤í—˜ ë°ì´í„°ì™€ ì˜ ë¶€í•©í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
      "    *   \"L3\" ë°ì´í„°ëŠ” íŠ¹íˆ QÂ²ê°€ ë‚®ì€ ì˜ì—­(0.2 GeVÂ² ë¯¸ë§Œ)ì—ì„œ \"This work\", \"DSE\", \"CA\" ì˜ˆì¸¡ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤.\n",
      "    *   \"CLEO\" ì‹¤í—˜ ë°ì´í„°ëŠ” ë†’ì€ QÂ²ì—ì„œ \"This work\" ê³¡ì„ ì˜ ìƒë‹¨ ë˜ëŠ” ê·¸ë³´ë‹¤ ì•½ê°„ ë†’ì€ ìœ„ì¹˜ì— ìˆìœ¼ë©°, \"DSE\" ë° \"CA\" ì˜ˆì¸¡ë³´ë‹¤ ë†’ê²Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.\n",
      "    *   ëª¨ë“  ì‹¤í—˜ ë°ì´í„°ì—ëŠ” ì˜¤ì°¨ ë§‰ëŒ€ê°€ í‘œì‹œë˜ì–´ ì¸¡ì • ë¶ˆí™•ì‹¤ì„±ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "**ì „ë°˜ì ì¸ ìš”ì•½:**\n",
      "ë‘ ê·¸ë˜í”„ ëª¨ë‘ \"This work\"ì˜ ì´ë¡ ì  ê³„ì‚°ì´ Î· ë° Î·' ì¤‘ê°„ìì˜ QÂ² ì˜ì¡´ì ì¸ ì „ì´ í˜•íƒœ ì¸ìì— ëŒ€í•œ ë‹¤ì–‘í•œ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë¹„êµì  ì˜ ì„¤ëª…í•˜ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë™ì‹œì— \"DSE\" ë° \"CA\"ì™€ ê°™ì€ ë‹¤ë¥¸ ì´ë¡ ì  ëª¨ë¸ê³¼ì˜ ë¹„êµ ë° ë‹¤ì–‘í•œ ì‹¤í—˜ ë°ì´í„°(CLEO, CELLO, L3)ì˜ ì°¨ì´ë¥¼ ì‹œê°ì ìœ¼ë¡œ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ\n",
    "image_path = \"standard_model\\physics_muon_paper-with-image-refs_artifacts\\image_000113_5d0f0f98dd32385cc160b1f470c6fe41e41cd81e6795a6af111ac6f2d451f1a0.png\"\n",
    "\n",
    "# ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ì„ base64ë¡œ ì¸ì½”ë”©\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "message_local = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"text\", \"text\": \"ì´ ì´ë¯¸ì§€ë¥¼ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´í•˜ê³ ì í•©ë‹ˆë‹¤. í•´ë‹¹ ì´ë¯¸ì§€ì— ëŒ€í•œ ì„¤ëª…ì„ í•œê¸€ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{encoded_image}\"},\n",
    "    ]\n",
    ")\n",
    "result_local = llm.invoke([message_local])\n",
    "print(f\"Response for local image: {result_local.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### âš¡ ë°°ì¹˜ ì²˜ë¦¬ë¥¼ í†µí•œ ëŒ€ëŸ‰ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±\n",
    "\n",
    "ë…¼ë¬¸ì— í¬í•¨ëœ ëª¨ë“  ì´ë¯¸ì§€(124ê°œ)ì— ëŒ€í•´ ìë™ìœ¼ë¡œ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” ê³ ê¸‰ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
    "\n",
    "ì£¼ìš” ê¸°ëŠ¥:\n",
    "- ì´ë¯¸ì§€ ì£¼ë³€ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° í™œìš©\n",
    "- Rate limitì„ ì¤€ìˆ˜í•˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬\n",
    "- ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ì— ëŒ€í•œ ê°œë³„ ì¬ì²˜ë¦¬\n",
    "- ìƒì„±ëœ ìº¡ì…˜ìœ¼ë¡œ ì´ë¯¸ì§€ ì°¸ì¡° ìë™ ëŒ€ì²´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ì°¾ì•„ì„œ VLMìœ¼ë¡œ ìº¡ì…˜ ìƒì„± í›„ ëŒ€ì²´í•˜ëŠ” ì½”ë“œ\n",
    "\n",
    "import re\n",
    "import time\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "def extract_surrounding_context(content, image_ref, context_lines=3):\n",
    "    \"\"\"\n",
    "    ì´ë¯¸ì§€ ì°¸ì¡° ì£¼ë³€ì˜ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ\n",
    "    \"\"\"\n",
    "    lines = content.split('\\n')\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì°¸ì¡°ê°€ ìˆëŠ” ë¼ì¸ ì°¾ê¸°\n",
    "    image_line_idx = None\n",
    "    for i, line in enumerate(lines):\n",
    "        if image_ref in line:\n",
    "            image_line_idx = i\n",
    "            break\n",
    "    \n",
    "    if image_line_idx is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # ì•ë’¤ context_linesë§Œí¼ì˜ ë¼ì¸ ì¶”ì¶œ\n",
    "    start_idx = max(0, image_line_idx - context_lines)\n",
    "    end_idx = min(len(lines), image_line_idx + context_lines + 1)\n",
    "    \n",
    "    context_lines_list = lines[start_idx:end_idx]\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì°¸ì¡° ë¼ì¸ ì œì™¸í•˜ê³  ì»¨í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "    context_lines_list = [line for line in context_lines_list if image_ref not in line]\n",
    "    \n",
    "    # ë¹ˆ ë¼ì¸ê³¼ ë§ˆí¬ë‹¤ìš´ í—¤ë” ë“± ì •ë¦¬\n",
    "    context_text = '\\n'.join(context_lines_list).strip()\n",
    "    \n",
    "    return context_text\n",
    "\n",
    "def create_caption_message(image_path: Path, context: str) -> HumanMessage:\n",
    "    \"\"\"\n",
    "    VLM ìº¡ì…˜ ìƒì„±ì„ ìœ„í•œ ë©”ì‹œì§€ ìƒì„±\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        \n",
    "        # ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "        prompt = f\"\"\"ë‹¤ìŒì€ í•™ìˆ  ë…¼ë¬¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ ì£¼ë³€ì˜ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ì£¼ë³€ í…ìŠ¤íŠ¸:\n",
    "{context}\n",
    "\n",
    "ìœ„ í…ìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì ì ˆí•œ ìº¡ì…˜ì„ í•œê¸€ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”. \n",
    "ìº¡ì…˜ì€ ê°„ê²°í•˜ê³  ì •í™•í•˜ë©°, ì£¼ë³€ í…ìŠ¤íŠ¸ì˜ ë§¥ë½ì— ë§ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\"\"\n",
    "\n",
    "        message = HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{encoded_image}\"},\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return message\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_images_with_lcel_batch(image_data_list: List[Tuple[str, str, Path, str]], batch_size: int = 5):\n",
    "    \"\"\"\n",
    "    LCEL batchë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë“¤ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬\n",
    "    Gemini 2.5 Flash Preview 05-20: 10 RPM, 250,000 TPM, 500 RPD\n",
    "    \"\"\"\n",
    "    captions = {}\n",
    "    total_batches = (len(image_data_list) + batch_size - 1) // batch_size\n",
    "    \n",
    "    print(f\"ì´ {len(image_data_list)}ê°œ ì´ë¯¸ì§€ë¥¼ {total_batches}ê°œ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    for batch_idx in range(0, len(image_data_list), batch_size):\n",
    "        batch = image_data_list[batch_idx:batch_idx + batch_size]\n",
    "        batch_num = batch_idx // batch_size + 1\n",
    "        \n",
    "        print(f\"ë°°ì¹˜ {batch_num}/{total_batches} ì²˜ë¦¬ ì¤‘... ({len(batch)}ê°œ ì´ë¯¸ì§€)\")\n",
    "        \n",
    "        # ë°°ì¹˜ìš© ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "        batch_messages = []\n",
    "        batch_refs = []\n",
    "        \n",
    "        for alt_text, image_path, full_image_path, context in batch:\n",
    "            print(f\"  - ë©”ì‹œì§€ ì¤€ë¹„ ì¤‘: {image_path}\")\n",
    "            message = create_caption_message(full_image_path, context)\n",
    "            if message:\n",
    "                batch_messages.append([message])  # LCEL batchëŠ” ê° ì…ë ¥ì´ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨\n",
    "                batch_refs.append(f\"![{alt_text}]({image_path})\")\n",
    "            else:\n",
    "                print(f\"  - ë©”ì‹œì§€ ìƒì„± ì‹¤íŒ¨: {image_path}\")\n",
    "                batch_refs.append(f\"![{alt_text}]({image_path})\")\n",
    "                captions[f\"![{alt_text}]({image_path})\"] = f\"[ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨: {image_path}]\"\n",
    "        \n",
    "        # LCEL batch ì²˜ë¦¬\n",
    "        if batch_messages:\n",
    "            try:\n",
    "                print(f\"  - LCEL batch ì‹¤í–‰ ì¤‘... ({len(batch_messages)}ê°œ ë©”ì‹œì§€)\")\n",
    "                batch_results = llm.batch(batch_messages)\n",
    "                \n",
    "                # ê²°ê³¼ ì²˜ë¦¬\n",
    "                for i, result in enumerate(batch_results):\n",
    "                    if i < len(batch_refs):\n",
    "                        caption = result.content.strip() if hasattr(result, 'content') else str(result).strip()\n",
    "                        captions[batch_refs[i]] = caption\n",
    "                        print(f\"  - ìº¡ì…˜ ìƒì„± ì™„ë£Œ: {batch_refs[i][:50]}...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  - ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±\n",
    "                for i, message_list in enumerate(batch_messages):\n",
    "                    try:\n",
    "                        result = llm.invoke(message_list)\n",
    "                        caption = result.content.strip()\n",
    "                        captions[batch_refs[i]] = caption\n",
    "                        print(f\"  - ê°œë³„ ì²˜ë¦¬ ì™„ë£Œ: {batch_refs[i][:50]}...\")\n",
    "                        time.sleep(6.5)  # Rate limit ì¤€ìˆ˜\n",
    "                    except Exception as individual_error:\n",
    "                        print(f\"  - ê°œë³„ ì²˜ë¦¬ ì‹¤íŒ¨: {individual_error}\")\n",
    "                        captions[batch_refs[i]] = f\"[ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„± ì‹¤íŒ¨]\"\n",
    "        \n",
    "        # ë°°ì¹˜ ê°„ Rate limit ì¤€ìˆ˜ë¥¼ ìœ„í•œ ëŒ€ê¸°\n",
    "        # RPM 10 ì œí•œ: ë°°ì¹˜ í¬ê¸°ê°€ 5ë¼ë©´ 30ì´ˆ ëŒ€ê¸° (6ì´ˆ * 5)\n",
    "        if batch_num < total_batches:\n",
    "            wait_time = batch_size * 6.5\n",
    "            print(f\"ë°°ì¹˜ {batch_num} ì™„ë£Œ. Rate limit ì¤€ìˆ˜ë¥¼ ìœ„í•´ {wait_time}ì´ˆ ëŒ€ê¸°...\")\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    return captions\n",
    "\n",
    "def replace_image_refs_with_captions(md_file_path, output_dir, doc_filename):\n",
    "    \"\"\"\n",
    "    ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ VLM ìƒì„± ìº¡ì…˜ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì €ì¥\n",
    "    \"\"\"\n",
    "    # ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°\n",
    "    with open(md_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì°¸ì¡° íŒ¨í„´ ì°¾ê¸° (![alt_text](image_path) í˜•ì‹)\n",
    "    image_pattern = r'!\\[([^\\]]*)\\]\\(([^)]+)\\)'\n",
    "    matches = re.findall(image_pattern, content)\n",
    "    \n",
    "    print(f\"ë°œê²¬ëœ ì´ë¯¸ì§€ ì°¸ì¡° ê°œìˆ˜: {len(matches)}\")\n",
    "    \n",
    "    # ì²˜ë¦¬í•  ì´ë¯¸ì§€ ë°ì´í„° ì¤€ë¹„\n",
    "    image_data_list = []\n",
    "    \n",
    "    for alt_text, image_path in matches:\n",
    "        # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜\n",
    "        if not Path(image_path).is_absolute():\n",
    "            full_image_path = output_dir / image_path\n",
    "        else:\n",
    "            full_image_path = Path(image_path)\n",
    "        \n",
    "        if full_image_path.exists():\n",
    "            # ì´ë¯¸ì§€ ì°¸ì¡° ì£¼ë³€ì˜ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "            image_ref = f\"![{alt_text}]({image_path})\"\n",
    "            surrounding_context = extract_surrounding_context(content, image_ref, context_lines=3)\n",
    "            \n",
    "            image_data_list.append((alt_text, image_path, full_image_path, surrounding_context))\n",
    "            print(f\"ì´ë¯¸ì§€ ì¶”ê°€: {image_path}\")\n",
    "            print(f\"ì»¨í…ìŠ¤íŠ¸: {surrounding_context[:100]}{'...' if len(surrounding_context) > 100 else ''}\\n\")\n",
    "        else:\n",
    "            print(f\"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {full_image_path}\")\n",
    "    \n",
    "    if not image_data_list:\n",
    "        print(\"ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return md_file_path\n",
    "    \n",
    "    # LCEL batch ì²˜ë¦¬ë¡œ ìº¡ì…˜ ìƒì„±\n",
    "    print(\"LCEL batchë¥¼ ì‚¬ìš©í•œ ìº¡ì…˜ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    captions = process_images_with_lcel_batch(image_data_list, batch_size=5)\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ìº¡ì…˜ìœ¼ë¡œ ëŒ€ì²´\n",
    "    for image_ref, caption in captions.items():\n",
    "        content = content.replace(image_ref, f\"[ì´ë¯¸ì§€ ìº¡ì…˜: {caption}]\")\n",
    "        print(f\"ëŒ€ì²´ ì™„ë£Œ: {image_ref[:50]}... -> {caption[:50]}...\")\n",
    "    \n",
    "    # ìº¡ì…˜ì´ ì ìš©ëœ ìƒˆë¡œìš´ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥\n",
    "    captioned_md_filename = output_dir / f\"{doc_filename}-with-captions.md\"\n",
    "    with open(captioned_md_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "    \n",
    "    end_time = time.time() - start_time\n",
    "    print(f\"ìº¡ì…˜ ìƒì„± ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {end_time:.2f}ì´ˆ\")\n",
    "    print(f\"ì´ {len(captions)}ê°œ ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±ë¨\")\n",
    "    print(f\"ìº¡ì…˜ì´ ì ìš©ëœ ìƒˆë¡œìš´ íŒŒì¼ ì €ì¥: {captioned_md_filename}\")\n",
    "    \n",
    "    return captioned_md_filename\n",
    "\n",
    "# ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ìº¡ì…˜ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì €ì¥\n",
    "captioned_file = replace_image_refs_with_captions(md_filename, output_dir, doc_filename)\n",
    "# End of Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ“š ë¬¸ì„œ ë¶„í•  ë° ì„ë² ë”© ì¤€ë¹„\n",
    "\n",
    "#### âœ‚ï¸ í…ìŠ¤íŠ¸ ì²­í‚¹\n",
    "\n",
    "ìº¡ì…˜ì´ ìƒì„±ëœ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ RAG ì‹œìŠ¤í…œì— ì í•©í•œ í¬ê¸°ì˜ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤. RecursiveCharacterTextSplitterë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ ìˆëŠ” êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¶„í• í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"##\\n\",\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# ìº¡ì…˜ì´ ì ìš©ëœ íŒŒì¼ ë‚´ìš© ì½ê¸°\n",
    "with open(captioned_file, 'r', encoding='utf-8') as f:\n",
    "    captioned_content = f.read()\n",
    "\n",
    "# Document ê°ì²´ë¡œ ìƒì„±\n",
    "document = Document(page_content=captioned_content, metadata={\"source\": str(captioned_file)})\n",
    "\n",
    "# split_documentsë¥¼ ì‚¬ìš©í•˜ì—¬ Document ê°ì²´ë“¤ë¡œ ë¶„í• \n",
    "splits = text_splitter.split_documents([document])\n",
    "\n",
    "# splits ê¸¸ì´ ë¶„í¬ íŒŒì•…\n",
    "split_lengths = [len(split.page_content) for split in splits]\n",
    "print(f\"ì´ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(splits)}\")\n",
    "print(f\"í‰ê·  ì²­í¬ ê¸¸ì´: {sum(split_lengths) / len(split_lengths):.1f} ë¬¸ì\")\n",
    "print(f\"ìµœì†Œ ì²­í¬ ê¸¸ì´: {min(split_lengths)} ë¬¸ì\")\n",
    "print(f\"ìµœëŒ€ ì²­í¬ ê¸¸ì´: {max(split_lengths)} ë¬¸ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ‘€ ë¶„í•  ê²°ê³¼ í™•ì¸\n",
    "\n",
    "ë¶„í• ëœ ì²« ë²ˆì§¸ ì²­í¬ì˜ ë‚´ìš©ì„ í™•ì¸í•˜ì—¬ ì²­í‚¹ì´ ì˜¬ë°”ë¥´ê²Œ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ ê²€í† í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ—„ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë° í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "\n",
    "#### ğŸ’¾ Qdrant ë²¡í„° ìŠ¤í† ì–´ êµ¬ì¶•\n",
    "\n",
    "Dense embeddingê³¼ Sparse embeddingì„ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤:\n",
    "- **Dense embedding**: BGE-M3 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì˜ë¯¸ì  ìœ ì‚¬ë„ ê²€ìƒ‰\n",
    "- **Sparse embedding**: BM25 ê¸°ë°˜ í‚¤ì›Œë“œ ê²€ìƒ‰\n",
    "- **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: ë‘ ë°©ì‹ì„ ê²°í•©í•˜ì—¬ ë” ì •í™•í•œ ê²€ìƒ‰ ì„±ëŠ¥ í™•ë³´\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/arxiv_physics_muon_paper \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET http://localhost:6333/collections/arxiv_physics_muon_paper \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìƒˆ ì»¬ë ‰ì…˜ 'arxiv_physics_muon_paper' ìƒì„±ë¨\n",
      "ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import Distance, SparseVectorParams, VectorParams\n",
    "\n",
    "# Qdrant í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "dense_embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# ì»¬ë ‰ì…˜ ì´ë¦„ ì„¤ì •\n",
    "collection_name = f\"arxiv_{doc_filename}\"\n",
    "# try:\n",
    "    # client.create_collection(\n",
    "    #     collection_name=collection_name,\n",
    "    #     vectors_config={\"dense\": VectorParams(size=1024, distance=Distance.COSINE)},\n",
    "    #     sparse_vectors_config={\n",
    "    #         \"sparse\": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))\n",
    "    #     },\n",
    "    # )\n",
    "# print(f\"ìƒˆ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„±ë¨\")\n",
    "    # ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€\n",
    "# print(\"ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ ì¤‘...\")\n",
    "qdrant = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=dense_embeddings,\n",
    "    sparse_embedding=sparse_embeddings,\n",
    "    retrieval_mode=RetrievalMode.HYBRID,\n",
    "    vector_name=\"dense\",\n",
    "    sparse_vector_name=\"sparse\",\n",
    ")\n",
    "    # qdrant.add_documents(splits)\n",
    "    # print(f\"âœ… {len(splits)}ê°œì˜ ë¬¸ì„œê°€ Qdrantì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# except:\n",
    "#     qdrant = QdrantVectorStore(\n",
    "#         client=client,\n",
    "#         collection_name=collection_name,\n",
    "#         embedding=dense_embeddings,\n",
    "#         sparse_embedding=sparse_embeddings,\n",
    "#         retrieval_mode=RetrievalMode.HYBRID,\n",
    "#         vector_name=\"dense\",\n",
    "#         sparse_vector_name=\"sparse\",\n",
    "#     )\n",
    "#     print(f\"âœ… {len(splits)}ê°œì˜ ë¬¸ì„œê°€ Qdrantì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ” ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”\n",
    "\n",
    "ë²¡í„° ìŠ¤í† ì–´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. ìƒìœ„ 10ê°œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ë„ë¡ êµ¬ì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = qdrant.as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ¨ ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜\n",
    "\n",
    "ê²€ìƒ‰ëœ ë¬¸ì„œë“¤ì„ ê¹”ë”í•˜ê²Œ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥í•˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ì…ë‹ˆë‹¤. ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„°ì™€ ë‚´ìš©ì„ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search_results(docs, title):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì´ì˜ê²Œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"{title}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"ğŸ“„ ë¬¸ì„œ {i}\")\n",
    "        print(f\"ğŸ“‚ ì¶œì²˜: {doc.metadata.get('source', 'N/A')}\")\n",
    "        print(f\"ğŸ“ƒ í˜ì´ì§€: {doc.metadata.get(' page', 'N/A')}\")\n",
    "        print(f\"ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "        print(doc.page_content)\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ§ª ê¸°ë³¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "HLbL(Hadronic Light-by-Light) ë¶ˆí™•ì‹¤ì„±ì— ê´€í•œ ì§ˆë¬¸ìœ¼ë¡œ ê²€ìƒ‰ ì‹œìŠ¤í…œì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ì´ëŠ” ë®¤ì˜¨ g-2 ì‹¤í—˜ì˜ í•µì‹¬ ì£¼ì œ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/arxiv_physics_muon_paper/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ê¸°ë³¸ Retriever ê²€ìƒ‰ ê²°ê³¼:\n",
      "================================================================================\n",
      "ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: 10ê°œ\n",
      "\n",
      "ğŸ“„ ë¬¸ì„œ 1\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "Table 33: Comparison of the key results from this work (WP25), as given in Table 1, to the corresponding numbers from WP20 [1] (in units of 10 -11 ). Note that the 'HLbL (lattice)' result from WP20 has been adapted to include the charm-loop contribution. The entry 'HVP (LO + NLO + NNLO)' derives from HVP LO (lattice) [WP25] and HVP LO ( e + e -) [WP20], respectively. The asterisk indicates that the LO HVP value from WP20 was based on e + e -data only, while in Table 5 we also include the current status for Ï„ -based evaluations.\n",
      "\n",
      "## 9. Conclusions and outlook\n",
      "\n",
      "In this second edition of the White Paper on the muon g -2, we have charted the progress that has been achieved since 2020 in evaluating the contributions from the electromagnetic (QED), electroweak (EW), and strong (QCD) interactions to a Âµ .\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 2\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "In recent years, the theoretical and experimental work aimed at reducing the uncertainties of the SM prediction has been particularly intense and relied on higher-order calculations, dispersive methods, lattice QCD, e ff ective field theories, as well as new data inputs from experiments. For HLbL these e ff orts have indeed been successful and the change from WP20 to the present review is that the uncertainty has been reduced by about a factor of two. Concerning HVP the situation is more complicated as reflected by the fact that the present review does not present a number for a data-driven estimate of this contribution, since not yet understood discrepancies among di ff erent experiments have emerged. On the other hand, there has been significant progress in lattice-QCD calculations of this quantity, and the consensus number for the HVP contribution presented in this review is based on them. The change from a data-driven to a lattice estimate of this contribution also means that the\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 3\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "$$a _ { \\mu } ^ { \\text{HLbL} } = a _ { \\mu } ^ { \\text{HLbL,c} } + a _ { \\mu } ^ { \\text{HLbL,s} } + a _ { \\mu } ^ { \\text{HLbL,c} } + a _ { \\mu } ^ { \\text{HLbL,rest} } \\,,$$\n",
      "\n",
      "where\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 4\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "For the hadronic light-by-light (HLbL) contribution, significant progress since WP20 has been made in both the dispersive method and lattice QCD. On the data-driven side, improved calculations of short-distance constraints and a number of subleading contributions have become available, leading to a reduction of the uncertainty by about a factor of two compared to WP20. At the same time, new lattice-QCD calculations have reached a similar level of precision. The two averages, from phenomenology and lattice QCD, are combined into a final average with a precision below 10%.\n",
      "\n",
      "Table 1 gives a summary of the contributions to the SM prediction, along with the locations in this White Paper (WP25) where the results are discussed.\n",
      "\n",
      "## 1. Introduction\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 5\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "$$a _ { \\mu } ^ { \\text{HVP}, \\text{LO} } ( \\text{WP} 2 0 ) = 7 1 1. 6 ( 1 8. 4 ) \\times 1 0 ^ { - 1 0 } \\,,$$\n",
      "\n",
      "with an uncertainty of 2.6%. As a consequence, the lattice world average was consistent with both the dispersive data-driven estimate and the 'no new physics' scenario. The uncertainty was a factor of 4.5 larger than that of the data-driven estimate, and the lattice average was not included in the final SM value for a HVP, LO Âµ . We also note that the BMW-20 [15] lattice calculation, which reported a precision of 0.8%, was posted on arXiv after the WP20 deadline and published in April 2021. Consequently, it was not included in the WP20 lattice world average of Eq. (3.7).\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 6\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "| 6   | Lattice approaches to HLbL                                               | Lattice approaches to HLbL                                                      | 140     |\n",
      "| 6.1 | Introduction . . . . .                                                   | . . . . . . . . . . . . . . . . . . . . .                                       | 140     |\n",
      "| 6.2 | Direct                                                                   | lattice calculations of the hadronic light-by-light contribution                | 140     |\n",
      "|     | 6.2.1                                                                    | a HLbL ,â„“ Âµ : the Mainz / CLS calculation . . . . . . . . . HLbL                | 142     |\n",
      "|     | 6.2.2 6.2.3                                                              | a ,â„“ Âµ : the RBC / UKQCD calculation . . . . . . . HLbL . . . . . . . . . . . . | 144 148 |\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 7\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "Table 32: Current lattice results for the direct calculation of a HLbL , where statistical and systematic errors have been added in quadrature.\n",
      "\n",
      "| Contribution                                                    | Average [10 - 11 ]                                                                                                       | Sources                                                                                 |\n",
      "|-----------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|\n",
      "| a HLbL ,â„“ Âµ a HLbL , s Âµ a HLbL , c Âµ a HLbL , 3 + 1 Âµ a HLbL Âµ | 119 . 6(7 . 1) stat (5 . 5) syst [9 . 0] tot - 1 . 4(8) 3 . 5(5) 0 . 82(25) 122 . 5(7 . 1) stat (5 . 6) syst [9 . 0] tot | Eq. (6.24), Table 31 Eqs. (6.27) and (6.28) Eqs. (6.29) to (6.31) Eq. (6.32) Eq. (6.34) |\n",
      "\n",
      "Âµ\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 8\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "$$a _ { \\mu } ^ { \\text{charm} \\cdot } = 3 ( 1 ) \\times 1 0 ^ { - 1 1 } \\,.$$\n",
      "\n",
      "Adding all the errors quadratically and the contributions gives a total (LO) HLbL contribution of\n",
      "\n",
      "$$a _ { \\mu } ^ { H L b L } = 1 0 3. 3 ( 8. 8 ) \\times 1 0 ^ { - 1 1 }.$$\n",
      "\n",
      "This should be compared with the WP20 result of 92(19) Ã— 10 -11 . Our new number is perfectly compatible with the previous number within errors and has a significantly improved precision due to improvements of many hadronic contributions as well as improvements in short-distance calculations and matching.\n",
      "\n",
      "Finally, there is the estimate of the NLO HLbL contribution from Ref. [57], which we update along the lines of Ref. [1]:\n",
      "\n",
      "$$a _ { \\mu } ^ { H L b L, N L O } = 2. 6 ( 6 ) \\times 1 0 ^ { - 1 1 } \\,.$$\n",
      "\n",
      "## 5.11. Prospects for future improvements\n",
      "\n",
      "## 5.11.1. Theory\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 9\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "The flavor structure of i b Î  plays an important role. In terms of the isospin decomposition j Âµ = j 3 Âµ + j 8 Âµ / 3 of the EMcurrent in the ( u d , , s ) sector, i b Î  can be decomposed into three terms, involving either zero, two, or four isovector currents j 3 Âµ , which lead respectively to the contributions a HLbL { j 8 } Âµ , a HLbL { j 3 , j 8 } Âµ , and a HLbL { j 3 } Âµ . On the other hand, for a given quark current there are five classes of Wick contractions, the connected (4) as well as the (2 + 2), the (3 + 1), the (2 + + 1 1), and the (1 + + + 1 1 1) disconnected diagrams. For instance, we denote the (2 + 2) contribution to a HLbL Âµ from the u d , quarks a HLbL (2 , â„“ + 2 ) â„“ Âµ . In particular, the contribution involving four isovector currents j 3 Âµ corresponds to a linear combination of the two leading quark-level contractions, a HLbL (4) , â„“ Âµ and a HLbL (2 , + 2) â„“ Âµ . We write\n",
      "----------------------------------------\n",
      "ğŸ“„ ë¬¸ì„œ 10\n",
      "ğŸ“‚ ì¶œì²˜: standard_model\\physics_muon_paper-with-captions.md\n",
      "ğŸ“ƒ í˜ì´ì§€: N/A\n",
      "ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\n",
      "2020 (WP20) [1]. Since then, new measurements have been announced by the Fermilab g -2 experiment, the first result in 2021 [6] with a precision of 460 ppb, and the second result in 2023 [7] with 200 ppb. These new measurements are consistent with, but more precise than, the ones of the BNL experiment, and provide the basis of the current world average. The agreement of the two most precise experiments lends a high degree of reliability to this world average. At present, the Fermilab E989 experiment is preparing to announce its final results with the full set of all experimental data collected. Another experiment with a largely di ff erent experimental method is currently under preparation at J-PARC [8], allowing an independent cross-check of these results.\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "query = \"HLbL ë¶ˆí™•ì‹¤ì„±ì´ 2020 WP ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ì¤„ì—ˆëŠ”ê°€?\"\n",
    "\n",
    "# ê¸°ë³¸ retriever ê²€ìƒ‰\n",
    "basic_docs = retriever.invoke(query)\n",
    "print_search_results(basic_docs, \"ğŸ” ê¸°ë³¸ Retriever ê²€ìƒ‰ ê²°ê³¼:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ¤– LangGraphë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ êµ¬ì¶•\n",
    "\n",
    "#### âš™ï¸ RAG ì›Œí¬í”Œë¡œìš° ì„¤ì •\n",
    "\n",
    "LangGraphë¥¼ ì‚¬ìš©í•˜ì—¬ ì²´ê³„ì ì¸ RAG(Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **State ì •ì˜**: ì§ˆë¬¸, ê²€ìƒ‰ëœ ë¬¸ì„œ, ìƒì„±ëœ ë‹µë³€ì„ ê´€ë¦¬\n",
    "2. **LLM ì„¤ì •**: Gemma3 4B ëª¨ë¸ì„ ì‚¬ìš©í•œ ë‹µë³€ ìƒì„±\n",
    "3. **í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿**: í•œêµ­ì–´ ë‹µë³€ì„ ìœ„í•œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸\n",
    "4. **ì›Œí¬í”Œë¡œìš° ë…¸ë“œ**: ë¬¸ì„œ ê²€ìƒ‰ê³¼ ë‹µë³€ ìƒì„±ì˜ ë‹¨ê³„ë³„ ì²˜ë¦¬\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# State ì •ì˜\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma3:4b\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¬¸ì„œë“¤:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "ë‹µë³€:\n",
    "\"\"\")\n",
    "\n",
    "def retrieve_documents(state: RAGState) -> RAGState:\n",
    "    \"\"\"ë¬¸ì„œ ê²€ìƒ‰ ë‹¨ê³„\"\"\"\n",
    "    print(\"ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\")\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    print(f\"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "\n",
    "def generate_answer(state: RAGState) -> RAGState:\n",
    "    \"\"\"ë‹µë³€ ìƒì„± ë‹¨ê³„\"\"\"\n",
    "    print(\"ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # ë¬¸ì„œ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    # LLM ì²´ì¸ êµ¬ì„±\n",
    "    chain = rag_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # ë‹µë³€ ìƒì„±\n",
    "    answer = chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    print(\"âœ… ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "workflow = StateGraph(RAGState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "rag_app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸš€ ì™„ì „í•œ RAG ì‹œìŠ¤í…œ ì‹¤í–‰\n",
    "\n",
    "êµ¬ì¶•ëœ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. \n",
    "- ë¬¸ì„œ ê²€ìƒ‰ê³¼ ë‹µë³€ ìƒì„± ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§\n",
    "- ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ë‹µë³€ ìƒì„± ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://localhost:6333/collections/arxiv_physics_muon_paper/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\n",
      "âœ… 10ê°œì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\n",
      "ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¬¸ì„œì— ë”°ë¥´ë©´, HLbLì˜ ë¶ˆí™•ì‹¤ì„±ì´ 2020 WP(WP20) ëŒ€ë¹„ ì•½ ë‘ ë°° ê°ì†Œí–ˆìŠµë‹ˆë‹¤. 2020 WP20ì˜ ê²°ê³¼ëŠ” 92(19) Ã— 10 -11 ì˜€ì§€ë§Œ, ìƒˆë¡œìš´ ì¸¡ì • ê²°ê³¼ë“¤ì´ ë°œí‘œë˜ë©´ì„œ í˜„ì¬ì˜ ì„¸ê³„ í‰ê· ê°’ì€ ì´ë³´ë‹¤ í›¨ì”¬ ë” ì •ë°€í•´ì¡ŒìŠµë‹ˆë‹¤. íŠ¹íˆ, 2021ë…„ì— ë°œí‘œëœ Fermilab g-2 ì‹¤í—˜ ê²°ê³¼(460 ppb)ì™€ 2023ë…„ì— ë°œí‘œëœ ê²°ê³¼(200 ppb)ëŠ” ì´ì „ ê²°ê³¼ë³´ë‹¤ í›¨ì”¬ ë” ë†’ì€ ì •ë°€ë„ë¥¼ ì œê³µí•˜ë©°, ì´ë¡œ ì¸í•´ HLbLì˜ ë¶ˆí™•ì‹¤ì„±ì´ í¬ê²Œ ê°œì„ ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, J-PARC ì‹¤í—˜ë„ ì¤€ë¹„ ì¤‘ì´ë©°, ì´ ì‹¤í—˜ ê²°ê³¼ ë˜í•œ ìµœì¢…ì ìœ¼ë¡œ ì„¸ê³„ í‰ê· ê°’ì˜ ì‹ ë¢°ë„ë¥¼ ë†’ì¼ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\n",
      "âœ… ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "question = \"HLbL ë¶ˆí™•ì‹¤ì„±ì´ 2020 WP ëŒ€ë¹„ ì–¼ë§ˆë‚˜ ì¤„ì—ˆëŠ”ê°€?\"\n",
    "initial_state = {\"question\": question, \"documents\": [], \"answer\": \"\"}\n",
    "result=[]\n",
    "for chunk, metadata in rag_app.stream(initial_state, stream_mode=\"messages\"):\n",
    "    if chunk.content:\n",
    "        result.append(chunk)\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ¯ RAG ì‹œìŠ¤í…œ ì™„ì„±\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ ì™„ì „í•œ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. **ğŸ“„ PDF ì²˜ë¦¬**: Doclingì„ í†µí•œ ê³ í’ˆì§ˆ ë¬¸ì„œ ë³€í™˜\n",
    "2. **ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬**: VLMì„ í™œìš©í•œ ìë™ ìº¡ì…˜ ìƒì„±\n",
    "3. **ğŸ“š ë¬¸ì„œ ë¶„í• **: ì˜ë¯¸ ìˆëŠ” ì²­í¬ ë‹¨ìœ„ë¡œ ë¶„í• \n",
    "4. **ğŸ—„ï¸ ë²¡í„° DB**: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•œ Qdrant ì„¤ì •\n",
    "5. **ğŸ¤– QA ì‹œìŠ¤í…œ**: LangGraph ê¸°ë°˜ ì²´ê³„ì  ë‹µë³€ ìƒì„±\n",
    "\n",
    "ì´ì œ arXiv ë…¼ë¬¸ì— ëŒ€í•œ ì •í™•í•˜ê³  ìƒì„¸í•œ ì§ˆë¬¸-ë‹µë³€ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
