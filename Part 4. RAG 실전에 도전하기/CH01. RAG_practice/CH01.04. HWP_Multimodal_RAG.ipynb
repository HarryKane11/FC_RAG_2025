{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### ğŸ“‹ HWP RAG ì‹œìŠ¤í…œ êµ¬ì¶• í”„ë¡œì íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” HWP(í•œê¸€) ë¬¸ì„œë¥¼ PDFë¡œ ë³€í™˜í•˜ê³ , AI ê¸°ë°˜ ë¬¸ì„œ ë¶„ì„ì„ í†µí•´ RAG(Retrieval-Augmented Generation) ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¤ë£¹ë‹ˆë‹¤.\n",
    "\n",
    "#### ğŸ”§ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "HWP íŒŒì¼ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ í•„ìš”í•œ `olefile` íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install olefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ“„ HWP â†’ PDF ì¼ê´„ ë³€í™˜\n",
    "Windows COM ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ HWP íŒŒì¼ë“¤ì„ PDF í˜•ì‹ìœ¼ë¡œ ì¼ê´„ ë³€í™˜í•©ë‹ˆë‹¤. í•œê¸€ í”„ë¡œê·¸ë¨ì´ ì„¤ì¹˜ëœ Windows í™˜ê²½ì—ì„œë§Œ ì‘ë™í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import win32com.client as win32\n",
    "\n",
    "def hwp_to_pdf_batch(folder: str, out_dir: str):\n",
    "    folder = Path(folder).resolve()\n",
    "    out_dir = Path(out_dir).resolve()\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    hwp = win32.gencache.EnsureDispatch(\"HWPFrame.HwpObject\")\n",
    "    hwp.RegisterModule(\"FilePathCheckDLL\", \"FilePathCheckerModule\")\n",
    "\n",
    "    for hwp_file in folder.glob(\"*.hwp\"):\n",
    "        try:\n",
    "            hwp.Open(str(hwp_file))\n",
    "        except Exception as e:\n",
    "            print(\"âœ– ì—´ê¸° ì‹¤íŒ¨:\", hwp_file.name, e)\n",
    "            continue\n",
    "\n",
    "        pdf_path = out_dir / f\"{hwp_file.stem}.pdf\"\n",
    "        hwp.SaveAs(str(pdf_path), \"PDF\", \"\")\n",
    "        hwp.Run(\"FileClose\")          # â† í•µì‹¬ ë³€ê²½: ë¬¸ì„œ ë‹«ê¸°\n",
    "        print(\"âœ”\", pdf_path.name)\n",
    "\n",
    "    hwp.Quit()\n",
    "\n",
    "hwp_to_pdf_batch(\"./data\", \"./data/pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ¤– Doclingì„ ì´ìš©í•œ ê³ ê¸‰ PDF ì²˜ë¦¬\n",
    "Docling ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ PDF ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜í•˜ê³ , ì´ë¯¸ì§€ì™€ í‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤. ê³ í’ˆì§ˆ ë¬¸ì„œ íŒŒì‹±ê³¼ êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash 4bba35b4916b4b6fae4b5936f7e9e6a2\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered ocr engines: ['easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.models.factories.base_factory:Loading plugin 'docling_defaults'\n",
      "INFO:docling.models.factories:Registered picture descriptions: ['vlm', 'api']\n",
      "INFO:docling.pipeline.base_pipeline:Processing document proposal_request_2025_ai_economic_policy_service.pdf\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# PDF ë¬¸ì„œ ë³€í™˜ ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m conv_res \u001b[38;5;241m=\u001b[39m doc_converter\u001b[38;5;241m.\u001b[39mconvert(input_doc_path)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:39\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\pydantic\\_internal\\_validate_call.py:136\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_complete__:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_validators()\n\u001b[1;32m--> 136\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(pydantic_core\u001b[38;5;241m.\u001b[39mArgsKwargs(args, kwargs))\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\document_converter.py:222\u001b[0m, in \u001b[0;36mDocumentConverter.convert\u001b[1;34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;129m@validate_call\u001b[39m(config\u001b[38;5;241m=\u001b[39mConfigDict(strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    212\u001b[0m     page_range: PageRange \u001b[38;5;241m=\u001b[39m DEFAULT_PAGE_RANGE,\n\u001b[0;32m    213\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ConversionResult:\n\u001b[0;32m    214\u001b[0m     all_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_all(\n\u001b[0;32m    215\u001b[0m         source\u001b[38;5;241m=\u001b[39m[source],\n\u001b[0;32m    216\u001b[0m         raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m         page_range\u001b[38;5;241m=\u001b[39mpage_range,\n\u001b[0;32m    221\u001b[0m     )\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(all_res)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\document_converter.py:245\u001b[0m, in \u001b[0;36mDocumentConverter.convert_all\u001b[1;34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[0m\n\u001b[0;32m    242\u001b[0m conv_res_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert(conv_input, raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error)\n\u001b[0;32m    244\u001b[0m had_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 245\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conv_res \u001b[38;5;129;01min\u001b[39;00m conv_res_iter:\n\u001b[0;32m    246\u001b[0m     had_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error \u001b[38;5;129;01mand\u001b[39;00m conv_res\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m    248\u001b[0m         ConversionStatus\u001b[38;5;241m.\u001b[39mSUCCESS,\n\u001b[0;32m    249\u001b[0m         ConversionStatus\u001b[38;5;241m.\u001b[39mPARTIAL_SUCCESS,\n\u001b[0;32m    250\u001b[0m     }:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\document_converter.py:280\u001b[0m, in \u001b[0;36mDocumentConverter._convert\u001b[1;34m(self, conv_input, raises_on_error)\u001b[0m\n\u001b[0;32m    271\u001b[0m _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoing to convert document batch...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(\n\u001b[0;32m    281\u001b[0m     partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_document, raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error),\n\u001b[0;32m    282\u001b[0m     input_batch,\n\u001b[0;32m    283\u001b[0m ):\n\u001b[0;32m    284\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m    285\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\document_converter.py:326\u001b[0m, in \u001b[0;36mDocumentConverter._process_document\u001b[1;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[0;32m    322\u001b[0m valid \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mallowed_formats\n\u001b[0;32m    324\u001b[0m )\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[1;32m--> 326\u001b[0m     conv_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_pipeline(in_doc, raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    328\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc\u001b[38;5;241m.\u001b[39mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\document_converter.py:349\u001b[0m, in \u001b[0;36mDocumentConverter._execute_pipeline\u001b[1;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[0;32m    347\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pipeline(in_doc\u001b[38;5;241m.\u001b[39mformat)\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 349\u001b[0m     conv_res \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mexecute(in_doc, raises_on_error\u001b[38;5;241m=\u001b[39mraises_on_error)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raises_on_error:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:46\u001b[0m, in \u001b[0;36mBasePipeline.execute\u001b[1;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TimeRecorder(\n\u001b[0;32m     42\u001b[0m         conv_res, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_total\u001b[39m\u001b[38;5;124m\"\u001b[39m, scope\u001b[38;5;241m=\u001b[39mProfilingScope\u001b[38;5;241m.\u001b[39mDOCUMENT\n\u001b[0;32m     43\u001b[0m     ):\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;66;03m# These steps are building and assembling the structure of the\u001b[39;00m\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;66;03m# output DoclingDocument.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m         conv_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_document(conv_res)\n\u001b[0;32m     47\u001b[0m         conv_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_document(conv_res)\n\u001b[0;32m     48\u001b[0m         \u001b[38;5;66;03m# From this stage, all operations should rely only on conv_res.output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:160\u001b[0m, in \u001b[0;36mPaginatedPipeline._build_document\u001b[1;34m(self, conv_res)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# 2. Run pipeline stages\u001b[39;00m\n\u001b[0;32m    158\u001b[0m pipeline_pages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_on_pages(conv_res, init_pages)\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pipeline_pages:  \u001b[38;5;66;03m# Must exhaust!\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# Cleanup cached images\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_images:\n\u001b[0;32m    163\u001b[0m         p\u001b[38;5;241m.\u001b[39m_image_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\pipeline\\base_pipeline.py:126\u001b[0m, in \u001b[0;36mPaginatedPipeline._apply_on_pages\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_pipe:\n\u001b[0;32m    124\u001b[0m     page_batch \u001b[38;5;241m=\u001b[39m model(conv_res, page_batch)\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m page_batch\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\models\\page_assemble_model.py:70\u001b[0m, in \u001b[0;36mPageAssembleModel.__call__\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m, conv_res: ConversionResult, page_batch: Iterable[Page]\n\u001b[0;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Page]:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m page_batch:\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m page\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m page\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mis_valid():\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling\\models\\table_structure_model.py:254\u001b[0m, in \u001b[0;36mTableStructureModel.__call__\u001b[1;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[0;32m    245\u001b[0m         tokens\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    246\u001b[0m             {\n\u001b[0;32m    247\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: new_cell\u001b[38;5;241m.\u001b[39mindex,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    250\u001b[0m             }\n\u001b[0;32m    251\u001b[0m         )\n\u001b[0;32m    252\u001b[0m page_input[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokens\n\u001b[1;32m--> 254\u001b[0m tf_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_predictor\u001b[38;5;241m.\u001b[39mmulti_table_predict(\n\u001b[0;32m    255\u001b[0m     page_input, [tbl_box], do_matching\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_cell_matching\n\u001b[0;32m    256\u001b[0m )\n\u001b[0;32m    257\u001b[0m table_out \u001b[38;5;241m=\u001b[39m tf_output[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    258\u001b[0m table_cells \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling_ibm_models\\tableformer\\data_management\\tf_predictor.py:485\u001b[0m, in \u001b[0;36mTFPredictor.multi_table_predict\u001b[1;34m(self, iocr_page, table_bboxes, do_matching, correct_overlapping_cells, sort_row_col_indexes)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# table_image = page_image\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_matching:\n\u001b[1;32m--> 485\u001b[0m     tf_responses, predict_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m    486\u001b[0m         iocr_page,\n\u001b[0;32m    487\u001b[0m         table_bbox,\n\u001b[0;32m    488\u001b[0m         table_image,\n\u001b[0;32m    489\u001b[0m         scale_factor,\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    491\u001b[0m         correct_overlapping_cells,\n\u001b[0;32m    492\u001b[0m     )\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    494\u001b[0m     tf_responses, predict_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_dummy(\n\u001b[0;32m    495\u001b[0m         iocr_page, table_bbox, table_image, scale_factor, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    496\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling_ibm_models\\tableformer\\data_management\\tf_predictor.py:815\u001b[0m, in \u001b[0;36mTFPredictor.predict\u001b[1;34m(self, iocr_page, table_bbox, table_image, scale_factor, eval_res_preds, correct_overlapping_cells)\u001b[0m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable_post_process:\n\u001b[0;32m    814\u001b[0m             AggProfiler()\u001b[38;5;241m.\u001b[39mbegin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_process\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prof)\n\u001b[1;32m--> 815\u001b[0m             matching_details \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_processor\u001b[38;5;241m.\u001b[39mprocess(\n\u001b[0;32m    816\u001b[0m                 matching_details, correct_overlapping_cells\n\u001b[0;32m    817\u001b[0m             )\n\u001b[0;32m    818\u001b[0m             AggProfiler()\u001b[38;5;241m.\u001b[39mend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_process\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prof)\n\u001b[0;32m    820\u001b[0m \u001b[38;5;66;03m# Generate the expected Docling responses\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling_ibm_models\\tableformer\\data_management\\matching_post_processor.py:1353\u001b[0m, in \u001b[0;36mMatchingPostProcessor.process\u001b[1;34m(self, matching_details, correct_overlapping_cells)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     aligned_table_cells2 \u001b[38;5;241m=\u001b[39m dedupl_table_cells_sorted\n\u001b[0;32m   1352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1353\u001b[0m     aligned_table_cells2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_table_cells_to_pdf(\n\u001b[0;32m   1354\u001b[0m         dedupl_table_cells_sorted, pdf_cells, final_matches\n\u001b[0;32m   1355\u001b[0m     )\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;66;03m# 9. Distance-match orphans\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m po1, po2, po3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pick_orphan_cells(\n\u001b[0;32m   1359\u001b[0m     tab_rows,\n\u001b[0;32m   1360\u001b[0m     tab_columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     final_matches,\n\u001b[0;32m   1365\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\test_venv\\Lib\\site-packages\\docling_ibm_models\\tableformer\\data_management\\matching_post_processor.py\u001b[0m, in \u001b[0;36mMatchingPostProcessor._align_table_cells_to_pdf\u001b[1;34m(self, table_cells, pdf_cells, matches)\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "from pathlib import Path\n",
    "from docling_core.types.doc import ImageRefMode, PictureItem, TableItem\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "# ë¡œê¹… ì„¤ì • - INFO ë ˆë²¨ë¡œ ë³€í™˜ ê³¼ì •ì„ ëª¨ë‹ˆí„°ë§\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "_log = logging.getLogger(__name__)\n",
    "\n",
    "# ì…ë ¥ PDF íŒŒì¼ ê²½ë¡œì™€ ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "input_doc_path = Path(\"data/pdf/proposal_request_2025_ai_economic_policy_service.pdf\")\n",
    "output_dir = Path(\"data/pdf/output\")\n",
    "\n",
    "# PDF íŒŒì´í”„ë¼ì¸ ì˜µì…˜ êµ¬ì„±\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.images_scale = 2.0  # ì´ë¯¸ì§€ í•´ìƒë„ ìŠ¤ì¼€ì¼ ì„¤ì •\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "# ë¬¸ì„œ ë³€í™˜ê¸° ì´ˆê¸°í™” - PDF í˜•ì‹ ì˜µì…˜ê³¼ í•¨ê»˜ ì„¤ì •\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# ë³€í™˜ ì‹œì‘ ì‹œê°„ ê¸°ë¡\n",
    "start_time = time.time()\n",
    "\n",
    "# PDF ë¬¸ì„œ ë³€í™˜ ì‹¤í–‰\n",
    "conv_res = doc_converter.convert(input_doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "#### ğŸ’¾ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥ ë° ë³€í™˜ ì™„ë£Œ\n",
    "ë³€í™˜ëœ ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê³  ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ í¬í•¨í•œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„± (ë¶€ëª¨ ë””ë ‰í† ë¦¬ë„ í•¨ê»˜ ìƒì„±)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "doc_filename = conv_res.input.file.stem\n",
    "\n",
    "# ì´ë¯¸ì§€ ì°¸ì¡°ê°€ í¬í•¨ëœ ì „ì²´ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥\n",
    "md_filename_with_refs = output_dir / f\"{doc_filename}-with-image-refs.md\"\n",
    "conv_res.document.save_as_markdown(md_filename_with_refs, image_mode=ImageRefMode.REFERENCED)\n",
    "\n",
    "# ë³€í™˜ ì™„ë£Œ ì‹œê°„ ê³„ì‚°\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "# ë³€í™˜ ì™„ë£Œ ë¡œê·¸ ì¶œë ¥\n",
    "_log.info(f\"Document converted and figures exported in {end_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ–¼ï¸ AI ê¸°ë°˜ ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±\n",
    "Gemini 2.5 Flash ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì¶”ì¶œëœ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•œ ìë™ ìº¡ì…˜ì„ ìƒì„±í•˜ê³ , ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì˜ ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ í…ìŠ¤íŠ¸ ì„¤ëª…ìœ¼ë¡œ êµì²´í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import glob\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-05-20\")\n",
    "\n",
    "# ì´ë¯¸ì§€ í´ë”ì—ì„œ PNG íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°\n",
    "image_folder = \"data/pdf/output/proposal_request_2025_ai_economic_policy_service-with-image-refs_artifacts/\"\n",
    "image_paths = glob.glob(f\"{image_folder}*.png\")\n",
    "\n",
    "# ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±\n",
    "messages_batch = []\n",
    "image_filenames = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    \n",
    "    message = HumanMessage(content=[\n",
    "        {\"type\": \"text\", \"text\": \"ì´ ì´ë¯¸ì§€ë¥¼ í•œê¸€ë¡œ ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”. í‘œë‚˜ ì°¨íŠ¸ì˜ ê²½ìš° ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{encoded_image}\"}\n",
    "    ])\n",
    "    \n",
    "    messages_batch.append([message])\n",
    "    image_filenames.append(Path(image_path).name)\n",
    "\n",
    "# ë°°ì¹˜ ì²˜ë¦¬ë¡œ ëª¨ë“  ì´ë¯¸ì§€ ì„¤ëª… ìƒì„±\n",
    "print(\"ì´ë¯¸ì§€ ì„¤ëª… ìƒì„± ì¤‘...\")\n",
    "batch_results = llm.batch(messages_batch)\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ëª…ê³¼ ì„¤ëª…ì„ ë§¤í•‘\n",
    "image_descriptions = {}\n",
    "for filename, result in zip(image_filenames, batch_results):\n",
    "    image_descriptions[filename] = result.content\n",
    "    print(f\"{filename}: {result.content}\\n\")\n",
    "\n",
    "# ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì½ê¸°\n",
    "with open(md_filename_with_refs, 'r', encoding='utf-8') as f:\n",
    "    markdown_content = f.read()\n",
    "\n",
    "# ì´ë¯¸ì§€ ì°¸ì¡°ë¥¼ ìº¡ì…˜ìœ¼ë¡œ êµì²´\n",
    "def replace_image_with_caption(match):\n",
    "    full_path = match.group(1)  # ì „ì²´ ê²½ë¡œ ì¶”ì¶œ\n",
    "    image_filename = Path(full_path).name  # íŒŒì¼ëª…ë§Œ ì¶”ì¶œ\n",
    "    if image_filename in image_descriptions:\n",
    "        caption = image_descriptions[image_filename]\n",
    "        return f\"\\n**[ì´ë¯¸ì§€ ì„¤ëª…]** {caption}\\n\"\n",
    "    return match.group(0)  # ì„¤ëª…ì´ ì—†ìœ¼ë©´ ì›ë³¸ ìœ ì§€\n",
    "\n",
    "# ì´ë¯¸ì§€ ì°¸ì¡° íŒ¨í„´ ì°¾ê¸° ë° êµì²´ (ë°±ìŠ¬ë˜ì‹œì™€ ìŠ¬ë˜ì‹œ ëª¨ë‘ ì²˜ë¦¬)\n",
    "image_pattern = r'!\\[.*?\\]\\(([^)]+\\.png)\\)'\n",
    "updated_markdown = re.sub(image_pattern, replace_image_with_caption, markdown_content)\n",
    "\n",
    "# ìº¡ì…˜ì´ í¬í•¨ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥\n",
    "md_filename_with_captions = output_dir / f\"{doc_filename}-with-captions.md\"\n",
    "with open(md_filename_with_captions, 'w', encoding='utf-8') as f:\n",
    "    f.write(updated_markdown)\n",
    "\n",
    "print(f\"ìº¡ì…˜ì´ í¬í•¨ëœ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {md_filename_with_captions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=3000,\n",
    "    chunk_overlap=500,\n",
    "    separators=[\"##\\n\",\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# ìº¡ì…˜ì´ ì ìš©ëœ íŒŒì¼ ë‚´ìš© ì½ê¸°\n",
    "with open(md_filename_with_captions, 'r', encoding='utf-8') as f:\n",
    "    captioned_content = f.read()\n",
    "\n",
    "# Document ê°ì²´ë¡œ ìƒì„±\n",
    "document = Document(page_content=captioned_content, metadata={\"source\": str(md_filename_with_captions)})\n",
    "\n",
    "# split_documentsë¥¼ ì‚¬ìš©í•˜ì—¬ Document ê°ì²´ë“¤ë¡œ ë¶„í• \n",
    "splits = text_splitter.split_documents([document])\n",
    "\n",
    "# splits ê¸¸ì´ ë¶„í¬ íŒŒì•…\n",
    "split_lengths = [len(split.page_content) for split in splits]\n",
    "print(f\"ì´ ë¶„í• ëœ ì²­í¬ ìˆ˜: {len(splits)}\")\n",
    "print(f\"í‰ê·  ì²­í¬ ê¸¸ì´: {sum(split_lengths) / len(split_lengths):.1f} ë¬¸ì\")\n",
    "print(f\"ìµœì†Œ ì²­í¬ ê¸¸ì´: {min(split_lengths)} ë¬¸ì\")\n",
    "print(f\"ìµœëŒ€ ì²­í¬ ê¸¸ì´: {max(split_lengths)} ë¬¸ì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ—„ï¸ Qdrant ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •\n",
    "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì„ ìœ„í•´ Dense ì„ë² ë”©(BGE-M3)ê³¼ Sparse ì„ë² ë”©(BM25)ì„ í•¨ê»˜ ì‚¬ìš©í•˜ëŠ” Qdrant ë²¡í„° ìŠ¤í† ì–´ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_qdrant import FastEmbedSparse, QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import Distance, SparseVectorParams, VectorParams\n",
    "\n",
    "# Qdrant í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "client = QdrantClient(host=\"localhost\", port=6333)\n",
    "\n",
    "dense_embeddings = OllamaEmbeddings(model=\"bge-m3\")\n",
    "sparse_embeddings = FastEmbedSparse(model_name=\"Qdrant/bm25\")\n",
    "\n",
    "# ì»¬ë ‰ì…˜ ì´ë¦„ ì„¤ì •\n",
    "collection_name = f\"hwp_rag\"\n",
    "try:\n",
    "    client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={\"dense\": VectorParams(size=1024, distance=Distance.COSINE)},\n",
    "        sparse_vectors_config={\n",
    "            \"sparse\": SparseVectorParams(index=models.SparseIndexParams(on_disk=False))\n",
    "        },\n",
    "    )\n",
    "    print(f\"ìƒˆ ì»¬ë ‰ì…˜ '{collection_name}' ìƒì„±ë¨\")\n",
    "    qdrant = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=dense_embeddings,\n",
    "        sparse_embedding=sparse_embeddings,\n",
    "        retrieval_mode=RetrievalMode.HYBRID,\n",
    "        vector_name=\"dense\",\n",
    "        sparse_vector_name=\"sparse\",\n",
    "    )\n",
    "\n",
    "    # ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€\n",
    "    print(\"ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€ ì¤‘...\")\n",
    "    qdrant.add_documents(splits)\n",
    "    print(f\"âœ… {len(splits)}ê°œì˜ ë¬¸ì„œê°€ Qdrantì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "except:\n",
    "    qdrant = QdrantVectorStore(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embedding=dense_embeddings,\n",
    "        sparse_embedding=sparse_embeddings,\n",
    "        retrieval_mode=RetrievalMode.HYBRID,\n",
    "        vector_name=\"dense\",\n",
    "        sparse_vector_name=\"sparse\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ¯ ë¦¬ë­ì»¤ ê¸°ë°˜ ê²€ìƒ‰ í’ˆì§ˆ í–¥ìƒ\n",
    "BGE-Reranker-v2-M3 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¬ìˆœìœ„í™”í•˜ê³ , ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ë¬¸ì„œë“¤ë§Œ ì„ ë³„í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "\n",
    "retriever = qdrant.as_retriever(\n",
    "    search_kwargs={\"k\": 10}\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-v2-m3\")\n",
    "\n",
    "# ìƒìœ„ ê°œì˜ ë¬¸ì„œ ì„ íƒ\n",
    "compressor = CrossEncoderReranker(model=model, top_n=5)\n",
    "\n",
    "# ë¬¸ì„œ ì••ì¶• ê²€ìƒ‰ê¸° ì´ˆê¸°í™”\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_search_results(docs, title):\n",
    "    \"\"\"ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì´ì˜ê²Œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    print(f\"{title}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}ê°œ\\n\")\n",
    "    \n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"ğŸ“„ ë¬¸ì„œ {i}\")\n",
    "        print(f\"ğŸ“‚ ì¶œì²˜: {doc.metadata.get('source', 'N/A')}\")\n",
    "        print(f\"ğŸ“ƒ í˜ì´ì§€: {doc.metadata.get(' page', 'N/A')}\")\n",
    "        print(f\"ğŸ“ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "        print(doc.page_content)\n",
    "        print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "query = \"AI ê¸°ë°˜ ê²½ì œì •ì±…ì •ë³´ ì œê³µ ì„œë¹„ìŠ¤ì˜ êµ¬ì¡°ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”\"\n",
    "\n",
    "# ê¸°ë³¸ retriever ê²€ìƒ‰\n",
    "basic_docs = retriever.invoke(query)\n",
    "print_search_results(basic_docs, \"ğŸ” ê¸°ë³¸ Retriever ê²€ìƒ‰ ê²°ê³¼:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reranker ì ìš©ëœ ê²€ìƒ‰\n",
    "compressed_docs = compression_retriever.invoke(query)\n",
    "print_search_results(compressed_docs, \"ğŸ¯ Reranker ì ìš©ëœ ê²€ìƒ‰ ê²°ê³¼:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# State ì •ì˜\n",
    "class RAGState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# LLM ì´ˆê¸°í™”\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# RAG í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "rag_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "ë‹¤ìŒ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "ë¬¸ì„œë“¤:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "\n",
    "ë‹µë³€ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ê³ , ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”.\n",
    "ë‹µë³€:\n",
    "\"\"\")\n",
    "\n",
    "def retrieve_documents(state: RAGState) -> RAGState:\n",
    "    \"\"\"ë¬¸ì„œ ê²€ìƒ‰ ë‹¨ê³„\"\"\"\n",
    "    print(\"ğŸ“š ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...\")\n",
    "    question = state[\"question\"]\n",
    "    documents = compression_retriever.invoke(question)\n",
    "    print(f\"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œë¥¼ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"answer\": \"\"\n",
    "    }\n",
    "\n",
    "def generate_answer(state: RAGState) -> RAGState:\n",
    "    \"\"\"ë‹µë³€ ìƒì„± ë‹¨ê³„\"\"\"\n",
    "    print(\"ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # ë¬¸ì„œ ë‚´ìš©ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ê²°í•©\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "    \n",
    "    # LLM ì²´ì¸ êµ¬ì„±\n",
    "    chain = rag_prompt | llm | StrOutputParser()\n",
    "    \n",
    "    # ë‹µë³€ ìƒì„±\n",
    "    answer = chain.invoke({\n",
    "        \"context\": context,\n",
    "        \"question\": question\n",
    "    })\n",
    "    \n",
    "    print(\"âœ… ë‹µë³€ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"documents\": documents,\n",
    "        \"answer\": answer\n",
    "    }\n",
    "\n",
    "# LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "workflow = StateGraph(RAGState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "workflow.set_entry_point(\"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "rag_app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"/no_think ì…ì°°ê°€ê²© í‰ê°€ëŠ” ì–´ë–»ê²Œ ì´ë¤„ì§€ë‚˜ìš”?\"\n",
    "initial_state = {\"question\": question, \"documents\": [], \"answer\": \"\"}\n",
    "\n",
    "for chunk, metadata in rag_app.stream(initial_state, stream_mode=\"messages\"):\n",
    "    if chunk.content:\n",
    "        print(chunk.content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
