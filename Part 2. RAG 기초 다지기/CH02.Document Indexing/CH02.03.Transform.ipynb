{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation\n",
    "## 📚 강의 개요 (Overview)\n",
    "\n",
    "이 강의에서는 RAG(Retrieval-Augmented Generation) 파이프라인에서 중요한 전처리 과정인 ‘Transformation’을 다룹니다. 여기서 ‘Transformation’은 단순한 스케일링이나 정규화 같은 전통적 의미의 데이터 변환이 아니라, 질의응답(Question-Answering) 및 생성(Generation)을 효과적으로 수행하기 위해 텍스트를 다양한 기준으로 나누는(Chunking) 과정을 의미합니다.\n",
    "\n",
    "RAG 모델은 대용량 텍스트 데이터에서 필요한 정보를 검색(Retrieval)한 뒤, 검색된 결과를 입력으로 하여 응답(Generation)을 생성하는 구조입니다. 이때, 문서(또는 여러 형태의 텍스트)를 어떻게 분할(Chunking)하고, 어떤 임베딩을 사용해 의미를 추출하느냐가 모델 성능에 큰 영향을 미칩니다.\n",
    "\n",
    "이 강의에서는 다음과 같은 Transformation(Chunking) 방법을 소개하며, 각각의 사용 용도와 장단점을 살펴봅니다:\n",
    "\n",
    "## 목차: \n",
    "* [CharacterTextSplitter청킹](#charactertextsplitter-청킹)\n",
    "* [RecursiveCharacterTextSplitter청킹](#recursivecharactertextsplitter-청킹)\n",
    "* [코드 청킹](#코드-청킹)\n",
    "* [마크다운 문서 청킹](#마크다운-문서-청킹)\n",
    "* [시맨틱 청킹](#시맨틱-청킹)\n",
    "* [오픈소스 임베딩 모델을 활용한 시맨틱 청킹](#오픈소스-임베딩-모델을-활용한-시맨틱-청킹)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경변수 설정하기 (.env 파일을 사용하지 않을 경우 여기에 입력해주세요!)\n",
    "import os\n",
    "\n",
    "# 환경변수 설정\n",
    "os.environ[\"API_KEY\"] = \"sk-...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -qU langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter 청킹\n",
    "텍스트를 일정 길이(캐릭터 수) 단위로 분할하는 가장 단순한 접근 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF 파일 경로 설정\n",
    "file_path = \"data/arxiv_paper.pdf\"\n",
    "\n",
    "# LangChain의 PyPDFLoader를 이용해 PDF 파일을 로드\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 객체 생성\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# PDF의 각 페이지를 저장할 리스트\n",
    "pages = []\n",
    "\n",
    "# 비동기 방식으로 PDF 페이지를 로드 (async for 사용)\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n",
      "along with Execution Policies, which enhance\n",
      "confidence calibration through scenario reinter-\n",
      "pretation, action sampling, and hypothetical rea-\n",
      "soning. Evaluating agents in calibration and fail-\n",
      "ure prediction tasks within the Minecraft envi-\n",
      "ronment, we show that structured reasoning ap-\n",
      "proaches, such as Chain-of-Thoughts, improve\n",
      "confidence calibration. However, our findings\n",
      "also reveal persistent challenges in distinguishing\n",
      "uncertainty, particularly under abductive settings,\n",
      "underscoring the need for more sophisticated em-\n",
      "bodied confidence elicitation methods.\n",
      "1. Introduction\n",
      "In complex embodied environments, success depends not\n",
      "only on what an agent knows but also on how well it un-\n",
      "derstands and communicates uncertainty. Whether navi-\n",
      "gating a cluttered space, interacting with objects, or plan-\n",
      "ning long-term strategies, eliciting confidence is pivotal as\n",
      "agents must interpret and interact with dynamic settings\n",
      "in real-time while managing uncertainty from both percep-\n",
      "tion and decision-making processes (Ren et al., 2023; Liang\n",
      "et al., 2024). For humans, this instinctive ability to express\n",
      "and calibrate uncertainty is fundamental to decision-making\n",
      "and social interaction. As AI systems are increasingly de-\n",
      "ployed in high-stakes contexts such as autonomous driving\n",
      "or healthcare, they must also acquire this crucial skill.\n",
      "*Preprint. Work in progress.\n",
      "Embodied Environment\n",
      "Elicitation Module\n",
      "Are you sure about yournext action?\n",
      "Elicitation Module\n",
      "Are you sure aboutwhat you see?\n",
      "Elicitation\n",
      "Policies\n",
      "Execution\n",
      "Policies\n",
      "Elicitation\n",
      "Policies\n",
      "Execution\n",
      "Policies\n",
      "Perception Stage\n",
      "Action Stage\n",
      "Figure 1.Embodied Confidence Estimation Framework consist-\n",
      "ing of Elicitation Policies and Execution Policies, which jointly\n",
      "enable an agent to assess and express its confidence. Elicitation\n",
      "Modules prompt the agent to evaluate uncertainty in what it sees\n",
      "and does, while Execution Policies refine confidence calibration\n",
      "by expanding the agent’s reasoning space (See §3 for details).\n",
      "Specifically, accurate confidence elicitation from AI systems\n",
      "provides critical insights for risk assessment, error mitiga-\n",
      "tion, and system reliability in decision-making (Kuleshov\n",
      "& Deshpande, 2022; Clark, 2015; Yildirim et al., 2019).\n",
      "This is particularly important in open-ended reasoning tasks,\n",
      "where models may generate outputs that are semantically\n",
      "plausible but factually incorrect, a phenomenon commonly\n",
      "referred to as hallucination (Xiao & Wang, 2021). How-\n",
      "ever, confidence elicitation in embodied AI is particularly\n",
      "challenging. For instance, in open-ended environments such\n",
      "as Minecraft, an agent may misinterpret visual cues due\n",
      "to limited viewpoints or struggle to determine the correct\n",
      "action sequence to achieve complex goals (e.g., obtaining\n",
      "a diamond). These illustrate the broader difficulties in elic-\n",
      "iting confidence in embodied environments, where agents\n",
      "must navigate uncertainty at multiple levels.\n",
      "Confidence elicitation in open-ended embodied environ-\n",
      "ments faces several challenges, including: 1) Multimodal\n",
      "understanding, where the agent must assess uncertainty from\n",
      "inputs across different interconnected modalities. 2) Granu-\n",
      "larity of confidence estimation, where the agent evaluates\n",
      "confidence not only in performing specific actions (e.g., “I\n",
      "am 90% confident I can collect some wood”) but also in\n",
      "1\n",
      "arXiv:2503.10628v1  [cs.AI]  13 Mar 2025\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "understanding high-level tasks or goals ( e.g., “I am 70%\n",
      "confident I craft a wooden table”). 3) Interactive depen-\n",
      "dencies, where the agent’s actions directly influence the\n",
      "environment, which in turn affects subsequent decisions,\n",
      "requiring ongoing adjustments to confidence estimates as\n",
      "tasks progress. 4) Finally, while state-of-the-art embodied\n",
      "agents leverage proprietary Large Language Models (LLMs)\n",
      "and Vision-Language Models (VLMs) for their strong mul-\n",
      "timodal understanding and reasoning capabilities (Wang\n",
      "et al., 2023a; Qin et al., 2024; Zhu et al., 2023), these of-\n",
      "ten lack access to internal token likelihoods or probabilistic\n",
      "outputs, making traditional confidence estimation methods\n",
      "ineffective (Kumar et al., 2023; Chen et al., 2024b).\n",
      "To address these challenges, we present the first system-\n",
      "atic approach that enables LLM/VLM-powered embodied\n",
      "agents to assess and articulate their confidence across multi-\n",
      "modal inputs, multiple granularities, and dynamic embodied\n",
      "environments. Our contributions are as follows: (1) We\n",
      "propose a framework for embodied verbalized confidence\n",
      "elicitation in multimodal open-ended environments. (2) As\n",
      "illustrated in Figure 1, we introduce Elicitation and Execu-\n",
      "tion Policies to enhance confidence estimation in embodied\n",
      "settings. Elicitation Policies target different types of un-\n",
      "certainties arising from inductive, deductive, and abductive\n",
      "reasoning, while also facilitating multi-granular confidence\n",
      "estimation, allowing agents to assess uncertainty at both\n",
      "perception and action stages. Execution Policies improve\n",
      "robust elicitation across diverse scenarios, plans, and actions\n",
      "while tackling interactive dependencies by incorporating ad-\n",
      "ditional information about the environment and expanding\n",
      "potential action trajectories. (3) We provide the first struc-\n",
      "tured analysis of embodied uncertainty and identify effective\n",
      "methods for improving confidence calibration and failure\n",
      "prediction, while also pinpointing persistent challenges.\n",
      "The following are key observations from our analysis:\n",
      "(1) Elicitation Policies are Effective But Vary by Context:\n",
      "While all proposed elicitation policies improve confidence\n",
      "calibration and failure prediction, their effectiveness varies\n",
      "based on task complexity and uncertainty type, highlighting\n",
      "the need for adaptive strategies that align with the embodied\n",
      "agent’s reasoning process and environment demands.\n",
      "(2) Execution Policies Amplify Reliable Embodied Con-\n",
      "fidence Elicitation: Execution policies enhance the robust-\n",
      "ness of elicited confidence as they expand the range of avail-\n",
      "able actions and scenario interpretations, enabling agents to\n",
      "assess their confidence levels more effectively based on a\n",
      "broader set of potential outcomes.\n",
      "(3) Model Differences Persist: While all models benefit\n",
      "from the proposed policies, differences in their inherent\n",
      "reasoning and representation capabilities lead to significant\n",
      "variability in confidence calibration and task success rates,\n",
      "highlighting the importance of tailoring elicitation and exe-\n",
      "cution strategies to each model’s strengths and limitations.\n",
      "2. Related Works\n",
      "Confidence Elicitation. Confidence elicitation for tradi-\n",
      "tional machine learning is well-studied (Abdar et al., 2021;\n",
      "Gawlikowski et al., 2023). One stream of work focuses on\n",
      "unsupervised methods leveraging entropy (Malinin & Gales,\n",
      "2021), graph semantic parsing (Lin et al., 2022b), semantic\n",
      "features (Kuhn et al., 2023; Farquhar et al., 2024), and logit\n",
      "or hidden state information (Su et al., 2024; Chen et al.,\n",
      "2024a) to craft uncertainty metrics. Another explores con-\n",
      "formal prediction for tasks like part-of-speech tagging (Dey\n",
      "et al., 2022), paraphrase detection (Giovannotti & Gam-\n",
      "merman, 2021), and fact verification (Fisch et al., 2021),\n",
      "offering statistically robust coverage guarantees (Kumar\n",
      "et al., 2023; Ye et al., 2024).\n",
      "However, these solutions often require full model access,\n",
      "making them less applicable to black-box language models,\n",
      "which are increasingly prevalent in real-world applications\n",
      "(Achiam et al., 2023; Touvron et al., 2023a). Additionally,\n",
      "their free-form nature of outputs further complicates the\n",
      "application of traditional methods. As a result, alternative\n",
      "approaches have been proposed, including estimating un-\n",
      "certainty by directly querying models for confidence scores\n",
      "after generating responses (Xiong et al., 2024; Kadavath\n",
      "et al., 2022; Lin et al., 2022a; Mielke et al., 2022; Chen &\n",
      "Mueller, 2024). Despite these advancements, existing meth-\n",
      "ods are not designed for embodied tasks, where confidence\n",
      "elicitation must address the challenges of multimodal per-\n",
      "ception, hierarchical reasoning and planning across various\n",
      "open-ended tasks, as well as non-deterministic interactions.\n",
      "LLM-based Embodied Agents. With the advent of lan-\n",
      "guage models, leveraging their reasoning and planning abili-\n",
      "ties to empower embodied agents has become quintessential\n",
      "(Huang et al., 2023; Yao et al., 2023; Chen et al., 2023;\n",
      "Zhang et al., 2024a; Shinn et al., 2024; Christianos et al.,\n",
      "2023). In the meantime, Minecraft’s open-ended nature\n",
      "with its adaptable mechanics and varied challenges, makes\n",
      "it a compelling benchmark for embedding reasoning and\n",
      "planning capabilities into language model-driven embod-\n",
      "ied agents (Wang et al., 2023a;c; Zhu et al., 2023). Re-\n",
      "cent works leverage pre-trained language models to control\n",
      "agents by generating continuous operation instructions or ex-\n",
      "ecutable policies. For example, some approaches (Zhu et al.,\n",
      "2023; Wang et al., 2023c) directly utilize scene data from\n",
      "simulation platforms like MineDojo (Fan et al., 2022) and\n",
      "MineRL (Guss et al., 2019), while others (Qin et al., 2024)\n",
      "rely on Vision-Language Models (VLMs) for perception.\n",
      "However, because language models are used in various\n",
      "roles—such as planners, critics, or perceivers—errors and in-\n",
      "accuracies often arise at different process stages (Guo et al.,\n",
      "2024; Driess et al., 2023). These challenges underscore\n",
      "the need for frameworks capable of systematically identi-\n",
      "fying and localizing sources of uncertainty, which we aim\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 분할을 위한 CharacterTextSplitter 불러오기\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 텍스트 분할기 설정\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",    # 문단 단위로 분할 (두 개의 개행 문자 기준)\n",
    "    chunk_size=500,      # 하나의 청크(조각) 크기를 500자로 설정\n",
    "    chunk_overlap=200,   # 청크 간 200자 겹치게 설정 (문맥 유지 목적)\n",
    "    length_function=len, # 텍스트 길이를 측정하는 함수 (len 사용)\n",
    "    is_separator_regex=False, # separator를 정규식이 아닌 단순 문자열로 처리\n",
    ")\n",
    "\n",
    "# PDF에서 로드한 데이터를 텍스트 청크로 분할\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"{texts[0].metadata}\") # 첫 번째 청크의 메타데이터 \n",
    "print(texts[0].page_content) # 첫 번째 청크의 내용 \n",
    "print(\"-\"*100)\n",
    "print(f\"{texts[1].metadata}\") # 두 번째 청크의 메타데이터 \n",
    "print(texts[1].page_content)# 두 번째 청크의 내용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      500 이상 문장 개수: 18\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "      500 이상 문장 개수: {\n",
    "          len(\n",
    "              [i for i in texts if len(i.page_content) > 500]\n",
    "              )\n",
    "          }\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter 청킹\n",
    "\n",
    "`RecursiveCharacterTextSplitter`는 문장을 여러 계층의 구분자(예: 문단, 줄바꿈, 공백 등)를 기준으로 재귀적으로 나누는 역할을 합니다.\n",
    "\n",
    "일반적인 `CharacterTextSplitter`보다 유연하게 텍스트를 나누는 데 사용됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# RecursiveCharacterTextSplitter를 사용하여 텍스트 분할 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,       # 하나의 청크 크기를 500자로 설정\n",
    "    chunk_overlap=200,    # 청크 간 200자 겹치게 설정 (문맥 유지 목적)\n",
    "    length_function=len,  # 텍스트 길이를 측정하는 함수 (len 사용)\n",
    "    is_separator_regex=False,  # separator가 정규식이 아님을 명시\n",
    ")\n",
    "\n",
    "# PDF에서 로드한 데이터를 텍스트 청크로 분할\n",
    "texts = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f\"{texts[0].metadata}\") # 첫 번째 청크의 메타데이터 \n",
    "print(texts[0].page_content) # 첫 번째 청크의 내용\n",
    "print(\"-\"*100)\n",
    "print(f\"{texts[1].metadata}\") # 두 번째 청크의 메타데이터\n",
    "print(texts[1].page_content) # 두 번째 청크의 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      500 이상 문장 개수: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "      500 이상 문장 개수: {\n",
    "          len(\n",
    "              [i for i in texts if len(i.page_content) > 500]\n",
    "              )\n",
    "              }\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다양한 구분자를 활용한 RecursiveCharacterTextSplitter 설정\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\n",
    "        \"\\n\\n\",   # 두 개의 개행 문자 (문단 분리)\n",
    "        \"\\n\",     # 단일 개행 문자 (줄바꿈)\n",
    "        \" \",      # 공백 (단어 단위 분리)\n",
    "        \".\",      # 마침표\n",
    "        \",\",      # 쉼표\n",
    "        \"\\u200b\",  # Zero-width space (보이지 않는 공백 문자)\n",
    "        \"\\uff0c\",  # Fullwidth comma (중국어, 일본어에서 사용)\n",
    "        \"\\u3001\",  # Ideographic comma (중국어, 일본어에서 사용)\n",
    "        \"\\uff0e\",  # Fullwidth full stop (중국어, 일본어에서 사용)\n",
    "        \"\\u3002\",  # Ideographic full stop (중국어, 일본어에서 사용)\n",
    "        \"\",       # 마지막 분할 기준 (기본적으로 아무 구분자가 없을 경우)\n",
    "    ],\n",
    "    chunk_size=500,       # 기존 설정 유지\n",
    "    chunk_overlap=200,    # 기존 설정 유지\n",
    "    length_function=len,  # 기존 설정 유지\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코드 청킹\n",
    "\n",
    "코드 블록이나 함수 단위로 텍스트를 나누어, 코드 문서 처리에 특화된 청킹 기법을 다룹니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cpp', 'go', 'java', 'kotlin', 'js', 'ts', 'php', 'proto', 'python', 'rst', 'ruby', 'rust', 'scala', 'swift', 'markdown', 'latex', 'html', 'sol', 'csharp', 'cobol', 'c', 'lua', 'perl', 'haskell', 'elixir', 'powershell']\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")\n",
    "\n",
    "# 지원되는 언어 목록 출력\n",
    "print([e.value for e in Language])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python 코드에 대한 기본적인 구분자 확인\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='# Call the function\\nhello_world()')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 Python 코드\n",
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "# Call the function\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "# Python 언어에 최적화된 text splitter 생성\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,  # 사용할 언어를 Python으로 설정\n",
    "    chunk_size=50,             # 청크 크기를 50자로 설정\n",
    "    chunk_overlap=0            # 청크 간 오버랩 없음\n",
    ")\n",
    "# Python 코드 문서를 분할하여 생성\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 마크다운 문서 청킹\n",
    "\n",
    "Markdown 헤더나 문서 구조를 기준으로 텍스트를 분할하여, 문서 구조를 활용하는 방법을 살펴봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='# 🦜️🔗 LangChain'),\n",
       " Document(metadata={}, page_content='⚡ Building applications with LLMs through composability ⚡'),\n",
       " Document(metadata={}, page_content='## What is LangChain?'),\n",
       " Document(metadata={}, page_content=\"# Hopefully this code block isn't split\"),\n",
       " Document(metadata={}, page_content='LangChain is a framework for...'),\n",
       " Document(metadata={}, page_content='As an open-source project in a rapidly developing field, we'),\n",
       " Document(metadata={}, page_content='are extremely open to contributions.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "# 🦜️🔗 LangChain\n",
    "\n",
    "⚡ Building applications with LLMs through composability ⚡\n",
    "\n",
    "## What is LangChain?\n",
    "\n",
    "# Hopefully this code block isn't split\n",
    "LangChain is a framework for...\n",
    "\n",
    "As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "\"\"\"\n",
    "# LangChain의 RecursiveCharacterTextSplitter를 사용하여 Markdown 텍스트 분할\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,  # Markdown 언어 지정\n",
    "    chunk_size=60,  # 청크 크기를 60자로 설정\n",
    "    chunk_overlap=0  # 청크 간 오버랩 없음\n",
    ")\n",
    "\n",
    "# Markdown 문서를 청크로 나누기\n",
    "md_docs = md_splitter.create_documents([markdown_text])\n",
    "md_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar'}, page_content='Hi this is Jim  \\nHi this is Joe'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Bar', 'Header 3': 'Boo'}, page_content='Hi this is Lance'),\n",
       " Document(metadata={'Header 1': 'Foo', 'Header 2': 'Baz'}, page_content='Hi this is Molly')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "# Markdown 형식의 샘플 텍스트\n",
    "markdown_document = \"# Foo\\n\\n    ## Bar\\n\\nHi this is Jim\\n\\nHi this is Joe\\n\\n ### Boo \\n\\n Hi this is Lance \\n\\n ## Baz\\n\\n Hi this is Molly\"\n",
    "\n",
    "# 헤더를 기준으로 Markdown을 분할하기 위한 규칙 설정\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),   # `#`은 Header 1로 분류\n",
    "    (\"##\", \"Header 2\"),  # `##`는 Header 2로 분류\n",
    "    (\"###\", \"Header 3\"), # `###`는 Header 3로 분류\n",
    "]\n",
    "\n",
    "# 헤더 기반으로 Markdown을 분할하는 Splitter 생성\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "\n",
    "# 설정한 헤더를 기준으로 Markdown을 분할\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시맨틱 청킹\n",
    "\n",
    "텍스트의 의미(Semantic) 기반으로 청크를 생성해, 문맥적으로 연관된 내용을 하나의 청크로 묶는 접근입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --q langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n",
      "along with Execution Policies, which enhance\n",
      "confidence calibration through scenario reinter-\n",
      "pretation, action sampling, and hypothetical rea-\n",
      "soning. Evaluating agents in calibration and fail-\n",
      "ure prediction tasks within the Minecraft envi-\n",
      "ronment, we show that structured reasoning ap-\n",
      "proaches, such as Chain-of-Thoughts, improve\n",
      "confidence calibration. However, our findings\n",
      "also reveal persistent challenges in distinguishing\n",
      "uncertainty, particularly under abductive settings,\n",
      "underscoring the need for more sophisticated em-\n",
      "bodied confidence elicitation methods.\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "file_path = (\n",
    "    \"data/arxiv_paper.pdf\"\n",
    ")\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 객체 생성\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# PDF의 각 페이지를 저장할 리스트\n",
    "pages = []\n",
    "\n",
    "# 비동기 방식으로 PDF의 각 페이지를 로드 (async for 사용)\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "# SemanticChunker를 사용하여 의미 기반으로 텍스트를 분할\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "\n",
    "# 문서를 의미적 청킹(Semantic Chunking) 수행\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "# 첫 번째 청크의 내용 출력\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 60개 만큼의 문서로 청킹되었습니다.\n",
      "[1315, 786, 2014, 3140, 975, 1997, 351, 1086, 3077, 2863, 2445, 77, 1742, 3402, 495, 1021, 2477, 1700, 1395, 1979, 1610, 557, 3496, 591, 1561, 949, 433, 1544, 367, 130, 3492, 57, 235, 302, 499, 209, 204, 151, 258, 2165, 1594, 2424, 176, 463, 2, 1425, 1108, 2219, 2466, 335, 2792, 1828, 1623, 901, 120, 2044, 284, 1679, 613, 2]\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n",
      "along with Execution Policies, which enhance\n",
      "confidence calibration through scenario reinter-\n",
      "pretation, action sampling, and hypothetical rea-\n",
      "soning. Evaluating agents in calibration and fail-\n",
      "ure prediction tasks within the Minecraft envi-\n",
      "ronment, we show that structured reasoning ap-\n",
      "proaches, such as Chain-of-Thoughts, improve\n",
      "confidence calibration. However, our findings\n",
      "also reveal persistent challenges in distinguishing\n",
      "uncertainty, particularly under abductive settings,\n",
      "underscoring the need for more sophisticated em-\n",
      "bodied confidence elicitation methods.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "1. Introduction\n",
      "In complex embodied environments, success depends not\n",
      "only on what an agent knows but also on how well it un-\n",
      "derstands and communicates uncertainty. Whether navi-\n",
      "gating a cluttered space, interacting with objects, or plan-\n",
      "ning long-term strategies, eliciting confidence is pivotal as\n",
      "agents must interpret and interact with dynamic settings\n",
      "in real-time while managing uncertainty from both percep-\n",
      "tion and decision-making processes (Ren et al., 2023; Liang\n",
      "et al., 2024). For humans, this instinctive ability to express\n",
      "and calibrate uncertainty is fundamental to decision-making\n",
      "and social interaction. As AI systems are increasingly de-\n",
      "ployed in high-stakes contexts such as autonomous driving\n",
      "or healthcare, they must also acquire this crucial skill. *Preprint.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "Work in progress. Embodied Environment\n",
      "Elicitation Module\n",
      "Are you sure about yournext action? Elicitation Module\n",
      "Are you sure aboutwhat you see? Elicitation\n",
      "Policies\n",
      "Execution\n",
      "Policies\n",
      "Elicitation\n",
      "Policies\n",
      "Execution\n",
      "Policies\n",
      "Perception Stage\n",
      "Action Stage\n",
      "Figure 1.Embodied Confidence Estimation Framework consist-\n",
      "ing of Elicitation Policies and Execution Policies, which jointly\n",
      "enable an agent to assess and express its confidence. Elicitation\n",
      "Modules prompt the agent to evaluate uncertainty in what it sees\n",
      "and does, while Execution Policies refine confidence calibration\n",
      "by expanding the agent’s reasoning space (See §3 for details). Specifically, accurate confidence elicitation from AI systems\n",
      "provides critical insights for risk assessment, error mitiga-\n",
      "tion, and system reliability in decision-making (Kuleshov\n",
      "& Deshpande, 2022; Clark, 2015; Yildirim et al., 2019). This is particularly important in open-ended reasoning tasks,\n",
      "where models may generate outputs that are semantically\n",
      "plausible but factually incorrect, a phenomenon commonly\n",
      "referred to as hallucination (Xiao & Wang, 2021). How-\n",
      "ever, confidence elicitation in embodied AI is particularly\n",
      "challenging. For instance, in open-ended environments such\n",
      "as Minecraft, an agent may misinterpret visual cues due\n",
      "to limited viewpoints or struggle to determine the correct\n",
      "action sequence to achieve complex goals (e.g., obtaining\n",
      "a diamond). These illustrate the broader difficulties in elic-\n",
      "iting confidence in embodied environments, where agents\n",
      "must navigate uncertainty at multiple levels. Confidence elicitation in open-ended embodied environ-\n",
      "ments faces several challenges, including: 1) Multimodal\n",
      "understanding, where the agent must assess uncertainty from\n",
      "inputs across different interconnected modalities. 2) Granu-\n",
      "larity of confidence estimation, where the agent evaluates\n",
      "confidence not only in performing specific actions (e.g., “I\n",
      "am 90% confident I can collect some wood”) but also in\n",
      "1\n",
      "arXiv:2503.10628v1  [cs.AI]  13 Mar 2025\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "understanding high-level tasks or goals ( e.g., “I am 70%\n",
      "confident I craft a wooden table”). 3) Interactive depen-\n",
      "dencies, where the agent’s actions directly influence the\n",
      "environment, which in turn affects subsequent decisions,\n",
      "requiring ongoing adjustments to confidence estimates as\n",
      "tasks progress. 4) Finally, while state-of-the-art embodied\n",
      "agents leverage proprietary Large Language Models (LLMs)\n",
      "and Vision-Language Models (VLMs) for their strong mul-\n",
      "timodal understanding and reasoning capabilities (Wang\n",
      "et al., 2023a; Qin et al., 2024; Zhu et al., 2023), these of-\n",
      "ten lack access to internal token likelihoods or probabilistic\n",
      "outputs, making traditional confidence estimation methods\n",
      "ineffective (Kumar et al., 2023; Chen et al., 2024b). To address these challenges, we present the first system-\n",
      "atic approach that enables LLM/VLM-powered embodied\n",
      "agents to assess and articulate their confidence across multi-\n",
      "modal inputs, multiple granularities, and dynamic embodied\n",
      "environments. Our contributions are as follows: (1) We\n",
      "propose a framework for embodied verbalized confidence\n",
      "elicitation in multimodal open-ended environments. (2) As\n",
      "illustrated in Figure 1, we introduce Elicitation and Execu-\n",
      "tion Policies to enhance confidence estimation in embodied\n",
      "settings. Elicitation Policies target different types of un-\n",
      "certainties arising from inductive, deductive, and abductive\n",
      "reasoning, while also facilitating multi-granular confidence\n",
      "estimation, allowing agents to assess uncertainty at both\n",
      "perception and action stages. Execution Policies improve\n",
      "robust elicitation across diverse scenarios, plans, and actions\n",
      "while tackling interactive dependencies by incorporating ad-\n",
      "ditional information about the environment and expanding\n",
      "potential action trajectories. (3) We provide the first struc-\n",
      "tured analysis of embodied uncertainty and identify effective\n",
      "methods for improving confidence calibration and failure\n",
      "prediction, while also pinpointing persistent challenges. The following are key observations from our analysis:\n",
      "(1) Elicitation Policies are Effective But Vary by Context:\n",
      "While all proposed elicitation policies improve confidence\n",
      "calibration and failure prediction, their effectiveness varies\n",
      "based on task complexity and uncertainty type, highlighting\n",
      "the need for adaptive strategies that align with the embodied\n",
      "agent’s reasoning process and environment demands. (2) Execution Policies Amplify Reliable Embodied Con-\n",
      "fidence Elicitation: Execution policies enhance the robust-\n",
      "ness of elicited confidence as they expand the range of avail-\n",
      "able actions and scenario interpretations, enabling agents to\n",
      "assess their confidence levels more effectively based on a\n",
      "broader set of potential outcomes. (3) Model Differences Persist: While all models benefit\n",
      "from the proposed policies, differences in their inherent\n",
      "reasoning and representation capabilities lead to significant\n",
      "variability in confidence calibration and task success rates,\n",
      "highlighting the importance of tailoring elicitation and exe-\n",
      "cution strategies to each model’s strengths and limitations. 2.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "Related Works\n",
      "Confidence Elicitation. Confidence elicitation for tradi-\n",
      "tional machine learning is well-studied (Abdar et al., 2021;\n",
      "Gawlikowski et al., 2023). One stream of work focuses on\n",
      "unsupervised methods leveraging entropy (Malinin & Gales,\n",
      "2021), graph semantic parsing (Lin et al., 2022b), semantic\n",
      "features (Kuhn et al., 2023; Farquhar et al., 2024), and logit\n",
      "or hidden state information (Su et al., 2024; Chen et al.,\n",
      "2024a) to craft uncertainty metrics. Another explores con-\n",
      "formal prediction for tasks like part-of-speech tagging (Dey\n",
      "et al., 2022), paraphrase detection (Giovannotti & Gam-\n",
      "merman, 2021), and fact verification (Fisch et al., 2021),\n",
      "offering statistically robust coverage guarantees (Kumar\n",
      "et al., 2023; Ye et al., 2024). However, these solutions often require full model access,\n",
      "making them less applicable to black-box language models,\n",
      "which are increasingly prevalent in real-world applications\n",
      "(Achiam et al., 2023; Touvron et al., 2023a).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "Additionally,\n",
      "their free-form nature of outputs further complicates the\n",
      "application of traditional methods. As a result, alternative\n",
      "approaches have been proposed, including estimating un-\n",
      "certainty by directly querying models for confidence scores\n",
      "after generating responses (Xiong et al., 2024; Kadavath\n",
      "et al., 2022; Lin et al., 2022a; Mielke et al., 2022; Chen &\n",
      "Mueller, 2024). Despite these advancements, existing meth-\n",
      "ods are not designed for embodied tasks, where confidence\n",
      "elicitation must address the challenges of multimodal per-\n",
      "ception, hierarchical reasoning and planning across various\n",
      "open-ended tasks, as well as non-deterministic interactions. LLM-based Embodied Agents. With the advent of lan-\n",
      "guage models, leveraging their reasoning and planning abili-\n",
      "ties to empower embodied agents has become quintessential\n",
      "(Huang et al., 2023; Yao et al., 2023; Chen et al., 2023;\n",
      "Zhang et al., 2024a; Shinn et al., 2024; Christianos et al.,\n",
      "2023). In the meantime, Minecraft’s open-ended nature\n",
      "with its adaptable mechanics and varied challenges, makes\n",
      "it a compelling benchmark for embedding reasoning and\n",
      "planning capabilities into language model-driven embod-\n",
      "ied agents (Wang et al., 2023a;c; Zhu et al., 2023). Re-\n",
      "cent works leverage pre-trained language models to control\n",
      "agents by generating continuous operation instructions or ex-\n",
      "ecutable policies. For example, some approaches (Zhu et al.,\n",
      "2023; Wang et al., 2023c) directly utilize scene data from\n",
      "simulation platforms like MineDojo (Fan et al., 2022) and\n",
      "MineRL (Guss et al., 2019), while others (Qin et al., 2024)\n",
      "rely on Vision-Language Models (VLMs) for perception. However, because language models are used in various\n",
      "roles—such as planners, critics, or perceivers—errors and in-\n",
      "accuracies often arise at different process stages (Guo et al.,\n",
      "2024; Driess et al., 2023). These challenges underscore\n",
      "the need for frameworks capable of systematically identi-\n",
      "fying and localizing sources of uncertainty, which we aim\n",
      "2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 2}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ElicitationPolicies What do you see?How confident are you? I see a pig next to\n",
      "a tree to the left [85% confident]\n",
      "ExecutionPolicies\n",
      "What do you see? Especially\n",
      "around the pig. How\n",
      "confident are you? What do you see? Especially\n",
      "around the trees. Howconfident are you? What do you see? Especially\n",
      "to your right.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 2}\n",
      "How confident\n",
      "are you? I see a pig with two trees \n",
      "[80% confident]\n",
      "I see sheeps and cows \n",
      "[90% confident]\n",
      "I see a mountain to the left\n",
      "[70% confident]\n",
      "Agent Answers: \n",
      "Vanilla Elicitation + Scene Reinterpretation:\n",
      " Execution Policies\n",
      "Action Sampling\n",
      "Scenario-\n",
      "Reinterpretation\n",
      "Hypothetical-\n",
      "Reasoning\n",
      " Elicitation Policies\n",
      "Vanilla\n",
      "Self-Intervention\n",
      "CoT \n",
      "P&S\n",
      "Top-K\n",
      "Figure 2.Embodied Confidence Elicitation. Elicitation Policies (§3.2) enable agents to express uncertainty, while Execution Policies\n",
      "(§3.3) refine and expand confidence assessment through scenario reinterpretation, action sampling, and hypothetical reasoning. Together,\n",
      "they enhance confidence calibration in embodied agents. The orange text represents the vanilla elicitation policy, which incorporates the\n",
      "vanilla confidence prompt (described in Table 1) into the original instruction. The brown arrows\n",
      " denote the Scenario-Reinterpretation\n",
      "execution policy, prompting the agent to generate additional scene insights. to address by designing a unified approach that enhances\n",
      "reliability and robustness in embodied agents.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 2}\n",
      "Uncertainty in Embodied Models. Uncertainty estima-\n",
      "tion is well explored in robot learning and reinforcement\n",
      "learning (Wang & Zou, 2021; Ghasemipour et al., 2022; He\n",
      "et al., 2023; Huang et al., 2019; Jin et al., 2023), but remains\n",
      "a challenge for language models (Tian et al., 2023; Groot\n",
      "& Valdenegro Toro, 2024; Zhang et al., 2024b). While\n",
      "recent efforts have sought to quantify and mitigate uncer-\n",
      "tainty (Sagar et al., 2024; Tian et al., 2022), the problem is\n",
      "further compounded in embodied AI settings, where agents\n",
      "must reason and act in dynamic multimodal environments\n",
      "(Ren et al., 2024; Shen & Lourentzou, 2025). Our work\n",
      "introduces a structured approach to verbalized confidence\n",
      "elicitation in embodied open-ended multimodal environ-\n",
      "ments to enable agents to express uncertainty and adapt to\n",
      "complex real-world interactions. 3. Method\n",
      "3.1. Problem Formulation & Framework Design\n",
      "Let E denote the embodied environment, characterized by\n",
      "multimodal sensory inputs I = {Iv, It}, where Iv repre-\n",
      "sents visual observations and It represents task instructions\n",
      "and other types of language-based guidance. For a given\n",
      "task T , the agent operates under a policy π : I → Athat\n",
      "maps input I to actions A. The task of embodied confidence\n",
      "elicitation is to enable agents to estimate and articulate a\n",
      "confidence score c ∈ [0, 1], representing their belief in the\n",
      "correctness of their perception and subsequent actions. The challenge lies in systematically identifying, quantify-\n",
      "ing, and articulating uncertainty as the agent interacts with\n",
      "its environment and executes tasks. This requires not only\n",
      "detecting uncertain aspects of the agent’s perception, reason-\n",
      "ing, or actions but also ensuring that confidence estimates\n",
      "are refined and reliable under dynamic multimodal condi-\n",
      "tions. To address this, we propose an embodied confidence\n",
      "estimation framework centered around Elicitation Modules\n",
      "that facilitates confidence elicitation at two critical points\n",
      "of interaction between the agent and its environment: Per-\n",
      "ception Stage, where the agent processes sensory input\n",
      "from the environment and assesses its confidence in what\n",
      "it perceives before engaging in reasoning or planning. Ac-\n",
      "tion Stage, which evaluates the agent’s confidence after\n",
      "reasoning, just before executing an action. Each Elicitation Module operates under a specific Elicita-\n",
      "tion Policy (§3.2), which defines what type of uncertainty\n",
      "is being expressed, focusing on quantifying confidence in\n",
      "the agent’s perception, reasoning, or action planning. Ad-\n",
      "ditionally, an Execution Policy (§3.3) determines how to\n",
      "collect and refine confidence, ensuring robust and adaptive\n",
      "estimates in complex, dynamic environments. An overview\n",
      "of the overall proposed method is shown in Figure 2. 3.2. Elicitation Policies\n",
      "Our confidence Elicitation Policies are designed to address\n",
      "distinct types of inferential uncertainty that embodied agents\n",
      "encounter in open-world long-horizon tasks. As these agents\n",
      "actively reason to determine their next actions, we draw in-\n",
      "spiration from rich studies on reasoning in language models\n",
      "3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 3}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Method Prompt\n",
      "Vanilla\n",
      "Read the task (e.g., collect wood, build a shelter), provide your answer, and explain how confident\n",
      "you are in perceiving the environment accurately to complete the task (e.g., recognizing resources,\n",
      "locating structures, identifying threats). Read the task given, provide your answer, and explain how confident you are in planning and executing\n",
      "the actions needed to achieve the goal (e.g., gathering materials, crafting tools, building a structure). Vanilla\n",
      "+\n",
      "Self-Intervention\n",
      "Task: [...], Perceived Situation: [...] Q: How confident you are in perceiving the environment\n",
      "accurately to complete the task? Task: [...], Planned Action: [...] Q: How confident you are in planning and executing the actions\n",
      "needed to achieve the goal? Chain-of-Thought\n",
      "(CoT)\n",
      "Read the task, analyze step by step what you perceive in the environment (e.g., observe surroundings,\n",
      "identify items), provide your answer, and evaluate your confidence based on the clarity and quality of\n",
      "the environment observations. Read the task, analyze step by step how to complete the task, provide your answer, and evaluate your\n",
      "confidence in successfully planning and executing each action needed to achieve the goal. Plan & Solve\n",
      "(P&S)\n",
      "Analyze the task, devise a systematic approach to perceive your environment effectively. (e.g., locating\n",
      "resources, identifying obstacles), and evaluate your confidence based on how well you perceive the\n",
      "environment. Analyze the task, devise a plan of actions needed to complete it, then evaluate your confidence in\n",
      "executing each action and achieving the desired outcome. Top-K\n",
      "Provide your K best descriptions of your perceptions of the environment and the probability that each\n",
      "is correct (0% to 100%). Provide your K best plans of the possible actions to take and the probability that each will succeed\n",
      "(0% to 100%). Table 1.Prompts for Different Elicitation Policies in generalist embodied Minecraft agents. Orange text indicates prompts focused on\n",
      "perception, while blue text highlights prompts centered on action and planning. (Huang & Chang, 2023) and introduce five prompt instruc-\n",
      "tions, comprising two general-purpose methods and three\n",
      "tailored to inductive, deductive, and abductive reasoning\n",
      "settings (Appendix A). These prompts ask the agent to ver-\n",
      "balize its confidence levels and systematically refine its\n",
      "uncertainty. Table 1 provides an overview of elicitation\n",
      "policy types with corresponding examples. ⋄ Vanilla. Leveraging the inherent capability of language\n",
      "models (Brown et al., 2020; Wei et al., 2022a), the Vanilla\n",
      "method directly queries the agent’s confidence without addi-\n",
      "tional structure or intervention. Vanilla serves as a baseline\n",
      "for comparison, relying solely on the agent’s built-in capac-\n",
      "ity for confidence elicitation and self-assessment. ⋄ Self-Intervention.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 3}\n",
      "Humans naturally benefit from revisit-\n",
      "ing their decisions with a fresh perspective, often uncovering\n",
      "insights or errors they initially overlooked. Inspired by this,\n",
      "the self-intervention method separates answer generation\n",
      "from evaluation. In one session, the model generates an an-\n",
      "swer; in another, it revisits the question and its response to\n",
      "assess its accuracy. This independent second pass mitigates\n",
      "confirmation bias and overconfidence, encouraging critical\n",
      "self-reflection and producing more reliable evaluations. ⋄ Chain-of-Thought (CoT). To address uncertainty in in-\n",
      "ductive reasoning settings, where the agent must identify pat-\n",
      "terns and infer relationships from observations, we employ\n",
      "zero-shot Chain-of-Thought (CoT) reasoning (Wei et al.,\n",
      "2022b). By decomposing tasks into incremental steps, CoT\n",
      "enhances both interpretability and confidence calibration,\n",
      "allowing agents to reassess uncertainty at each step. ⋄ Plan & Solve (P&S). Despite the success of CoT, it of-\n",
      "ten suffers from semantic misunderstandings and missing\n",
      "step errors, particularly when applying general principles\n",
      "to specific cases. These failures stem from uncertainty in\n",
      "deductive reasoning, where the agent is unsure about the\n",
      "correct instantiation of abstract rules or whether a logical\n",
      "step is valid in a given context. P&S (Wang et al., 2023b)\n",
      "mitigates this by explicitly separating planning from execu-\n",
      "tion, prompting the agent to construct a structured reasoning\n",
      "blueprint before solving the problem step by step. ⋄ Top-K. To address uncertainty in abductive reasoning,\n",
      "where multiple plausible explanations may fit the observed\n",
      "data, the Top-K method prompts the agent to generate its top\n",
      "K answers, each with an associated confidence level. This\n",
      "encourages the agent to consider and distribute its attention\n",
      "across several possible outcomes. By ranking responses\n",
      "rather than a single definitive answer, Top-K provides a\n",
      "balanced and comprehensive representation of abductive\n",
      "uncertainty across multiple plausible interpretations. 3.3. Execution Policies\n",
      "In embodied contexts, planning is a key factor in task suc-\n",
      "cess, requiring the agent to assess its confidence in execut-\n",
      "ing action sequences effectively. Dynamic environments\n",
      "introduce unpredictable factors in action outcomes, which\n",
      "makes it important for the agent to not only consider its\n",
      "primary course of action but also to evaluate and commu-\n",
      "nicate its confidence in alternative actions.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 3}\n",
      "By analyzing\n",
      "variance across potential actions rollouts, the agent can bet-\n",
      "4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 4}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ter quantify uncertainty and anticipate divergent outcomes. To address this, we introduce a set of policies that gener-\n",
      "ate additional observations and diverse action trajectories,\n",
      "promoting robust confidence assessment:\n",
      "⟳ Action Sampling: The agent can generate multiple pos-\n",
      "sible actions by sampling from a learned policy distribution\n",
      "over the action space, conditioned on the current state and\n",
      "task objectives. By doing so, the agent can explore multiple\n",
      "actions, evaluate different outcomes, and assess which is\n",
      "most likely to succeed based on its perception. ⟳ Scenario Reinterpretation: The agent can be prompted\n",
      "to reinterpret the same scenario from different perspec-\n",
      "tives. For example, it could focus on a particular object,\n",
      "re-evaluate environmental obstacles, or re-assess the prox-\n",
      "imity of targets. This enables the agent to propose different\n",
      "courses of action by gathering and redirecting its attention\n",
      "to relevant environmental information. ⟳ Hypothetical Reasoning: The agent can be prompted\n",
      "with hypothetical or counterfactual scenarios (e.g., “What if\n",
      "the object in front were not an obstacle?”). By simulating\n",
      "these hypotheticals, the agent can explore how its actions\n",
      "would change and assess confidence in its original plan. This\n",
      "helps to gauge how flexible the agent’s decision-making\n",
      "process is when confronted with uncertainty or alternative\n",
      "interpretations of the environment. Figure 2 provides an overview and examples of Elicitation\n",
      "and Execution Policies. During task-solving, agents rely\n",
      "on these execution policies to gather additional informa-\n",
      "tion about the environment and potential action trajectories,\n",
      "which they incorporate into further confidence elicitation. 4.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 4}\n",
      "Experiment Setup\n",
      "Environment & Task Setting. Minecraft has emerged as\n",
      "a popular benchmark for embodied AI research due to its\n",
      "open-ended environment, with diverse terrains, resources,\n",
      "and open-ended goals, making it an ideal testbed for embod-\n",
      "ied agents that perform hierarchical reasoning and long-term\n",
      "planning (Johnson et al., 2016; Guss et al., 2019; Hafner\n",
      "et al., 2023; Nottingham et al., 2023; Lin et al., 2023; Qin\n",
      "et al., 2024). Building on this foundation, we define 30\n",
      "tasks evenly distributed across three difficulty levels: easy,\n",
      "medium, and hard, based on the complexity of reasoning\n",
      "steps and the amount of contextual information required. Detailed task descriptions can be found in Appendix B. Easy tasks typically involve basic interactions with a single\n",
      "environmental element (e.g., locating a pig or observing the\n",
      "weather). Medium tasks require combining perception and\n",
      "reasoning over multiple elements, while hard tasks increase\n",
      "dependency on sequential reasoning and include complex\n",
      "challenges like the Diamond Challenge , which requires\n",
      "long-term planning and multi-step execution. Following\n",
      "prior work (Guss et al., 2019), the maximum episode length\n",
      "is set to 6000 steps. Privileged observation is used as the\n",
      "ground truth for perception, while overall task success rate\n",
      "serves as the ground truth for planning and reasoning. Evaluation Metrics. To assess the reliability of confidence\n",
      "estimates, we evaluate two key aspects: calibration and fail-\n",
      "ure prediction (Naeini et al., 2015; Yuan et al., 2021). Cali-\n",
      "bration measures how well an agent’s expressed confidence\n",
      "reflects its actual performance, e.g., an 80% confidence\n",
      "should ideally correspond to 80% accuracy. This calibration\n",
      "is crucial for applications requiring robust risk assessment\n",
      "and trustworthiness. On the other hand, failure prediction\n",
      "focuses on the agent’s ability to distinguish between correct\n",
      "and incorrect predictions by assigning higher confidence to\n",
      "correct outcomes. We use the Expected Calibration Error\n",
      "(ECE) to quantify calibration quality and the Area Under\n",
      "the Receiver Operating Characteristic Curve (AUROC) to\n",
      "evaluate failure prediction. To address imbalances stem-\n",
      "ming from varying accuracy levels across tasks, we also\n",
      "include AUPRC-Positive (PR-P) and AUPRC-Negative (PR-\n",
      "N), which separately measure the agent’s effectiveness in\n",
      "identifying correct and incorrect predictions. Minecraft Agents. In this work, we focus on embod-\n",
      "ied agents powered by advanced Large Language Models\n",
      "(LLMs) and Vision-Language Models (VLMs) that enable\n",
      "multimodal reasoning and understanding in complex embod-\n",
      "ied environments. We employ three models as the agent’s\n",
      "backbone: (1) GPT-4V, chosen for its strong performance\n",
      "in multimodal reasoning and proven effectiveness in com-\n",
      "plex environments like Minecraft (Wang et al., 2023a; Qin\n",
      "et al., 2024; Li et al., 2025) for planning and perception\n",
      "tasks. (2) MineLLM (Qin et al., 2024), a model specifically\n",
      "designed for Minecraft tasks, that leverages MineCLIP’s vi-\n",
      "sual encoder and Vicuna-13B (Chiang et al., 2023) to deliver\n",
      "robust multimodal understanding. and (3) STEVE, built on\n",
      "the versatile LLaMA framework, STEVE models excel in\n",
      "contextual understanding and decision-making (Zhao et al.,\n",
      "2025). Fine-tuned for Minecraft, STEVE enhances plan-\n",
      "ning, communication, and interaction capabilities. Detailed\n",
      "model descriptions are provided in Appendix C.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 4}\n",
      "5. Experimental Results\n",
      "Table 2 presents the performance of benchmarked agents\n",
      "across all Elicitation Policies. In this experiment, evaluation\n",
      "is conducted without Execution Policies. The final confi-\n",
      "dence scores are computed as the average of individual step\n",
      "confidence scores across five independent task episodes. All Elicitation Policies Facilitate Better Calibration and\n",
      "Failure Prediction. Across all models, Elicitation Policies\n",
      "consistently improve calibration (lower ECE) and failure\n",
      "5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 5}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Metric Model Vanilla Self-Intervention CoT (Inductive) P&S (Deductive) Top-K (Abductive)\n",
      "ECE ↓\n",
      "GPT-4V 0.27 0.21 0.16 0.15 0.17\n",
      "MineLLM 0.49 0.41 0.34 0.39 0.43\n",
      "STEVE 0.43 0.32 0.26 0.26 0.35\n",
      "AUROC ↑\n",
      "GPT-4V 0.69 0.76 0.83 0.82 0.73\n",
      "MineLLM 0.53 0.59 0.64 0.61 0.58\n",
      "STEVE 0.58 0.69 0.72 0.67 0.68\n",
      "PR-P ↑\n",
      "GPT-4V 0.66 0.76 0.81 0.79 0.70\n",
      "MineLLM 0.51 0.59 0.63 0.60 0.57\n",
      "STEVE 0.56 0.67 0.69 0.66 0.64\n",
      "PR-N ↑\n",
      "GPT-4V 0.52 0.53 0.58 0.55 0.53\n",
      "MineLLM 0.39 0.42 0.42 0.43 0.40\n",
      "STEVE 0.41 0.46 0.46 0.43 0.42\n",
      "Table 2.Confidence Metrics across Elicitation Policies with three models (GPT-4V , MineLLM, and LLaMA-based STEVE) using\n",
      "different elicitation strategies: Vanilla (basic task understanding), Self-Intervention (reflection on own actions), Chain-of-Thought\n",
      "(step-by-step reasoning), Plan & Solve (explicit planning before execution), and Top-K (confidence distribution across multiple outputs)\n",
      "with No Execution Policies applied. The best performance across each model is in bold.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 5}\n",
      "prediction (higher AUROC, PR-P, PR-N) compared to the\n",
      "Vanilla baseline. For instance, in GPT-4V , every Elicitation\n",
      "Policy results in a lower ECE and higher AUROC rela-\n",
      "tive to Vanilla, demonstrating their effectiveness in improv-\n",
      "ing the robustness of uncertainty quantification. Likewise,\n",
      "MineLLM and STEVE exhibit noticeable gains in ECE and\n",
      "AUROC when incorporating elicitation mechanisms, con-\n",
      "firming that Elicitation Policies help agents better assess\n",
      "uncertainty and predict incorrect responses. Structured Elicitation (CoT and P&S) Improves Cali-\n",
      "bration and Failure Prediction the Most. Among the four\n",
      "Elicitation Policies, structured reasoning approaches—CoT\n",
      "(Inductive) and P&S (Deductive)—consistently yield the\n",
      "best calibration and failure detection performance. For ex-\n",
      "ample, in GPT-4V , P&S achieves the lowest ECE (0.15)\n",
      "and one of the highest AUROC scores (0.82), while CoT\n",
      "further improves AUROC up to 0.83. Similar trends hold for\n",
      "MineLLM and STEVE, where CoT and P&S outperform\n",
      "Self-Intervention and Top-K across nearly all metrics. These\n",
      "improvements suggest that breaking down reasoning into\n",
      "explicit steps helps the models maintain logical consistency,\n",
      "facilitating better overall calibration. Abductive Reasoning Poses Greater Challenges than\n",
      "Inductive and Deductive. While Top-K (Abductive) im-\n",
      "proves over the Vanilla policy, it exhibits weaker calibration\n",
      "and failure prediction, suggesting that generating multiple\n",
      "plausible interpretations increases uncertainty misalignment,\n",
      "and therefore making it harder for the model to distinguish\n",
      "between correct and incorrect predictions. Additionally, the\n",
      "lower PR-P and PR-N scores indicate that confidence esti-\n",
      "mation for abductive reasoning is more difficult to calibrate\n",
      "compared to inductive and deductive settings. Confidence Calibration Remains Inconsistent Across\n",
      "Models. While GPT-4V consistently benefits from different\n",
      "Elicitation Policies, the improvements are less stable in\n",
      "fine-tuned models like MineLLM and STEVE. For instance,\n",
      "CoT boosts AUROC to 0.83 in GPT-4V but only reaches\n",
      "0.64 in MineLLM and 0.72 in STEVE, indicating that fine-\n",
      "tuned models struggle to generalize confidence estimation\n",
      "effectively. One likely reason for this inconsistency is that\n",
      "MineLLM and STEVE, being fine-tuned models, exhibit\n",
      "degenerated language capabilities, limiting their ability to\n",
      "verbalize uncertainty reliably. Execution Policies Amplify Reliable Embodied Confi-\n",
      "dence Across Elicitation Policies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 5}\n",
      "Figure 3 illustrates how\n",
      "Execution Policies interact with Elicitation Policies. Overall,\n",
      "Execution Policies are capable of further improving cali-\n",
      "bration and failure prediction performance. For example,\n",
      "GPT-4V achieves better ECE results when pairing any Exe-\n",
      "cution Policy with all Elicitation Policies. More specifically,\n",
      "structured reasoning approaches such as CoT (Inductive)\n",
      "and P&S (Deductive), when paired with Action Sampling,\n",
      "tend to yield improved confidence calibration. For instance,\n",
      "MineLLM’s ECE achieves 0.32 and 0.30 paired with CoT\n",
      "and P&S respectively, outperforming other combinations. Hypothetical Reasoning sometimes degrades performance. For instance, STEVE’s ECE worsens when pairing Hypo-\n",
      "thetical Reasoning with all Elicitation Policies, suggesting\n",
      "that while this execution strategy allows models to reason\n",
      "over multiple possible outcomes, it may introduce uncer-\n",
      "tainty, leading to less calibrated confidence judgments. So, How Effectively Can Embodied Agents Express Con-\n",
      "fidence in Dynamic Embodied Tasks? While embodied\n",
      "agents can convey confidence to some extent, their effec-\n",
      "tiveness depends on how well they integrate reasoning, un-\n",
      "certainty assessment, and environmental interactions. The\n",
      "findings reveal that embodied confidence elicitation remains\n",
      "a challenging problem, requiring a careful balance between\n",
      "general-purpose reasoning and task-specific specialization. However, our proposed Elicitation Policies improve both\n",
      "confidence calibration and failure prediction, while our Ex-\n",
      "ecution Policies further augment these performance gains\n",
      "by refining uncertainty through iterative interactions with\n",
      "the environment. These results highlight the importance of\n",
      "6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 6}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Vanilla Self-Intervention CoT P&S Top-K\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.24\n",
      "0.22\n",
      "0.14\n",
      "0.10\n",
      "0.12\n",
      "0.11\n",
      "0.11\n",
      "0.12\n",
      "0.11\n",
      "0.11\n",
      "0.13\n",
      "0.18\n",
      "0.12\n",
      "0.14\n",
      "0.15\n",
      "ECE ↓\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.50\n",
      "0.53\n",
      "0.52\n",
      "0.35\n",
      "0.42\n",
      "0.50\n",
      "0.32\n",
      "0.44\n",
      "0.33\n",
      "0.30\n",
      "0.45\n",
      "0.38\n",
      "0.42\n",
      "0.47\n",
      "0.43\n",
      "ECE ↓\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.40\n",
      "0.42\n",
      "0.41\n",
      "0.28\n",
      "0.27\n",
      "0.39\n",
      "0.24\n",
      "0.24\n",
      "0.33\n",
      "0.27\n",
      "0.28\n",
      "0.35\n",
      "0.30\n",
      "0.31\n",
      "0.34\n",
      "ECE ↓\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.76\n",
      "0.75\n",
      "0.78\n",
      "0.80\n",
      "0.79\n",
      "0.81\n",
      "0.84\n",
      "0.82\n",
      "0.84\n",
      "0.88\n",
      "0.79\n",
      "0.85\n",
      "0.78\n",
      "0.77\n",
      "0.81\n",
      "AUROC ↑\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.55\n",
      "0.64\n",
      "0.51\n",
      "0.64\n",
      "0.68\n",
      "0.68\n",
      "0.69\n",
      "0.74\n",
      "0.71\n",
      "0.67\n",
      "0.71\n",
      "0.65\n",
      "0.63\n",
      "0.66\n",
      "0.65\n",
      "AUROC ↑\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.62\n",
      "0.66\n",
      "0.57\n",
      "0.74\n",
      "0.74\n",
      "0.65\n",
      "0.72\n",
      "0.70\n",
      "0.65\n",
      "0.72\n",
      "0.72\n",
      "0.64\n",
      "0.70\n",
      "0.68\n",
      "0.64\n",
      "AUROC ↑\n",
      "GPT-4V MineLLM STEVE\n",
      "Figure 3.ECE and AUROC across Models and Execution Policies. Bars present ECE (top, lower is better) and AUROC (bottom,\n",
      "higher is better) under different elicitation strategies. Red dashed lines are metrics for Vanilla elicitation with no execution policy applied. accounting for the unique challenges faced by embodied\n",
      "agents in confidence estimation, emphasizing the need for\n",
      "execution-aware strategies that enhance both calibration and\n",
      "failure prediction in complex environments. 6.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 6}\n",
      "Ablation Studies\n",
      "Impact of Execution Policies. We analyze the performance\n",
      "of Execution Policy combinations, incorporating Action\n",
      "Sampling (AS), Scenario Reinterpretation (SR), and Hypo-\n",
      "thetical Reasoning (HR) both incrementally and collectively. Results in Table 3 show clear trends in how Execution Poli-\n",
      "cies influence performance. Without any Execution Policies,\n",
      "Vanilla Elicitation exhibits the worst calibration, with ECE\n",
      "as high as 0.27, while also struggling with failure predic-\n",
      "tion. When Execution Policies are introduced, performance\n",
      "improves, though trade-offs emerge between failure predic-\n",
      "tion accuracy (AUROC) and confidence calibration (ECE). Among two-policy combinations, the combination of Action\n",
      "Sampling with Scenario Reinterpretation (AS + SR) deliv-\n",
      "ers the most balanced improvement, significantly increas-\n",
      "ing AUROC (up to 0.83 for GPT-4V and 0.69 for STEVE)\n",
      "while maintaining the lowest ECE (0.17 for GPT-4V , 0.32\n",
      "for MineLLM). This suggests that jointly exploring multi-\n",
      "ple action paths and reinterpreting environmental cues helps\n",
      "refine confidence estimation without sacrificing calibration. In addition, strategies incorporating Action Sampling (AS)\n",
      "consistently outperform those without it, resulting in better\n",
      "uncertainty estimation and more reliable confidence scores. By generating multiple action plans, AS enhances confi-\n",
      "dence calibration, underscoring the importance of address-\n",
      "ing action planning uncertainty in embodied agents. Com-\n",
      "bining all Execution Policies yields the strongest overall\n",
      "performance across models, achieving the highest AUROC\n",
      "across all three models while maintaining competitive cali-\n",
      "bration, with the lowest ECE for GPT-4V (0.17) and strong\n",
      "values for MineLLM (0.32) and STEVE (0.38). This sug-\n",
      "gests that integrating Action Sampling, Scenario Reinterpre-\n",
      "tation, and Hypothetical Reasoning provides a complemen-\n",
      "tary effect, improving both failure prediction accuracy and\n",
      "confidence estimation. Perception v.s.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 6}\n",
      "Cognition. Embodied agents, when tasked\n",
      "with high-level objectives ( e.g., “find a pig”), often rely\n",
      "on language models to decompose the task into smaller,\n",
      "granular actions (e.g., “step forward 2 steps”). During task\n",
      "execution, the agent generates confidence scores for each\n",
      "granular action. Typically, these scores are aggregated tem-\n",
      "porally to produce a single overall confidence score for the\n",
      "entire task. While this method provides a holistic measure\n",
      "of confidence, it does not differentiate between the confi-\n",
      "dence associated with perception (e.g., recognizing a pig)\n",
      "and cognition (e.g., reasoning about the sequence of steps). To better understand how different sources of uncertainty\n",
      "contribute to overall confidence, we separately analyze per-\n",
      "ception and reasoning confidence. Perception Confidence\n",
      "aggregates scores related to the agent’s ability to interpret its\n",
      "sensory inputs (e.g., detecting objects or understanding en-\n",
      "vironmental cues), while Reasoning Confidence aggregates\n",
      "scores associated with reasoning and decision-making pro-\n",
      "cesses during task execution. Figure 4 reveals that temporal\n",
      "aggregation achieves the lowest ECE (0.18) and a balanced\n",
      "AUROC (0.76). Temporal aggregation smooths over indi-\n",
      "vidual uncertainties, providing robust overall calibration and\n",
      "reliable failure prediction. Perception-based confidence, when aggregated separately,\n",
      "offers a distinct advantage in predictive reliability. With an\n",
      "AUROC of 0.79, the highest among the methods, and strong\n",
      "PR-P (0.85) and PR-N (0.81) scores, perception confidence\n",
      "consistently outperforms reasoning. This highlights the\n",
      "7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 7}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Execution Strategies GPT-4V MineLLM STEVE\n",
      "ECE ↓ AUROC ↑ ECE ↓ AUROC ↑ ECE ↓ AUROC ↑\n",
      "No Execution Strategy 0.27 0.69 0.49 0.53 0.43 0.58\n",
      "AS + SR 0.18 0.82 0.32 0.59 0.39 0.69\n",
      "AS + HR 0.20 0.79 0.34 0.57 0.37 0.66\n",
      "SR + HR 0.22 0.80 0.37 0.54 0.44 0.58\n",
      "AS + SR + HR 0.17 0.83 0.32 0.62 0.38 0.69\n",
      "Table 3.Performance of Vanilla Elicitation with Combined Execution Strategies. AS = Action Sampling, SR = Scenario Reinterpreta-\n",
      "tion, HR = Hypothetical Reasoning. ECE and AUROC for each model, GPT-4V , MineLLM, and STEVE.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 7}\n",
      "Best values highlighted inbold. ECE AUROC PR-P PR-N\n",
      "Temporal\n",
      "Aggregation\n",
      "Reasoning\n",
      "Confidence\n",
      "Perception\n",
      "Confidence\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.18\n",
      "0.26\n",
      "0.22\n",
      "0.76\n",
      "0.71\n",
      "0.79\n",
      "0.82\n",
      "0.78\n",
      "0.85\n",
      "0.80\n",
      "0.72\n",
      "0.81\n",
      "Confidence Scores\n",
      "Figure 4.Comparison of Aggregation Methods for Vanilla Elic-\n",
      "itation without Execution Policies. Temporal aggregation pro-\n",
      "vides a holistic score, while separate aggregation evaluates confi-\n",
      "dence in reasoning and perception separately respectively. inherent stability of sensory tasks, where clear input-output\n",
      "mappings and deterministic operations reduce uncertainty. Additionally, perception confidence maintains a competitive\n",
      "ECE (0.22), indicating that it remains well-calibrated. In contrast, reasoning confidence introduces more uncer-\n",
      "tainty, resulting in a higher ECE (0.26) and a lower AU-\n",
      "ROC (0.71). These results reflect the challenges of reason-\n",
      "ing tasks, which often involve multi-step decision-making\n",
      "and are susceptible to cascading errors. The lower PR-P\n",
      "(0.78) and PR-N (0.72) scores suggest reasoning confidence\n",
      "struggles to accurately distinguish correct from incorrect\n",
      "outcomes. In essence, results affirm that reasoning tasks\n",
      "inherently present greater uncertainty, requiring more so-\n",
      "phisticated calibration methods to maintain reliability. Interestingly, the performance gap between perception and\n",
      "reasoning confidence underscores their complementary na-\n",
      "ture. While perception excels in calibration and failure\n",
      "prediction, reasoning provides critical insights into decision-\n",
      "making under uncertainty. Temporal aggregation balances\n",
      "these components effectively for an overall confidence score\n",
      "but sacrifices the interpretability offered by separate aggre-\n",
      "gation. This comparison emphasizes the need to align ag-\n",
      "gregation methods with task complexity and performance\n",
      "priorities, whether for holistic confidence measures or de-\n",
      "tailed insights into perception and cognition. Impact of Execution Iterations. We investigate the impact\n",
      "of repeatedly applying execution policies on calibration and\n",
      "failure prediction accuracy. Iterations range from 0 (i.e., no\n",
      "execution policies employed) to 15, allowing for an analysis\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0 5 10 150.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "# Iterations\n",
      "ECE\n",
      "0 5 10 15\n",
      "0.76\n",
      "0.78\n",
      "0.8\n",
      "0.82\n",
      "0.84\n",
      "# Iterations\n",
      "AUROC\n",
      "Figure 5.ECE and AUROC across Execution Policy Iterations. of both the initial benefits and potential diminishing returns\n",
      "of repeated applications. As shown in Figure 5, repeated\n",
      "applications initially improve ECE across all policies but\n",
      "eventually plateau. For instance, Action Sampling reduces\n",
      "ECE from 0.18 (at 0 iterations) to 0.14 (at 15 iterations),\n",
      "with most of the improvement occurring within the first 10\n",
      "iterations. A similar trend is observed for Scenario Rein-\n",
      "terpretation and Hypothetical Reasoning, where ECE drops\n",
      "from 0.25 to 0.18 and from 0.23 to 0.17, respectively. The\n",
      "plateau effect is less pronounced in AUROC, which consis-\n",
      "tently improves across iterations. Action Sampling increases\n",
      "AUROC from 0.77 to 0.83, while Scenario Reinterpretation\n",
      "and Hypothetical Reasoning improve from 0.79 to 0.84 and\n",
      "from 0.78 to 0.84, respectively. Most AUROC gains occur\n",
      "between 0 and 10 iterations, with diminishing returns after\n",
      "15 iterations. Overall, early iterations improve calibration\n",
      "and failure prediction, but excessive repetition yields di-\n",
      "minishing returns. This underscores the need to balance\n",
      "execution policy applications for optimal effectiveness.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 7}\n",
      "7. Conclusion\n",
      "This work presents the first systematic exploration of em-\n",
      "bodied confidence elicitation, introducing elicitation and\n",
      "execution policies that enhance calibration and failure pre-\n",
      "diction in open-ended multimodal embodied tasks. Our\n",
      "findings highlight improvements in confidence estimation\n",
      "using our proposed methods, providing more accurate un-\n",
      "certainty quantification. Future research could improve\n",
      "confidence elicitation in embodied environments by scaling\n",
      "to more diverse and complex environments and exploring\n",
      "their integration with various embodied agent architectures. 8\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "8. Impact Statement\n",
      "This work advances Embodied AI by introducing confidence\n",
      "elicitation and execution policies tailored to multimodal and\n",
      "dynamic environments. By enabling embodied agents to\n",
      "express uncertainty, our approach enhances their calibra-\n",
      "tion, adaptability, and reliability in complex tasks. This\n",
      "contribution supports safer AI deployment in real-world do-\n",
      "mains like robotics, education, and collaborative systems,\n",
      "where accurate self-assessment is critical. However, the\n",
      "reliance on large pre-trained models raises concerns about\n",
      "energy efficiency and ethical considerations in high-stakes\n",
      "applications, which warrant further exploration. References\n",
      "Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D.,\n",
      "Liu, L., Ghavamzadeh, M., Fieguth, P., Cao, X., Khos-\n",
      "ravi, A., Acharya, U. R., et al. A review of uncertainty\n",
      "quantification in deep learning: Techniques, applications\n",
      "and challenges. Information Fusion, 2021. Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I.,\n",
      "Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S.,\n",
      "Anadkat, S., et al. Gpt-4 technical report. arXiv preprint\n",
      "arXiv:2303.08774, 2023. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,\n",
      "Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\n",
      "Askell, A., et al. Language models are few-shot learners. In Advances in Neural Information Processing Systems,\n",
      "2020. Chen, B., Shu, C., Shareghi, E., Collier, N., Narasimhan, K.,\n",
      "and Yao, S. Fireact: Toward language agent fine-tuning. arXiv preprint arXiv:2310.05915, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "Chen, C., Liu, K., Chen, Z., Gu, Y ., Wu, Y ., Tao, M., Fu, Z.,\n",
      "and Ye, J. INSIDE: LLMs’ internal states retain the power\n",
      "of hallucination detection. In International Conference\n",
      "on Learning Representations, 2024a. Chen, J. and Mueller, J. Quantifying uncertainty in answers\n",
      "from any language model and enhancing their trustwor-\n",
      "thiness. In Association for Computational Linguistics ,\n",
      "2024. Chen, J., Park, S., and Simeone, O. Knowing when to stop:\n",
      "Delay-adaptive spiking neural network classifiers with\n",
      "reliability guarantees. IEEE Journal of Selected Topics in\n",
      "Signal Processing, 2024b. Cheng, K., Yang, J., Jiang, H., Wang, Z., Huang, B., Li,\n",
      "R., Li, S., Li, Z., Gao, Y ., Li, X., et al. Inductive or\n",
      "deductive? rethinking the fundamental reasoning abilities\n",
      "of llms. arXiv preprint arXiv:2408.00114, 2024. Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y ., Wu, Z., Zhang,\n",
      "H., Zheng, L., Zhuang, S., Zhuang, Y ., Gonzalez, J. E.,\n",
      "Stoica, I., and Xing, E.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "P. Vicuna: An open-source chat-\n",
      "bot impressing gpt-4 with 90%* chatgpt quality. See\n",
      "https://lmsys.org/blog/2023-03-30-vicuna/, 2023. Christianos, F., Papoudakis, G., Zimmer, M., Coste, T., Wu,\n",
      "Z., Chen, J., Khandelwal, K., Doran, J., Feng, X., Liu,\n",
      "J., Xiong, Z., Luo, Y ., Hao, J., Shao, K., Bou-Ammar,\n",
      "H., and Wang, J. Pangu-agent: A fine-tunable gener-\n",
      "alist agent with structured reasoning. arXiv preprint\n",
      "arXiv:2312.14878, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "Clark, A. Surfing Uncertainty: Prediction, Action, and the\n",
      "Embodied Mind. Oxford University Press, 2015. Dey, N., Ding, J., Ferrell, J., Kapper, C., Lovig, M., Plan-\n",
      "chon, E., and Williams, J. P. Conformal prediction for text\n",
      "infilling and part-of-speech prediction. The New England\n",
      "Journal of Statistics in Data Science, 2022. Driess, D., Xia, F., Sajjadi, M. S. M., Lynch, C., Chowdhery,\n",
      "A., Ichter, B., Wahid, A., Tompson, J., Vuong, Q., Yu,\n",
      "T., Huang, W., Chebotar, Y ., Sermanet, P., Duckworth,\n",
      "D., Levine, S., Vanhoucke, V ., Hausman, K., Toussaint,\n",
      "M., Greff, K., Zeng, A., Mordatch, I., and Florence, P. Palm-e: An embodied multimodal language model. In\n",
      "International Conference on Machine Learning, 2023. Fan, L., Wang, G., Jiang, Y ., Mandlekar, A., Yang, Y ., Zhu,\n",
      "H., Tang, A., Huang, D.-A., Zhu, Y ., and Anandkumar,\n",
      "A. Minedojo: Building open-ended embodied agents\n",
      "with internet-scale knowledge. In Advances in Neural\n",
      "Information Processing Systems, 2022. Farquhar, S., Kossen, J., Kuhn, L., and Gal, Y . Detecting\n",
      "hallucinations in large language models using semantic\n",
      "entropy. Nature, 2024. Fisch, A., Schuster, T., Jaakkola, T., and Barzilay, R. Effi-\n",
      "cient conformal prediction via cascaded inference with\n",
      "expanded admission. In International Conference on\n",
      "Learning Representations, 2021. Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M.,\n",
      "Feng, J., Kruspe, A., Triebel, R., Jung, P., Roscher, R.,\n",
      "et al. A survey of uncertainty in deep neural networks. Artificial Intelligence Review, 2023. Ghasemipour, K., Gu, S.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "S., and Nachum, O. Why so pes-\n",
      "simistic? estimating uncertainties for offline rl through\n",
      "ensembles, and why their independence matters. In Ad-\n",
      "vances in Neural Information Processing Systems, 2022. Giovannotti, P. and Gammerman, A. Transformer-based\n",
      "conformal predictors for paraphrase detection. In Con-\n",
      "formal and Probabilistic Prediction and Applications ,\n",
      "2021. 9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Goel, V . Anatomy of deductive reasoning.Trends in cogni-\n",
      "tive sciences, 2007. Groot, T.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "and Valdenegro Toro, M. Overconfidence is key:\n",
      "Verbalized uncertainty evaluation in large language and\n",
      "vision-language models. In Trustworthy Natural Lan-\n",
      "guage Processing, 2024. Guo, X., Huang, K., Liu, J., Fan, W., V ´elez, N., Wu, Q.,\n",
      "Wang, H., Griffiths, T. L., and Wang, M. Embodied\n",
      "LLM agents learn to cooperate in organized teams. In\n",
      "Language Gamification - NeurIPS 2024 Workshop, 2024. Guss, W. H., Houghton, B., Topin, N., Wang, P., Codel,\n",
      "C. R., Veloso, M. M., and Salakhutdinov, R. Minerl:\n",
      "A large-scale dataset of minecraft demonstrations. In\n",
      "International Joint Conference on Artificial Intelligence,\n",
      "2019. Hafner, D., Pasukonis, J., Ba, J., and Lillicrap, T. Mastering\n",
      "diverse domains through world models. arXiv preprint\n",
      "arXiv:2301.04104, 2023. He, S., Han, S., Su, S., Han, S., Zou, S., and Miao, F. Robust\n",
      "multi-agent reinforcement learning with state uncertainty. Transactions on Machine Learning Research, 2023. Huang, J. and Chang, K. C.-C. Towards reasoning in large\n",
      "language models: A survey. In Association for Computa-\n",
      "tional Linguistics, 2023. Huang, W., Zhang, J., and Huang, K. Bootstrap estimated\n",
      "uncertainty of the environment model for model-based\n",
      "reinforcement learning. In AAAI Conference on Artificial\n",
      "Intelligence, 2019. Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence,\n",
      "P., Zeng, A., Tompson, J., Mordatch, I., Chebotar, Y .,\n",
      "et al. Inner monologue: Embodied reasoning through\n",
      "planning with language models. In Conference on Robot\n",
      "Learning, 2023. Jin, L., Chen, X., R ¨uckin, J., and Popovi ´c, M. Neu-nbv:\n",
      "Next best view planning using uncertainty estimation in\n",
      "image-based neural rendering. In International Confer-\n",
      "ence on Intelligent Robots and Systems. IEEE, 2023. Johnson, M., Hofmann, K., Hutton, T., and Bignell, D. The malmo platform for artificial intelligence experimen-\n",
      "tation. In International Joint Conference on Artificial\n",
      "Intelligence, 2016. Johnson-Laird, P. N. Deductive reasoning. Annual review\n",
      "of psychology, 1999. Josephson, J. R. and Josephson, S. G. Abductive inference:\n",
      "Computation, philosophy, technology. Cambridge Uni-\n",
      "versity Press, 1996. Kadavath, S., Conerly, T., Askell, A., Henighan, T., Drain,\n",
      "D., Perez, E., Schiefer, N., Hatfield-Dodds, Z., DasSarma,\n",
      "N., Tran-Johnson, E., Johnston, S., El-Showk, S., Jones,\n",
      "A., Elhage, N., Hume, T., Chen, A., Bai, Y ., Bowman,\n",
      "S., Fort, S., Ganguli, D., Hernandez, D., Jacobson, J.,\n",
      "Kernion, J., Kravec, S., Lovitt, L., Ndousse, K., Olsson,\n",
      "C., Ringer, S., Amodei, D., Brown, T., Clark, J., Joseph,\n",
      "N., Mann, B., McCandlish, S., Olah, C., and Kaplan, J. Language models (mostly) know what they know. arXiv\n",
      "preprint arXiv:2207.05221, 2022. Kuhn, L., Gal, Y ., and Farquhar, S. Semantic uncertainty:\n",
      "Linguistic invariances for uncertainty estimation in natu-\n",
      "ral language generation. In International Conference on\n",
      "Learning Representations, 2023. Kuleshov, V . and Deshpande, S. Calibrated and sharp un-\n",
      "certainties in deep learning via density estimation. In\n",
      "International Conference on Machine Learning, 2022. Kumar, B., Lu, C., Gupta, G., Palepu, A., Bellamy, D.,\n",
      "Raskar, R., and Beam, A. Conformal prediction with large\n",
      "language models for multi-choice question answering. In\n",
      "ICML Neural Conversational AI TEACH workshop, 2023. Levine, Y ., Wies, N., Jannai, D., Navon, D., Hoshen, Y ., and\n",
      "Shashua, A. The inductive bias of in-context learning:\n",
      "Rethinking pretraining example design. In International\n",
      "Conference on Learning Representations, 2022. Li, M. and Vit´anyi, P. M.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "B. Inductive reasoning. In Lan-\n",
      "guage Computations, 1992.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "Li, Z., Xie, Y ., Shao, R., Chen, G., Jiang, D., and Nie,\n",
      "L. Optimus-1: Hybrid multimodal memory empowered\n",
      "agents excel in long-horizon tasks. Advances in Neural\n",
      "Information Processing Systems, 2025. Liang, K., Zhang, Z., and Fisac, J.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "F. Introspective planning:\n",
      "Aligning robots’ uncertainty with inherent task ambiguity. In Advances in Neural Information Processing Systems,\n",
      "2024. Lin, H., Wang, Z., Ma, J., and Liang, Y . Mcu: A task-centric\n",
      "framework for open-ended agent evaluation in minecraft. arXiv preprint arXiv:2310.08367, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "Lin, S., Hilton, J., and Evans, O. Teaching models to express\n",
      "their uncertainty in words. Transactions on Machine\n",
      "Learning Research, 2022a. Lin, Z., Liu, J. Z., and Shang, J. Towards collaborative\n",
      "neural-symbolic graph semantic parsing via uncertainty. In Association for Computational Linguistics, 2022b. Liu, E., Neubig, G., and Andreas, J. An incomplete loop: In-\n",
      "struction inference, instruction following, and in-context\n",
      "learning in language models. In Conference on Language\n",
      "Modeling, 2024. 10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Malinin, A. and Gales, M. Uncertainty estimation in autore-\n",
      "gressive structured prediction. In International Confer-\n",
      "ence on Learning Representations, 2021. Mielke, S.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "J., Szlam, A., Dinan, E., and Boureau, Y .-L. Reducing conversational agents’ overconfidence through\n",
      "linguistic calibration. Transactions of the Association for\n",
      "Computational Linguistics, 2022. Naeini, M.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "P., Cooper, G., and Hauskrecht, M. Obtaining\n",
      "well calibrated probabilities using bayesian binning. In\n",
      "AAAI Conference on Artificial Intelligence, 2015.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Nottingham, K., Ammanabrolu, P., Suhr, A., Choi, Y ., Ha-\n",
      "jishirzi, H., Singh, S., and Fox, R. Do embodied agents\n",
      "dream of pixelated sheep: Embodied decision making\n",
      "using language guided world modelling. In International\n",
      "Conference on Machine Learning, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Okoli, C. Inductive, abductive and deductive theorising. International Journal of Management Concepts and Phi-\n",
      "losophy, 2023. Peirce, C. S. Collected papers of charles sanders peirce . Harvard University Press, 1934. Qin, Y ., Zhou, E., Liu, Q., Yin, Z., Sheng, L., Zhang, R.,\n",
      "Qiao, Y ., and Shao, J. Mp5: A multi-modal open-ended\n",
      "embodied system in minecraft via active perception. In\n",
      "Conference on Computer Vision and Pattern Recognition,\n",
      "2024. Ren, A. Z., Dixit, A., Bodrova, A., Singh, S., Tu, S., Brown,\n",
      "N., Xu, P., Takayama, L. T., Xia, F., Varley, J., et al. Robots that ask for help: Uncertainty alignment for large\n",
      "language model planners. In Conference on Robot Learn-\n",
      "ing, 2023. Ren, A. Z., Clark, J., Dixit, A., Itkina, M., Majumdar, A.,\n",
      "and Sadigh, D. Explore until confident: Efficient explo-\n",
      "ration for embodied question answering. In Robotics:\n",
      "Science and Systems, 2024. Robinson, J. and Wingate, D. Leveraging large language\n",
      "models for multiple choice question answering. In Inter-\n",
      "national Conference on Learning Representations, 2023. Sagar, S., Taparia, A., and Senanayake, R. Failures are fated,\n",
      "but can be faded: Characterizing and mitigating unwanted\n",
      "behaviors in large-scale vision and language models. In\n",
      "International Conference on Machine Learning, 2024. Shen, Y . and Lourentzou, I. Learning by asking for embod-\n",
      "ied visual navigation and task completion. In IEEE/CVF\n",
      "Winter Conference on Applications of Computer Vision,\n",
      "2025. Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and\n",
      "Yao, S. Reflexion: Language agents with verbal rein-\n",
      "forcement learning. In Advances in Neural Information\n",
      "Processing Systems, 2024. Su, W., Wang, C., Ai, Q., Hu, Y ., Wu, Z., Zhou, Y ., and\n",
      "Liu, Y . Unsupervised real-time hallucination detection\n",
      "based on the internal states of large language models. In\n",
      "Association for Computational Linguistics, 2024. Tian, B., Luo, L., Zhao, H., and Zhou, G. Vibus: Data-\n",
      "efficient 3d scene parsing with viewpoint bottleneck and\n",
      "uncertainty-spectrum modeling. ISPRS Journal of Pho-\n",
      "togrammetry and Remote Sensing, 2022. Tian, K., Mitchell, E., Zhou, A., Sharma, A., Rafailov,\n",
      "R., Yao, H., Finn, C., and Manning, C.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "D. Just ask for\n",
      "calibration: Strategies for eliciting calibrated confidence\n",
      "scores from language models fine-tuned with human feed-\n",
      "back. In Conference on Empirical Methods in Natural\n",
      "Language Processing, 2023. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,\n",
      "M.-A., Lacroix, T., Rozi`ere, B., Goyal, N., Hambro, E.,\n",
      "Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lam-\n",
      "ple, G. Llama: Open and efficient foundation language\n",
      "models. arXiv preprint arXiv:2302.13971, 2023a. Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi,\n",
      "A., Babaei, Y ., Bashlykov, N., Batra, S., Bhargava, P.,\n",
      "Bhosale, S., et al. Llama 2: Open foundation and fine-\n",
      "tuned chat models. arXiv preprint arXiv:2307.09288 ,\n",
      "2023b. Walton, D. Abductive, presumptive and plausible arguments. Informal Logic, 2001. Walton, D. Abductive reasoning. University of Alabama\n",
      "Press, 2014. Wang, G., Xie, Y ., Jiang, Y ., Mandlekar, A., Xiao, C., Zhu,\n",
      "Y ., Fan, L., and Anandkumar, A. V oyager: An open-\n",
      "ended embodied agent with large language models. In\n",
      "NeurIPS Intrinsically-Motivated and Open-Ended Learn-\n",
      "ing Workshop, 2023a. Wang, L., Xu, W., Lan, Y ., Hu, Z., Lan, Y ., Lee, R. K.-W.,\n",
      "and Lim, E.-P. Plan-and-solve prompting: Improving\n",
      "zero-shot chain-of-thought reasoning by large language\n",
      "models. In Association for Computational Linguistics ,\n",
      "2023b. Wang, Y . and Zou, S. Online robust reinforcement learning\n",
      "with model uncertainty. Advances in Neural Information\n",
      "Processing Systems, 2021. Wang, Z., Cai, S., Chen, G., Liu, A., Ma, X., Liang, Y .,\n",
      "and CraftJarvis, T. Describe, explain, plan and select:\n",
      "11\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Interactive planning with large language models enables\n",
      "open-world multi-task agents. In Advances in Neural\n",
      "Information Processing Systems, 2023c. Wei, J., Tay, Y ., Bommasani, R., Raffel, C., Zoph, B.,\n",
      "Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Met-\n",
      "zler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang,\n",
      "P., Dean, J., and Fedus, W. Emergent abilities of large\n",
      "language models. Transactions on Machine Learning\n",
      "Research, 2022a. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,\n",
      "E., Le, Q. V ., Zhou, D., et al. Chain-of-thought prompting\n",
      "elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems, 2022b. Xiao, Y . and Wang, W. Y . On hallucination and predic-\n",
      "tive uncertainty in conditional language generation. In\n",
      "European Chapter of the Association for Computational\n",
      "Linguistics, 2021. Xiong, M., Hu, Z., Lu, X., LI, Y ., Fu, J., He, J., and Hooi, B. Can LLMs express their uncertainty? an empirical evalu-\n",
      "ation of confidence elicitation in LLMs. In International\n",
      "Conference on Learning Representations, 2024. Xu, F., Lin, Q., Han, J., Zhao, T., Liu, J., and Cambria,\n",
      "E. Are large language models really good logical rea-\n",
      "soners? a comprehensive evaluation and beyond. IEEE\n",
      "Transactions on Knowledge and Data Engineering, 2025. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,\n",
      "K., and Cao, Y . React: Synergizing reasoning and act-\n",
      "ing in language models. In International Conference on\n",
      "Learning Representations, 2023. Ye, F., Yang, M., Pang, J., Wang, L., Wong, D. F., Yilmaz, E.,\n",
      "Shi, S., and Tu, Z. Benchmarking LLMs via uncertainty\n",
      "quantification. In Neural Information Processing Systems\n",
      "Datasets and Benchmarks Track, 2024. Yildirim, M. Y ., Ozer, M., and Davulcu, H. Leveraging\n",
      "uncertainty in deep learning for selective classification. arXiv preprint arXiv:1905.09509, 2019. Yuan, Z., Yan, Y ., Sonka, M., and Yang, T. Large-scale\n",
      "robust deep auc maximization: A new surrogate loss and\n",
      "empirical studies on medical image classification. In\n",
      "International Conference on Computer Vision, 2021. Zhang, J., Lan, T., Murthy, R., Liu, Z., Yao, W., Tan, J.,\n",
      "Hoang, T., Yang, L., Feng, Y ., Liu, Z., Awalgaonkar, T.,\n",
      "Niebles, J. C., Savarese, S., Heinecke, S., Wang, H., and\n",
      "Xiong, C. Agentohana: Design unified data and train-\n",
      "ing pipeline for effective agent learning. arXiv preprint\n",
      "arXiv:2402.15506, 2024a.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "Zhang, R., Zhang, H., and Zheng, Z. Vl-uncertainty: De-\n",
      "tecting hallucination in large vision-language model via\n",
      "uncertainty estimation. arXiv preprint arXiv:2411.11919,\n",
      "2024b.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "Zhao, Z., Chai, W., Wang, X., Li, B., Hao, S., Cao, S., Ye,\n",
      "T., and Wang, G. See and think: Embodied agent in vir-\n",
      "tual environment. In European Conference on Computer\n",
      "Vision, 2025. Zhu, X., Chen, Y ., Tian, H., Tao, C., Su, W., Yang, C.,\n",
      "Huang, G., Li, B., Lu, L., Wang, X., et al. Ghost\n",
      "in the minecraft: Generally capable agents for open-\n",
      "world environments via large language models with\n",
      "text-based knowledge and memory. arXiv preprint\n",
      "arXiv:2305.17144, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "12\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 12}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "A. Definitions of Uncertainty Types\n",
      "The three fundamental forms of logical reasoning, inductive, deductive, and abductive, have long been recognized and\n",
      "studied (Peirce, 1934; Walton, 2014; Wei et al., 2022b; Levine et al., 2022; Okoli, 2023). As language models demonstrated\n",
      "extraordinary abilities, designing better reasoning mechanisms has become a popular research trend (Cheng et al., 2024; Liu\n",
      "et al., 2024). These reasoning paradigms serve as fundamental frameworks for structuring inference and decision-making\n",
      "processes, particularly in settings where uncertainty arises due to partial observations, ambiguous premises, or multiple\n",
      "plausible explanations (Xu et al., 2025). We adapt these reasoning types to the domain of embodied confidence elicitation\n",
      "and formally define and describe each uncertainty type (See Table 4). Reasoning Type Definition Uncertainty Associated Example Elicitation Method\n",
      "Inductive\n",
      "Inductive reasoning de-\n",
      "rives general principles\n",
      "from a body of observa-\n",
      "tions which means mak-\n",
      "ing broad generalizations\n",
      "based on specific obser-\n",
      "vations (Li & Vit ´anyi,\n",
      "1992). Inductive Uncertainty :\n",
      "Arises when an agent\n",
      "generalizes from limited\n",
      "observations, leading to\n",
      "potential overgeneraliza-\n",
      "tion or misclassification. An agent observes that\n",
      "all previously encoun-\n",
      "tered caves contained hos-\n",
      "tile entities and infers that\n",
      "any future cave is also\n",
      "dangerous.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 12}\n",
      "However, this\n",
      "conclusion is uncertain\n",
      "because it is based on a\n",
      "limited number of obser-\n",
      "vations. Chain-of-Thought (CoT):\n",
      "The agent systematically\n",
      "analyzes observed trends,\n",
      "considers possible excep-\n",
      "tions, and evaluates confi-\n",
      "dence in applying general-\n",
      "izations. Deductive\n",
      "Deductive reasoning is\n",
      "the process of drawing\n",
      "deductive inferences\n",
      "that start from the given\n",
      "premises and reason\n",
      "with logical rules or\n",
      "commonsense to obtain\n",
      "certain conclusions\n",
      "(Johnson-Laird, 1999;\n",
      "Goel, 2007). Deductive Uncertainty :\n",
      "Arises when an agent\n",
      "applies logical rules\n",
      "but encounters missing,\n",
      "conflicting, or incomplete\n",
      "premises, making the\n",
      "outcome uncertain. An agent knows the rule:\n",
      "”If wood is available, then\n",
      "a wooden tool can be\n",
      "crafted.” However, if it is\n",
      "uncertain whether wood\n",
      "is available, it cannot con-\n",
      "fidently conclude whether\n",
      "crafting is possible. Plan-and-Solve (P&S) :\n",
      "The agent formulates a\n",
      "set of premises, identifies\n",
      "missing dependencies,\n",
      "and assesses confidence\n",
      "in executing the task. Abductive\n",
      "The process of inferring\n",
      "the most plausible ex-\n",
      "planation for an obser-\n",
      "vation based on incom-\n",
      "plete evidence.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 12}\n",
      "Abduc-\n",
      "tion generates hypotheses\n",
      "rather than definitive con-\n",
      "clusions (Josephson &\n",
      "Josephson, 1996; Walton,\n",
      "2001). Abductive Uncertainty :\n",
      "Arises when multiple\n",
      "explanations could ac-\n",
      "count for an observation,\n",
      "with no definitive way to\n",
      "determine the correct one. An agent searching for a\n",
      "pig near a river hypothe-\n",
      "sizes that pigs and rivers\n",
      "may exist in any of the\n",
      "four cardinal directions\n",
      "but lacks direct evidence\n",
      "to confirm a single hy-\n",
      "pothesis. Top-K Reasoning : The\n",
      "agent generates multi-\n",
      "ple plausible hypotheses,\n",
      "assigns probability esti-\n",
      "mates to each, and ranks\n",
      "them by likelihood. Table 4.Definitions of reasoning types, their associated uncertainty, examples, and the corresponding elicitation methods. Inductive Uncertainty arises when an agent generalizes from specific observations to broader conclusions based on\n",
      "incomplete data. Induction relies on identifying patterns from limited experiences, leading to inherent uncertainty. This\n",
      "is particularly relevant in open-world environments, where observations are partial, and inferred generalizations may not\n",
      "always hold. For example, an agent navigating an unfamiliar environment may observe that all previously encountered caves\n",
      "contained hostile entities. Based on this pattern, it may infer that any future cave is also dangerous. However, since this\n",
      "conclusion is based on a limited set of observations rather than a deterministic rule, the agent must assess how strongly its\n",
      "past experiences justify this generalization, introducing inductive uncertainty. To elicit inductive uncertainty, we employ Chain-of-Thought (Wei et al., 2022b), which prompts the agent to explicitly reflect\n",
      "on the reliability of its observed patterns. By systematically verbalizing its reasoning, the agent is encouraged to: (1) analyze\n",
      "the strength of observed trends, (2) consider possible exceptions or contradictory evidence, and (3) assess its confidence\n",
      "in applying the generalization to new situations. This structured elicitation enables the agent to express uncertainty in its\n",
      "inductive inferences rather than assuming patterns always hold. Deductive Uncertainty arises when an agent faces ambiguity due to missing, conflicting, or incomplete premises. Deductive\n",
      "13\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 13}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "uncertainty occurs within a structured decision-making process when the available information is insufficient to determine\n",
      "a definitive outcome. Consider an agent tasked with crafting a wooden tool in a survival environment. It knows the rule:\n",
      "”If wood is available, then a wooden tool can be crafted.” However, if the agent is uncertain whether wood is currently\n",
      "accessible, it cannot confidently conclude whether crafting is possible. This scenario exemplifies deductive uncertainty,\n",
      "where the agent’s ability to reason is constrained by unknown or ambiguous premises. To elicit deductive uncertainty, we usePlan-and-Solve prompting (Wang et al., 2023b), which guides the agent through a\n",
      "structured reasoning process. The agent is encouraged to: (1) formulate a comprehensive set of premises relevant to the task,\n",
      "(2) identify any missing premises or dependencies, and (3) assess its confidence in executing each step successfully. This\n",
      "structured elicitation enables the agent to explicitly express uncertainty when premises are incomplete or insufficient to\n",
      "deduce a definitive conclusion. Abductive Uncertainty occurs when an agent must infer the most plausible explanation for an observation without definitive\n",
      "evidence. Abduction involves hypothesis generation under uncertainty. The challenge in abductive reasoning lies in selecting\n",
      "the most probable explanation when multiple interpretations exist, each carrying some degree of uncertainty. A simple\n",
      "example occurs when an agent is tasked with locating a pig near a river for unspecified reasons. Given its environment, the\n",
      "agent may hypothesize that pigs and rivers could exist in any of the four cardinal directions but are unlikely to be present in\n",
      "all directions simultaneously. Since the agent lacks direct evidence to confirm a single hypothesis, it must infer the most\n",
      "plausible explanation, leading to abductive uncertainty. To elicit abductive uncertainty, we implementTop-K reasoning(Robinson & Wingate, 2023), where the agent is instructed\n",
      "to generate multiple plausible hypotheses explaining an observation and assign probability estimates to each. This process\n",
      "forces the agent to explicitly consider alternative interpretations, rank them by likelihood, and communicate the level of\n",
      "confidence in its inferences. By quantifying uncertainty across multiple competing hypotheses, Top-K reasoning reveals the\n",
      "agent’s abductive reasoning capabilities. B.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 13}\n",
      "Task Setting Details\n",
      "Inspired by previous works (Lin et al., 2023; Qin et al., 2024), we define a set of 30 tasks evenly distributed across three\n",
      "difficulty levels: easy, medium, and hard. Categorization is based on the complexity of reasoning required and the extent\n",
      "of contextual information necessary for successful task completion.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 13}\n",
      "Each difficulty level incorporates distinct challenges,\n",
      "ranging from straightforward operations to intricate reasoning across interdependent objectives, with a balanced distribution\n",
      "of complexity within the task set. We present all tasks and highlight entities of different categories in Table 5\n",
      "Easy Tasks are designed to evaluate the agent’s ability to process minimal perceptual information and perform straightfor-\n",
      "ward actions with limited reasoning. These tasks typically require the perception of only one environmental element from\n",
      "predefined categories such as Object, Mob, Ecology, Time, Weather, or Brightness (Qin et al., 2024). For example, tasks\n",
      "at this level may involve identifying a specific object in the environment or recognizing a simple temporal condition (e.g.,\n",
      "daytime or nighttime). The actions required are relatively simple and involve a single reasoning step, such as gathering an\n",
      "object that is readily visible. Medium Tasks introduce moderate complexity by requiring the perception and integration of two to three environmental\n",
      "elements, alongside a corresponding increase in reasoning steps. Tasks at this level involve combining multiple types of\n",
      "perceptual data, such as recognizing a specific biome and locating a particular mob or object within it. For example, the\n",
      "agent might need to identify a forest biome, locate a pig, and gather specific materials. In addition to perceptual challenges,\n",
      "medium tasks often include sequential sub-goals, such as collecting and combining resources to create basic tools. These\n",
      "tasks require the agent to interpret dynamic environmental information, execute plans involving multiple steps, and adapt to\n",
      "minor changes in the environment. This level evaluates the agent’s ability to balance perception, reasoning, and adaptability. Hard Tasks are the most challenging and require the agent to process and integrate multiple layers of perceptual information\n",
      "(up to six elements) while performing complex situation-aware planning and dynamic action execution. These tasks involve\n",
      "a high level of reasoning, such as decomposing long-term objectives into interdependent sub-tasks, managing uncertainties\n",
      "in the environment, and dynamically adjusting strategies in response to real-time changes. For example, a hard task might\n",
      "involve navigating through hazardous biomes, identifying and gathering multiple resources, and crafting advanced tools or\n",
      "items that require sequential processing and the use of specialized platforms. Environmental conditions, such as weather,\n",
      "time of day, or changing brightness, may dynamically impact the task, necessitating constant adaptation by the agent. These\n",
      "tasks often introduce significant challenges, such as hostile mobs or the need to traverse difficult terrain, testing the agent’s\n",
      "14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 14}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Mine Wood Log\n",
      "Craft Wooden\n",
      "Planks\n",
      "Craft Sticks\n",
      "Craft Wooden\n",
      "Pickaxe\n",
      "Craft Stone\n",
      "Pickaxe\n",
      "Mine\n",
      "Cobblestone\n",
      "Craft\n",
      "CraftingTable\n",
      "Craft Iron\n",
      "Pickaxe\n",
      "Smelt Raw\n",
      "Iron\n",
      "Mine Iron Ore\n",
      "Mine Coal Ore\n",
      "Craft Furnace\n",
      "Obtain Diamond\n",
      "Figure 6.An illustrative diagram of the Obtain Diamond task, featuring five distinct colors to represent the source materials re-\n",
      "quired—wood, stone, iron, coal, and diamond—aligned with the Minecraft tech tree. ability to balance perception, planning, and execution effectively. The (obtain) Diamond Task is one of the most iconic and challenging benchmarks in Minecraft agent research, serving as a\n",
      "comprehensive test of an agent’s long-horizon planning, resource management, and adaptability. The task requires the agent\n",
      "to progress through multiple interdependent steps, including gathering basic resources like wood and stone, crafting tools\n",
      "such as a pickaxe, and locating and mining diamonds deep within underground caves (See Figure 6). Each step presents\n",
      "its own set of challenges, such as navigating complex terrain, managing limited resources, and avoiding environmental\n",
      "hazards like lava or hostile mobs. The randomized nature of Minecraft’s procedural world generation further compounds\n",
      "the difficulty, as the agent must adapt dynamically to new environments while maintaining focus on the ultimate objective. Success in the “Obtain Diamond” task is often seen as a key indicator of an agent’s ability to integrate active perception,\n",
      "situational awareness, and embodied action execution in an open-world setting. This task demonstrates the complexity\n",
      "of open-ended problem-solving and has become a gold standard for evaluating the capabilities of autonomous agents in\n",
      "multi-modal and multi-step scenarios. We added the diamond task as one of our hard tasks.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 14}\n",
      "C. Detailed Model Descriptions\n",
      "GPT-4V:This vision-capable variant of GPT-4 excels at processing both visual and textual inputs, making it a powerful\n",
      "tool for tackling tasks within the visually complex Minecraft environment. Unlike its predecessors, GPT-4V’s ability to\n",
      "seamlessly combine perception and reasoning allows for sophisticated decision-making and planning. The GPT-4 series\n",
      "has already demonstrated its efficacy in Minecraft-based research. For instance, V oyager (Wang et al., 2023a), the first\n",
      "LLM-powered embodied lifelong learning agent, used GPT-4 to facilitate continuous exploration, skill acquisition, and task\n",
      "execution without human intervention. V oyager’s architecture included an automatic curriculum for exploration and a skill\n",
      "library to store and retrieve executable code, allowing agents to adapt and improve iteratively. Similarly, Optimus-1 (Li\n",
      "et al., 2025) employs GPT-4V to refine its planning processes, focusing on logical reasoning and task generalization. These\n",
      "implementations underscore GPT-4V’s pivotal role in advancing embodied AI research, offering exceptional capabilities for\n",
      "both exploration and problem-solving. MineLLM: Tailored specifically for tasks within Minecraft, MineLLM represents a significant leap in AI development\n",
      "for complex embodied environments. As a central component of the MP5 framework (Qin et al., 2024), MineLLM is\n",
      "designed to tackle the unique challenges posed by Minecraft’s open-ended tasks. It combines the image visual encoder\n",
      "from MineCLIP (Fan et al., 2022) with the Vicuna-13B-v1.5 language model for integrating visual perception with natural\n",
      "15\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 15}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Difficulty Task ID Task Description\n",
      "Easy\n",
      "1 Find a pig\n",
      "2 Find a cow\n",
      "3 Find a tree\n",
      "4 Mine log\n",
      "5 Mine sand\n",
      "6 Craft a plank\n",
      "7 Craft a stick\n",
      "8 Craft a chest\n",
      "9 Craft a wooden door\n",
      "10 Craft a wooden boat\n",
      "Medium\n",
      "11 Find a tree\n",
      " in the forest\n",
      "12 Find a pig\n",
      " on grass\n",
      "13 Find a cow\n",
      " in the desert\n",
      "14 Craft a wooden sword\n",
      "15 Craft a wooden pickaxe\n",
      "16 Craft a stone pickaxe\n",
      "17 Smelt an iron ingot\n",
      "18 Smelt glass\n",
      "19 Cook beef\n",
      "20 Cook mutton\n",
      "Hard\n",
      "21 Find a pig\n",
      " near a grass\n",
      " in the forest\n",
      " during the daytime\n",
      "22 Find a cow\n",
      " in the desert\n",
      " during the daytime\n",
      "23 Find a grass\n",
      " near a pig\n",
      " in the forest\n",
      "24 Find a pig\n",
      " while wearing an iron helmet\n",
      "25 Craft an iron door\n",
      "26 Craft an iron pickaxe\n",
      "27 Craft an iron sword\n",
      "28 Craft a compass\n",
      "29 Kill a zombie\n",
      " with an iron sword\n",
      "30 Obtain a diamond\n",
      "Table 5.Full task details. 30 tasks evenly distributed as easy, medium, and hard.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 15}\n",
      "Underlines label different information categories in\n",
      "Minecraft, highlighting how the complexity varies at each level. 16\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 16}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "language understanding. Trained on a vast dataset of 500,000 Minecraft-specific image-text instruction pairs, MineLLM\n",
      "can generate detailed insights about the game environment, answer complex queries, and provide contextual guidance for\n",
      "planning and execution. Its integration into MP5 enables the framework to address context- and process-dependent tasks\n",
      "with remarkable success rates, achieving a 91% success rate on context-dependent tasks and demonstrating exceptional\n",
      "adaptability in novel scenarios. STEVE: The STEVE series represents another advancement in language model-driven embodied agents for the Minecraft\n",
      "environment (Zhao et al., 2025). Built upon the foundation of LLaMA-2 (Touvron et al., 2023b), STEVE integrates powerful\n",
      "language capabilities tailored to enhance task reasoning, contextual understanding, and interaction. At its core, the language\n",
      "model in the STEVE series excels at decomposing complex objectives into actionable subtasks through iterative reasoning\n",
      "and hierarchical planning. This allows STEVE agents to process high-level instructions effectively and generate detailed\n",
      "plans for task execution. The STEVE series relies heavily on its ability to adapt to Minecraft-specific tasks. To this end,\n",
      "Zhao et al. (2025) curated the STEVE-21K dataset, containing 20K knowledge-based question-answering pairs and 200+\n",
      "skill-code pairs that directly enhance the model’s contextual understanding and task reasoning. These adaptations enable the\n",
      "language model to seamlessly integrate with perception and action modules, driving coherent decision-making in real time. Furthermore, STEVE agents leverage advanced contextual awareness to refine their decision-making processes, significantly\n",
      "outperforming prior benchmarks in task decomposition and completion efficiency. The series also demonstrated up to 1.5x\n",
      "faster progression in complex tasks like unlocking tech trees and up to 2.5x quicker performance in block search scenarios\n",
      "compared to other state-of-the-art models.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 16}\n",
      "D. Additional Experiments\n",
      "Do Hard Tasks Lead to Poor Calibration? We use the best-performing GPT-4V as our agent backbone and withhold any\n",
      "execution policies to reduce computation costs. We set the maximum episode length as 12,000 to provide enough coverage\n",
      "for all task difficulties.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 16}\n",
      "Results are shown in Table 6. Task Policies ECE ( ↓) AUROC ( ↑) Success Rate ( ↑)\n",
      "Easy\n",
      "Vanilla 0.26 0.76 84%\n",
      "Self-Intervention 0.26 0.76 92%\n",
      "CoT 0.11 0.78 94%\n",
      "P&S 0.12 0.80 82%\n",
      "Top-K 0.32 0.72 74%\n",
      "Medium\n",
      "Vanilla 0.35 0.54 52%\n",
      "Self-Intervention 0.35 0.51 44%\n",
      "CoT 0.22 0.58 54%\n",
      "P&S 0.22 0.55 48%\n",
      "Top-K 0.40 0.47 32%\n",
      "Hard\n",
      "Vanilla 0.33 0.58 17%\n",
      "Self-Intervention 0.35 0.52 12%\n",
      "CoT 0.31 0.68 18%\n",
      "P&S 0.32 0.71 18%\n",
      "Top-K 0.41 0.49 8%\n",
      "Table 6.ECE, AUROC, and Success Rates for Different Task Difficulties and Elicitation Policies. Lower ECE and higher AUROC/Success\n",
      "Rates indicate better performance. For Easy tasks, CoT demonstrated the best performance, achieving the lowest ECE (0.11) and the highest success rate\n",
      "(94%), followed by P&S, which recorded the highest AUROC of 0.80 and a success rate of 82%. Self-Intervention performed\n",
      "comparably in calibration (ECE = 0.26, AUROC = 0.76). Top-K underperformed, with the highest ECE (0.32) and the\n",
      "lowest success rate (74%), indicating limitations in leveraging task simplicity. For Medium tasks, all policies showed\n",
      "noticeable declines in performance. CoT emerged as the best overall, with an ECE of 0.22, an AUROC of 0.58, and a\n",
      "success rate of 54%, balancing calibration and task success effectively. P&S followed closely with similar calibration (ECE\n",
      "= 0.22) but a slightly lower AUROC (0.55) and success rate (48%). For Hard tasks, performance further degraded across\n",
      "all policies. CoT and P&S maintained relative superiority, with CoT achieving an ECE of 0.31, AUROC of 0.68, and a\n",
      "success rate of 22%, while P&S recorded slightly worse calibration (ECE = 0.32) and the highest AUROC (0.71) but tied for\n",
      "a success rate of 18%. 17\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 17}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "These results confirm our hypothesis that as task difficulty increases, confidence calibration significantly deteriorates, with\n",
      "the ECE gap increasing as high as 0.20 (Easy CoT vs. Hard CoT). However, the results also demonstrate that structured\n",
      "elicitation policies, such as CoT and P&S, consistently prove effective in handling calibration, failure prediction, and task\n",
      "success across task difficulties. Additionally, simpler policies like Self-Intervention also show moderate success, particularly\n",
      "in easier tasks, suggesting their utility in less demanding scenarios.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 17}\n",
      "18\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"총 {len(docs)}개 만큼의 문서로 청킹되었습니다.\")\n",
    "print([len(i.page_content) for i in docs])\n",
    "\n",
    "# 각 청크의 메타데이터 및 내용 출력\n",
    "for i in docs:\n",
    "    print(i.metadata)       # 문서의 메타데이터 출력 (예: 페이지 번호 등)\n",
    "    print(i.page_content)   # 분할된 청크의 내용 출력\n",
    "    print(\"-\" * 100)        # 구분선 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오픈소스 임베딩 모델을 활용한 시맨틱 청킹  \n",
    "오픈소스 임베딩 모델을 활용하여 텍스트의 의미를 벡터로 변환하고, 이를 기반으로 효과적인 청킹을 수행하는 방법을 실습합니다.  \n",
    "\n",
    "**bge-m3**는 BGE(Bilingual General Embeddings) 시리즈 중 하나로, **텍스트 임베딩(embedding)**을 생성하는 강력한 모델입니다. 주로 정보 검색(Retrieval), 문서 분류, 시맨틱 검색(Semantic Search) 등 다양한 자연어 처리(NLP) 작업에서 활용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-ollama) (0.3.28)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-ollama) (0.4.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.2.4)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (9.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from ollama<1,>=0.4.4->langchain-ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (4.7.0)\n",
      "Requirement already satisfied: certifi in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.4.4->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/erika/.pyenv/versions/3.11.11/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-ollama) (2.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling daec91ffb5dd... 100% ▕████████████████▏ 1.2 GB                         \n",
      "pulling a406579cd136... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling 0c4c9c2a325f... 100% ▕████████████████▏  337 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "#\"bge-m3\" 모델을 다운로드 및 설치 (설치가 안 되어 있다면 다운로드)\n",
    "# !ollama pull bge-m3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n",
      "along with Execution Policies, which enhance\n",
      "confidence calibration through scenario reinter-\n",
      "pretation, action sampling, and hypothetical rea-\n",
      "soning. Evaluating agents in calibration and fail-\n",
      "ure prediction tasks within the Minecraft envi-\n",
      "ronment, we show that structured reasoning ap-\n",
      "proaches, such as Chain-of-Thoughts, improve\n",
      "confidence calibration. However, our findings\n",
      "also reveal persistent challenges in distinguishing\n",
      "uncertainty, particularly under abductive settings,\n",
      "underscoring the need for more sophisticated em-\n",
      "bodied confidence elicitation methods.\n"
     ]
    }
   ],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "# PDF 파일 경로 설정\n",
    "file_path = \"data/arxiv_paper.pdf\"\n",
    "\n",
    "# LangChain의 PyPDFLoader를 사용하여 PDF 로드\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# PDF 로더 객체 생성\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "# PDF의 각 페이지를 저장할 리스트\n",
    "pages = []\n",
    "\n",
    "# 비동기 방식으로 PDF의 각 페이지를 로드 \n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "# SemanticChunker를 사용하여 의미 기반으로 텍스트를 분할\n",
    "# OllamaEmbeddings의 \"bge-m3\" 모델을 사용하여 임베딩 생성\n",
    "text_splitter = SemanticChunker(OllamaEmbeddings(model=\"bge-m3\"))\n",
    "\n",
    "# 문서를 의미적 청킹(Semantic Chunking) 수행\n",
    "docs = text_splitter.split_documents(pages)\n",
    "\n",
    "# 첫 번째 청크의 내용 출력\n",
    "print(docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 60개 만큼의 문서로 청킹되었습니다.\n",
      "[1315, 786, 2014, 3140, 1083, 1889, 1438, 838, 2238, 2863, 925, 1597, 1742, 3402, 495, 1021, 2477, 1700, 1392, 1982, 1610, 498, 58, 4088, 2511, 433, 1544, 213, 153, 597, 473, 1074, 1476, 596, 499, 414, 547, 79, 229, 1420, 1892, 2424, 176, 463, 2, 1425, 1108, 2219, 2463, 338, 2792, 1828, 1623, 901, 120, 2047, 281, 1679, 233, 382]\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n",
      "along with Execution Policies, which enhance\n",
      "confidence calibration through scenario reinter-\n",
      "pretation, action sampling, and hypothetical rea-\n",
      "soning. Evaluating agents in calibration and fail-\n",
      "ure prediction tasks within the Minecraft envi-\n",
      "ronment, we show that structured reasoning ap-\n",
      "proaches, such as Chain-of-Thoughts, improve\n",
      "confidence calibration. However, our findings\n",
      "also reveal persistent challenges in distinguishing\n",
      "uncertainty, particularly under abductive settings,\n",
      "underscoring the need for more sophisticated em-\n",
      "bodied confidence elicitation methods.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "1. Introduction\n",
      "In complex embodied environments, success depends not\n",
      "only on what an agent knows but also on how well it un-\n",
      "derstands and communicates uncertainty. Whether navi-\n",
      "gating a cluttered space, interacting with objects, or plan-\n",
      "ning long-term strategies, eliciting confidence is pivotal as\n",
      "agents must interpret and interact with dynamic settings\n",
      "in real-time while managing uncertainty from both percep-\n",
      "tion and decision-making processes (Ren et al., 2023; Liang\n",
      "et al., 2024). For humans, this instinctive ability to express\n",
      "and calibrate uncertainty is fundamental to decision-making\n",
      "and social interaction. As AI systems are increasingly de-\n",
      "ployed in high-stakes contexts such as autonomous driving\n",
      "or healthcare, they must also acquire this crucial skill. *Preprint.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 0}\n",
      "Work in progress. Embodied Environment\n",
      "Elicitation Module\n",
      "Are you sure about yournext action? Elicitation Module\n",
      "Are you sure aboutwhat you see? Elicitation\n",
      "Policies\n",
      "Execution\n",
      "Policies\n",
      "Elicitation\n",
      "Policies\n",
      "Execution\n",
      "Policies\n",
      "Perception Stage\n",
      "Action Stage\n",
      "Figure 1.Embodied Confidence Estimation Framework consist-\n",
      "ing of Elicitation Policies and Execution Policies, which jointly\n",
      "enable an agent to assess and express its confidence. Elicitation\n",
      "Modules prompt the agent to evaluate uncertainty in what it sees\n",
      "and does, while Execution Policies refine confidence calibration\n",
      "by expanding the agent’s reasoning space (See §3 for details). Specifically, accurate confidence elicitation from AI systems\n",
      "provides critical insights for risk assessment, error mitiga-\n",
      "tion, and system reliability in decision-making (Kuleshov\n",
      "& Deshpande, 2022; Clark, 2015; Yildirim et al., 2019). This is particularly important in open-ended reasoning tasks,\n",
      "where models may generate outputs that are semantically\n",
      "plausible but factually incorrect, a phenomenon commonly\n",
      "referred to as hallucination (Xiao & Wang, 2021). How-\n",
      "ever, confidence elicitation in embodied AI is particularly\n",
      "challenging. For instance, in open-ended environments such\n",
      "as Minecraft, an agent may misinterpret visual cues due\n",
      "to limited viewpoints or struggle to determine the correct\n",
      "action sequence to achieve complex goals (e.g., obtaining\n",
      "a diamond). These illustrate the broader difficulties in elic-\n",
      "iting confidence in embodied environments, where agents\n",
      "must navigate uncertainty at multiple levels. Confidence elicitation in open-ended embodied environ-\n",
      "ments faces several challenges, including: 1) Multimodal\n",
      "understanding, where the agent must assess uncertainty from\n",
      "inputs across different interconnected modalities. 2) Granu-\n",
      "larity of confidence estimation, where the agent evaluates\n",
      "confidence not only in performing specific actions (e.g., “I\n",
      "am 90% confident I can collect some wood”) but also in\n",
      "1\n",
      "arXiv:2503.10628v1  [cs.AI]  13 Mar 2025\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "understanding high-level tasks or goals ( e.g., “I am 70%\n",
      "confident I craft a wooden table”). 3) Interactive depen-\n",
      "dencies, where the agent’s actions directly influence the\n",
      "environment, which in turn affects subsequent decisions,\n",
      "requiring ongoing adjustments to confidence estimates as\n",
      "tasks progress. 4) Finally, while state-of-the-art embodied\n",
      "agents leverage proprietary Large Language Models (LLMs)\n",
      "and Vision-Language Models (VLMs) for their strong mul-\n",
      "timodal understanding and reasoning capabilities (Wang\n",
      "et al., 2023a; Qin et al., 2024; Zhu et al., 2023), these of-\n",
      "ten lack access to internal token likelihoods or probabilistic\n",
      "outputs, making traditional confidence estimation methods\n",
      "ineffective (Kumar et al., 2023; Chen et al., 2024b). To address these challenges, we present the first system-\n",
      "atic approach that enables LLM/VLM-powered embodied\n",
      "agents to assess and articulate their confidence across multi-\n",
      "modal inputs, multiple granularities, and dynamic embodied\n",
      "environments. Our contributions are as follows: (1) We\n",
      "propose a framework for embodied verbalized confidence\n",
      "elicitation in multimodal open-ended environments. (2) As\n",
      "illustrated in Figure 1, we introduce Elicitation and Execu-\n",
      "tion Policies to enhance confidence estimation in embodied\n",
      "settings. Elicitation Policies target different types of un-\n",
      "certainties arising from inductive, deductive, and abductive\n",
      "reasoning, while also facilitating multi-granular confidence\n",
      "estimation, allowing agents to assess uncertainty at both\n",
      "perception and action stages. Execution Policies improve\n",
      "robust elicitation across diverse scenarios, plans, and actions\n",
      "while tackling interactive dependencies by incorporating ad-\n",
      "ditional information about the environment and expanding\n",
      "potential action trajectories. (3) We provide the first struc-\n",
      "tured analysis of embodied uncertainty and identify effective\n",
      "methods for improving confidence calibration and failure\n",
      "prediction, while also pinpointing persistent challenges. The following are key observations from our analysis:\n",
      "(1) Elicitation Policies are Effective But Vary by Context:\n",
      "While all proposed elicitation policies improve confidence\n",
      "calibration and failure prediction, their effectiveness varies\n",
      "based on task complexity and uncertainty type, highlighting\n",
      "the need for adaptive strategies that align with the embodied\n",
      "agent’s reasoning process and environment demands. (2) Execution Policies Amplify Reliable Embodied Con-\n",
      "fidence Elicitation: Execution policies enhance the robust-\n",
      "ness of elicited confidence as they expand the range of avail-\n",
      "able actions and scenario interpretations, enabling agents to\n",
      "assess their confidence levels more effectively based on a\n",
      "broader set of potential outcomes. (3) Model Differences Persist: While all models benefit\n",
      "from the proposed policies, differences in their inherent\n",
      "reasoning and representation capabilities lead to significant\n",
      "variability in confidence calibration and task success rates,\n",
      "highlighting the importance of tailoring elicitation and exe-\n",
      "cution strategies to each model’s strengths and limitations. 2.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "Related Works\n",
      "Confidence Elicitation. Confidence elicitation for tradi-\n",
      "tional machine learning is well-studied (Abdar et al., 2021;\n",
      "Gawlikowski et al., 2023). One stream of work focuses on\n",
      "unsupervised methods leveraging entropy (Malinin & Gales,\n",
      "2021), graph semantic parsing (Lin et al., 2022b), semantic\n",
      "features (Kuhn et al., 2023; Farquhar et al., 2024), and logit\n",
      "or hidden state information (Su et al., 2024; Chen et al.,\n",
      "2024a) to craft uncertainty metrics. Another explores con-\n",
      "formal prediction for tasks like part-of-speech tagging (Dey\n",
      "et al., 2022), paraphrase detection (Giovannotti & Gam-\n",
      "merman, 2021), and fact verification (Fisch et al., 2021),\n",
      "offering statistically robust coverage guarantees (Kumar\n",
      "et al., 2023; Ye et al., 2024). However, these solutions often require full model access,\n",
      "making them less applicable to black-box language models,\n",
      "which are increasingly prevalent in real-world applications\n",
      "(Achiam et al., 2023; Touvron et al., 2023a). Additionally,\n",
      "their free-form nature of outputs further complicates the\n",
      "application of traditional methods.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 1}\n",
      "As a result, alternative\n",
      "approaches have been proposed, including estimating un-\n",
      "certainty by directly querying models for confidence scores\n",
      "after generating responses (Xiong et al., 2024; Kadavath\n",
      "et al., 2022; Lin et al., 2022a; Mielke et al., 2022; Chen &\n",
      "Mueller, 2024). Despite these advancements, existing meth-\n",
      "ods are not designed for embodied tasks, where confidence\n",
      "elicitation must address the challenges of multimodal per-\n",
      "ception, hierarchical reasoning and planning across various\n",
      "open-ended tasks, as well as non-deterministic interactions. LLM-based Embodied Agents. With the advent of lan-\n",
      "guage models, leveraging their reasoning and planning abili-\n",
      "ties to empower embodied agents has become quintessential\n",
      "(Huang et al., 2023; Yao et al., 2023; Chen et al., 2023;\n",
      "Zhang et al., 2024a; Shinn et al., 2024; Christianos et al.,\n",
      "2023). In the meantime, Minecraft’s open-ended nature\n",
      "with its adaptable mechanics and varied challenges, makes\n",
      "it a compelling benchmark for embedding reasoning and\n",
      "planning capabilities into language model-driven embod-\n",
      "ied agents (Wang et al., 2023a;c; Zhu et al., 2023). Re-\n",
      "cent works leverage pre-trained language models to control\n",
      "agents by generating continuous operation instructions or ex-\n",
      "ecutable policies. For example, some approaches (Zhu et al.,\n",
      "2023; Wang et al., 2023c) directly utilize scene data from\n",
      "simulation platforms like MineDojo (Fan et al., 2022) and\n",
      "MineRL (Guss et al., 2019), while others (Qin et al., 2024)\n",
      "rely on Vision-Language Models (VLMs) for perception. However, because language models are used in various\n",
      "roles—such as planners, critics, or perceivers—errors and in-\n",
      "accuracies often arise at different process stages (Guo et al.,\n",
      "2024; Driess et al., 2023). These challenges underscore\n",
      "the need for frameworks capable of systematically identi-\n",
      "fying and localizing sources of uncertainty, which we aim\n",
      "2\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 2}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ElicitationPolicies What do you see?How confident are you? I see a pig next to\n",
      "a tree to the left [85% confident]\n",
      "ExecutionPolicies\n",
      "What do you see? Especially\n",
      "around the pig. How\n",
      "confident are you? What do you see? Especially\n",
      "around the trees. Howconfident are you? What do you see? Especially\n",
      "to your right. How confident\n",
      "are you? I see a pig with two trees \n",
      "[80% confident]\n",
      "I see sheeps and cows \n",
      "[90% confident]\n",
      "I see a mountain to the left\n",
      "[70% confident]\n",
      "Agent Answers: \n",
      "Vanilla Elicitation + Scene Reinterpretation:\n",
      " Execution Policies\n",
      "Action Sampling\n",
      "Scenario-\n",
      "Reinterpretation\n",
      "Hypothetical-\n",
      "Reasoning\n",
      " Elicitation Policies\n",
      "Vanilla\n",
      "Self-Intervention\n",
      "CoT \n",
      "P&S\n",
      "Top-K\n",
      "Figure 2.Embodied Confidence Elicitation. Elicitation Policies (§3.2) enable agents to express uncertainty, while Execution Policies\n",
      "(§3.3) refine and expand confidence assessment through scenario reinterpretation, action sampling, and hypothetical reasoning. Together,\n",
      "they enhance confidence calibration in embodied agents. The orange text represents the vanilla elicitation policy, which incorporates the\n",
      "vanilla confidence prompt (described in Table 1) into the original instruction. The brown arrows\n",
      " denote the Scenario-Reinterpretation\n",
      "execution policy, prompting the agent to generate additional scene insights. to address by designing a unified approach that enhances\n",
      "reliability and robustness in embodied agents.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 2}\n",
      "Uncertainty in Embodied Models. Uncertainty estima-\n",
      "tion is well explored in robot learning and reinforcement\n",
      "learning (Wang & Zou, 2021; Ghasemipour et al., 2022; He\n",
      "et al., 2023; Huang et al., 2019; Jin et al., 2023), but remains\n",
      "a challenge for language models (Tian et al., 2023; Groot\n",
      "& Valdenegro Toro, 2024; Zhang et al., 2024b). While\n",
      "recent efforts have sought to quantify and mitigate uncer-\n",
      "tainty (Sagar et al., 2024; Tian et al., 2022), the problem is\n",
      "further compounded in embodied AI settings, where agents\n",
      "must reason and act in dynamic multimodal environments\n",
      "(Ren et al., 2024; Shen & Lourentzou, 2025). Our work\n",
      "introduces a structured approach to verbalized confidence\n",
      "elicitation in embodied open-ended multimodal environ-\n",
      "ments to enable agents to express uncertainty and adapt to\n",
      "complex real-world interactions. 3.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 2}\n",
      "Method\n",
      "3.1. Problem Formulation & Framework Design\n",
      "Let E denote the embodied environment, characterized by\n",
      "multimodal sensory inputs I = {Iv, It}, where Iv repre-\n",
      "sents visual observations and It represents task instructions\n",
      "and other types of language-based guidance. For a given\n",
      "task T , the agent operates under a policy π : I → Athat\n",
      "maps input I to actions A. The task of embodied confidence\n",
      "elicitation is to enable agents to estimate and articulate a\n",
      "confidence score c ∈ [0, 1], representing their belief in the\n",
      "correctness of their perception and subsequent actions. The challenge lies in systematically identifying, quantify-\n",
      "ing, and articulating uncertainty as the agent interacts with\n",
      "its environment and executes tasks. This requires not only\n",
      "detecting uncertain aspects of the agent’s perception, reason-\n",
      "ing, or actions but also ensuring that confidence estimates\n",
      "are refined and reliable under dynamic multimodal condi-\n",
      "tions. To address this, we propose an embodied confidence\n",
      "estimation framework centered around Elicitation Modules\n",
      "that facilitates confidence elicitation at two critical points\n",
      "of interaction between the agent and its environment: Per-\n",
      "ception Stage, where the agent processes sensory input\n",
      "from the environment and assesses its confidence in what\n",
      "it perceives before engaging in reasoning or planning. Ac-\n",
      "tion Stage, which evaluates the agent’s confidence after\n",
      "reasoning, just before executing an action. Each Elicitation Module operates under a specific Elicita-\n",
      "tion Policy (§3.2), which defines what type of uncertainty\n",
      "is being expressed, focusing on quantifying confidence in\n",
      "the agent’s perception, reasoning, or action planning. Ad-\n",
      "ditionally, an Execution Policy (§3.3) determines how to\n",
      "collect and refine confidence, ensuring robust and adaptive\n",
      "estimates in complex, dynamic environments. An overview\n",
      "of the overall proposed method is shown in Figure 2. 3.2. Elicitation Policies\n",
      "Our confidence Elicitation Policies are designed to address\n",
      "distinct types of inferential uncertainty that embodied agents\n",
      "encounter in open-world long-horizon tasks. As these agents\n",
      "actively reason to determine their next actions, we draw in-\n",
      "spiration from rich studies on reasoning in language models\n",
      "3\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 3}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Method Prompt\n",
      "Vanilla\n",
      "Read the task (e.g., collect wood, build a shelter), provide your answer, and explain how confident\n",
      "you are in perceiving the environment accurately to complete the task (e.g., recognizing resources,\n",
      "locating structures, identifying threats). Read the task given, provide your answer, and explain how confident you are in planning and executing\n",
      "the actions needed to achieve the goal (e.g., gathering materials, crafting tools, building a structure). Vanilla\n",
      "+\n",
      "Self-Intervention\n",
      "Task: [...], Perceived Situation: [...] Q: How confident you are in perceiving the environment\n",
      "accurately to complete the task? Task: [...], Planned Action: [...] Q: How confident you are in planning and executing the actions\n",
      "needed to achieve the goal? Chain-of-Thought\n",
      "(CoT)\n",
      "Read the task, analyze step by step what you perceive in the environment (e.g., observe surroundings,\n",
      "identify items), provide your answer, and evaluate your confidence based on the clarity and quality of\n",
      "the environment observations. Read the task, analyze step by step how to complete the task, provide your answer, and evaluate your\n",
      "confidence in successfully planning and executing each action needed to achieve the goal. Plan & Solve\n",
      "(P&S)\n",
      "Analyze the task, devise a systematic approach to perceive your environment effectively. (e.g., locating\n",
      "resources, identifying obstacles), and evaluate your confidence based on how well you perceive the\n",
      "environment. Analyze the task, devise a plan of actions needed to complete it, then evaluate your confidence in\n",
      "executing each action and achieving the desired outcome. Top-K\n",
      "Provide your K best descriptions of your perceptions of the environment and the probability that each\n",
      "is correct (0% to 100%). Provide your K best plans of the possible actions to take and the probability that each will succeed\n",
      "(0% to 100%). Table 1.Prompts for Different Elicitation Policies in generalist embodied Minecraft agents. Orange text indicates prompts focused on\n",
      "perception, while blue text highlights prompts centered on action and planning. (Huang & Chang, 2023) and introduce five prompt instruc-\n",
      "tions, comprising two general-purpose methods and three\n",
      "tailored to inductive, deductive, and abductive reasoning\n",
      "settings (Appendix A). These prompts ask the agent to ver-\n",
      "balize its confidence levels and systematically refine its\n",
      "uncertainty. Table 1 provides an overview of elicitation\n",
      "policy types with corresponding examples. ⋄ Vanilla. Leveraging the inherent capability of language\n",
      "models (Brown et al., 2020; Wei et al., 2022a), the Vanilla\n",
      "method directly queries the agent’s confidence without addi-\n",
      "tional structure or intervention. Vanilla serves as a baseline\n",
      "for comparison, relying solely on the agent’s built-in capac-\n",
      "ity for confidence elicitation and self-assessment. ⋄ Self-Intervention.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 3}\n",
      "Humans naturally benefit from revisit-\n",
      "ing their decisions with a fresh perspective, often uncovering\n",
      "insights or errors they initially overlooked. Inspired by this,\n",
      "the self-intervention method separates answer generation\n",
      "from evaluation. In one session, the model generates an an-\n",
      "swer; in another, it revisits the question and its response to\n",
      "assess its accuracy. This independent second pass mitigates\n",
      "confirmation bias and overconfidence, encouraging critical\n",
      "self-reflection and producing more reliable evaluations. ⋄ Chain-of-Thought (CoT). To address uncertainty in in-\n",
      "ductive reasoning settings, where the agent must identify pat-\n",
      "terns and infer relationships from observations, we employ\n",
      "zero-shot Chain-of-Thought (CoT) reasoning (Wei et al.,\n",
      "2022b). By decomposing tasks into incremental steps, CoT\n",
      "enhances both interpretability and confidence calibration,\n",
      "allowing agents to reassess uncertainty at each step.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 3}\n",
      "⋄ Plan & Solve (P&S). Despite the success of CoT, it of-\n",
      "ten suffers from semantic misunderstandings and missing\n",
      "step errors, particularly when applying general principles\n",
      "to specific cases. These failures stem from uncertainty in\n",
      "deductive reasoning, where the agent is unsure about the\n",
      "correct instantiation of abstract rules or whether a logical\n",
      "step is valid in a given context. P&S (Wang et al., 2023b)\n",
      "mitigates this by explicitly separating planning from execu-\n",
      "tion, prompting the agent to construct a structured reasoning\n",
      "blueprint before solving the problem step by step. ⋄ Top-K. To address uncertainty in abductive reasoning,\n",
      "where multiple plausible explanations may fit the observed\n",
      "data, the Top-K method prompts the agent to generate its top\n",
      "K answers, each with an associated confidence level. This\n",
      "encourages the agent to consider and distribute its attention\n",
      "across several possible outcomes. By ranking responses\n",
      "rather than a single definitive answer, Top-K provides a\n",
      "balanced and comprehensive representation of abductive\n",
      "uncertainty across multiple plausible interpretations. 3.3. Execution Policies\n",
      "In embodied contexts, planning is a key factor in task suc-\n",
      "cess, requiring the agent to assess its confidence in execut-\n",
      "ing action sequences effectively. Dynamic environments\n",
      "introduce unpredictable factors in action outcomes, which\n",
      "makes it important for the agent to not only consider its\n",
      "primary course of action but also to evaluate and commu-\n",
      "nicate its confidence in alternative actions. By analyzing\n",
      "variance across potential actions rollouts, the agent can bet-\n",
      "4\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 4}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ter quantify uncertainty and anticipate divergent outcomes. To address this, we introduce a set of policies that gener-\n",
      "ate additional observations and diverse action trajectories,\n",
      "promoting robust confidence assessment:\n",
      "⟳ Action Sampling: The agent can generate multiple pos-\n",
      "sible actions by sampling from a learned policy distribution\n",
      "over the action space, conditioned on the current state and\n",
      "task objectives. By doing so, the agent can explore multiple\n",
      "actions, evaluate different outcomes, and assess which is\n",
      "most likely to succeed based on its perception. ⟳ Scenario Reinterpretation: The agent can be prompted\n",
      "to reinterpret the same scenario from different perspec-\n",
      "tives. For example, it could focus on a particular object,\n",
      "re-evaluate environmental obstacles, or re-assess the prox-\n",
      "imity of targets. This enables the agent to propose different\n",
      "courses of action by gathering and redirecting its attention\n",
      "to relevant environmental information. ⟳ Hypothetical Reasoning: The agent can be prompted\n",
      "with hypothetical or counterfactual scenarios (e.g., “What if\n",
      "the object in front were not an obstacle?”). By simulating\n",
      "these hypotheticals, the agent can explore how its actions\n",
      "would change and assess confidence in its original plan. This\n",
      "helps to gauge how flexible the agent’s decision-making\n",
      "process is when confronted with uncertainty or alternative\n",
      "interpretations of the environment. Figure 2 provides an overview and examples of Elicitation\n",
      "and Execution Policies. During task-solving, agents rely\n",
      "on these execution policies to gather additional informa-\n",
      "tion about the environment and potential action trajectories,\n",
      "which they incorporate into further confidence elicitation. 4.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 4}\n",
      "Experiment Setup\n",
      "Environment & Task Setting. Minecraft has emerged as\n",
      "a popular benchmark for embodied AI research due to its\n",
      "open-ended environment, with diverse terrains, resources,\n",
      "and open-ended goals, making it an ideal testbed for embod-\n",
      "ied agents that perform hierarchical reasoning and long-term\n",
      "planning (Johnson et al., 2016; Guss et al., 2019; Hafner\n",
      "et al., 2023; Nottingham et al., 2023; Lin et al., 2023; Qin\n",
      "et al., 2024). Building on this foundation, we define 30\n",
      "tasks evenly distributed across three difficulty levels: easy,\n",
      "medium, and hard, based on the complexity of reasoning\n",
      "steps and the amount of contextual information required. Detailed task descriptions can be found in Appendix B. Easy tasks typically involve basic interactions with a single\n",
      "environmental element (e.g., locating a pig or observing the\n",
      "weather). Medium tasks require combining perception and\n",
      "reasoning over multiple elements, while hard tasks increase\n",
      "dependency on sequential reasoning and include complex\n",
      "challenges like the Diamond Challenge , which requires\n",
      "long-term planning and multi-step execution. Following\n",
      "prior work (Guss et al., 2019), the maximum episode length\n",
      "is set to 6000 steps. Privileged observation is used as the\n",
      "ground truth for perception, while overall task success rate\n",
      "serves as the ground truth for planning and reasoning. Evaluation Metrics. To assess the reliability of confidence\n",
      "estimates, we evaluate two key aspects: calibration and fail-\n",
      "ure prediction (Naeini et al., 2015; Yuan et al., 2021). Cali-\n",
      "bration measures how well an agent’s expressed confidence\n",
      "reflects its actual performance, e.g., an 80% confidence\n",
      "should ideally correspond to 80% accuracy. This calibration\n",
      "is crucial for applications requiring robust risk assessment\n",
      "and trustworthiness. On the other hand, failure prediction\n",
      "focuses on the agent’s ability to distinguish between correct\n",
      "and incorrect predictions by assigning higher confidence to\n",
      "correct outcomes. We use the Expected Calibration Error\n",
      "(ECE) to quantify calibration quality and the Area Under\n",
      "the Receiver Operating Characteristic Curve (AUROC) to\n",
      "evaluate failure prediction. To address imbalances stem-\n",
      "ming from varying accuracy levels across tasks, we also\n",
      "include AUPRC-Positive (PR-P) and AUPRC-Negative (PR-\n",
      "N), which separately measure the agent’s effectiveness in\n",
      "identifying correct and incorrect predictions. Minecraft Agents. In this work, we focus on embod-\n",
      "ied agents powered by advanced Large Language Models\n",
      "(LLMs) and Vision-Language Models (VLMs) that enable\n",
      "multimodal reasoning and understanding in complex embod-\n",
      "ied environments. We employ three models as the agent’s\n",
      "backbone: (1) GPT-4V, chosen for its strong performance\n",
      "in multimodal reasoning and proven effectiveness in com-\n",
      "plex environments like Minecraft (Wang et al., 2023a; Qin\n",
      "et al., 2024; Li et al., 2025) for planning and perception\n",
      "tasks. (2) MineLLM (Qin et al., 2024), a model specifically\n",
      "designed for Minecraft tasks, that leverages MineCLIP’s vi-\n",
      "sual encoder and Vicuna-13B (Chiang et al., 2023) to deliver\n",
      "robust multimodal understanding. and (3) STEVE, built on\n",
      "the versatile LLaMA framework, STEVE models excel in\n",
      "contextual understanding and decision-making (Zhao et al.,\n",
      "2025). Fine-tuned for Minecraft, STEVE enhances plan-\n",
      "ning, communication, and interaction capabilities. Detailed\n",
      "model descriptions are provided in Appendix C.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 4}\n",
      "5. Experimental Results\n",
      "Table 2 presents the performance of benchmarked agents\n",
      "across all Elicitation Policies. In this experiment, evaluation\n",
      "is conducted without Execution Policies. The final confi-\n",
      "dence scores are computed as the average of individual step\n",
      "confidence scores across five independent task episodes. All Elicitation Policies Facilitate Better Calibration and\n",
      "Failure Prediction. Across all models, Elicitation Policies\n",
      "consistently improve calibration (lower ECE) and failure\n",
      "5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 5}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Metric Model Vanilla Self-Intervention CoT (Inductive) P&S (Deductive) Top-K (Abductive)\n",
      "ECE ↓\n",
      "GPT-4V 0.27 0.21 0.16 0.15 0.17\n",
      "MineLLM 0.49 0.41 0.34 0.39 0.43\n",
      "STEVE 0.43 0.32 0.26 0.26 0.35\n",
      "AUROC ↑\n",
      "GPT-4V 0.69 0.76 0.83 0.82 0.73\n",
      "MineLLM 0.53 0.59 0.64 0.61 0.58\n",
      "STEVE 0.58 0.69 0.72 0.67 0.68\n",
      "PR-P ↑\n",
      "GPT-4V 0.66 0.76 0.81 0.79 0.70\n",
      "MineLLM 0.51 0.59 0.63 0.60 0.57\n",
      "STEVE 0.56 0.67 0.69 0.66 0.64\n",
      "PR-N ↑\n",
      "GPT-4V 0.52 0.53 0.58 0.55 0.53\n",
      "MineLLM 0.39 0.42 0.42 0.43 0.40\n",
      "STEVE 0.41 0.46 0.46 0.43 0.42\n",
      "Table 2.Confidence Metrics across Elicitation Policies with three models (GPT-4V , MineLLM, and LLaMA-based STEVE) using\n",
      "different elicitation strategies: Vanilla (basic task understanding), Self-Intervention (reflection on own actions), Chain-of-Thought\n",
      "(step-by-step reasoning), Plan & Solve (explicit planning before execution), and Top-K (confidence distribution across multiple outputs)\n",
      "with No Execution Policies applied. The best performance across each model is in bold.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 5}\n",
      "prediction (higher AUROC, PR-P, PR-N) compared to the\n",
      "Vanilla baseline. For instance, in GPT-4V , every Elicitation\n",
      "Policy results in a lower ECE and higher AUROC rela-\n",
      "tive to Vanilla, demonstrating their effectiveness in improv-\n",
      "ing the robustness of uncertainty quantification. Likewise,\n",
      "MineLLM and STEVE exhibit noticeable gains in ECE and\n",
      "AUROC when incorporating elicitation mechanisms, con-\n",
      "firming that Elicitation Policies help agents better assess\n",
      "uncertainty and predict incorrect responses. Structured Elicitation (CoT and P&S) Improves Cali-\n",
      "bration and Failure Prediction the Most. Among the four\n",
      "Elicitation Policies, structured reasoning approaches—CoT\n",
      "(Inductive) and P&S (Deductive)—consistently yield the\n",
      "best calibration and failure detection performance. For ex-\n",
      "ample, in GPT-4V , P&S achieves the lowest ECE (0.15)\n",
      "and one of the highest AUROC scores (0.82), while CoT\n",
      "further improves AUROC up to 0.83. Similar trends hold for\n",
      "MineLLM and STEVE, where CoT and P&S outperform\n",
      "Self-Intervention and Top-K across nearly all metrics. These\n",
      "improvements suggest that breaking down reasoning into\n",
      "explicit steps helps the models maintain logical consistency,\n",
      "facilitating better overall calibration. Abductive Reasoning Poses Greater Challenges than\n",
      "Inductive and Deductive. While Top-K (Abductive) im-\n",
      "proves over the Vanilla policy, it exhibits weaker calibration\n",
      "and failure prediction, suggesting that generating multiple\n",
      "plausible interpretations increases uncertainty misalignment,\n",
      "and therefore making it harder for the model to distinguish\n",
      "between correct and incorrect predictions. Additionally, the\n",
      "lower PR-P and PR-N scores indicate that confidence esti-\n",
      "mation for abductive reasoning is more difficult to calibrate\n",
      "compared to inductive and deductive settings. Confidence Calibration Remains Inconsistent Across\n",
      "Models. While GPT-4V consistently benefits from different\n",
      "Elicitation Policies, the improvements are less stable in\n",
      "fine-tuned models like MineLLM and STEVE. For instance,\n",
      "CoT boosts AUROC to 0.83 in GPT-4V but only reaches\n",
      "0.64 in MineLLM and 0.72 in STEVE, indicating that fine-\n",
      "tuned models struggle to generalize confidence estimation\n",
      "effectively. One likely reason for this inconsistency is that\n",
      "MineLLM and STEVE, being fine-tuned models, exhibit\n",
      "degenerated language capabilities, limiting their ability to\n",
      "verbalize uncertainty reliably. Execution Policies Amplify Reliable Embodied Confi-\n",
      "dence Across Elicitation Policies.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 5}\n",
      "Figure 3 illustrates how\n",
      "Execution Policies interact with Elicitation Policies. Overall,\n",
      "Execution Policies are capable of further improving cali-\n",
      "bration and failure prediction performance. For example,\n",
      "GPT-4V achieves better ECE results when pairing any Exe-\n",
      "cution Policy with all Elicitation Policies. More specifically,\n",
      "structured reasoning approaches such as CoT (Inductive)\n",
      "and P&S (Deductive), when paired with Action Sampling,\n",
      "tend to yield improved confidence calibration. For instance,\n",
      "MineLLM’s ECE achieves 0.32 and 0.30 paired with CoT\n",
      "and P&S respectively, outperforming other combinations. Hypothetical Reasoning sometimes degrades performance. For instance, STEVE’s ECE worsens when pairing Hypo-\n",
      "thetical Reasoning with all Elicitation Policies, suggesting\n",
      "that while this execution strategy allows models to reason\n",
      "over multiple possible outcomes, it may introduce uncer-\n",
      "tainty, leading to less calibrated confidence judgments. So, How Effectively Can Embodied Agents Express Con-\n",
      "fidence in Dynamic Embodied Tasks? While embodied\n",
      "agents can convey confidence to some extent, their effec-\n",
      "tiveness depends on how well they integrate reasoning, un-\n",
      "certainty assessment, and environmental interactions. The\n",
      "findings reveal that embodied confidence elicitation remains\n",
      "a challenging problem, requiring a careful balance between\n",
      "general-purpose reasoning and task-specific specialization. However, our proposed Elicitation Policies improve both\n",
      "confidence calibration and failure prediction, while our Ex-\n",
      "ecution Policies further augment these performance gains\n",
      "by refining uncertainty through iterative interactions with\n",
      "the environment. These results highlight the importance of\n",
      "6\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 6}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Vanilla Self-Intervention CoT P&S Top-K\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.24\n",
      "0.22\n",
      "0.14\n",
      "0.10\n",
      "0.12\n",
      "0.11\n",
      "0.11\n",
      "0.12\n",
      "0.11\n",
      "0.11\n",
      "0.13\n",
      "0.18\n",
      "0.12\n",
      "0.14\n",
      "0.15\n",
      "ECE ↓\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.50\n",
      "0.53\n",
      "0.52\n",
      "0.35\n",
      "0.42\n",
      "0.50\n",
      "0.32\n",
      "0.44\n",
      "0.33\n",
      "0.30\n",
      "0.45\n",
      "0.38\n",
      "0.42\n",
      "0.47\n",
      "0.43\n",
      "ECE ↓\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.40\n",
      "0.42\n",
      "0.41\n",
      "0.28\n",
      "0.27\n",
      "0.39\n",
      "0.24\n",
      "0.24\n",
      "0.33\n",
      "0.27\n",
      "0.28\n",
      "0.35\n",
      "0.30\n",
      "0.31\n",
      "0.34\n",
      "ECE ↓\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.76\n",
      "0.75\n",
      "0.78\n",
      "0.80\n",
      "0.79\n",
      "0.81\n",
      "0.84\n",
      "0.82\n",
      "0.84\n",
      "0.88\n",
      "0.79\n",
      "0.85\n",
      "0.78\n",
      "0.77\n",
      "0.81\n",
      "AUROC ↑\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.55\n",
      "0.64\n",
      "0.51\n",
      "0.64\n",
      "0.68\n",
      "0.68\n",
      "0.69\n",
      "0.74\n",
      "0.71\n",
      "0.67\n",
      "0.71\n",
      "0.65\n",
      "0.63\n",
      "0.66\n",
      "0.65\n",
      "AUROC ↑\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.62\n",
      "0.66\n",
      "0.57\n",
      "0.74\n",
      "0.74\n",
      "0.65\n",
      "0.72\n",
      "0.70\n",
      "0.65\n",
      "0.72\n",
      "0.72\n",
      "0.64\n",
      "0.70\n",
      "0.68\n",
      "0.64\n",
      "AUROC ↑\n",
      "GPT-4V MineLLM STEVE\n",
      "Figure 3.ECE and AUROC across Models and Execution Policies. Bars present ECE (top, lower is better) and AUROC (bottom,\n",
      "higher is better) under different elicitation strategies. Red dashed lines are metrics for Vanilla elicitation with no execution policy applied. accounting for the unique challenges faced by embodied\n",
      "agents in confidence estimation, emphasizing the need for\n",
      "execution-aware strategies that enhance both calibration and\n",
      "failure prediction in complex environments.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 6}\n",
      "6. Ablation Studies\n",
      "Impact of Execution Policies. We analyze the performance\n",
      "of Execution Policy combinations, incorporating Action\n",
      "Sampling (AS), Scenario Reinterpretation (SR), and Hypo-\n",
      "thetical Reasoning (HR) both incrementally and collectively. Results in Table 3 show clear trends in how Execution Poli-\n",
      "cies influence performance. Without any Execution Policies,\n",
      "Vanilla Elicitation exhibits the worst calibration, with ECE\n",
      "as high as 0.27, while also struggling with failure predic-\n",
      "tion. When Execution Policies are introduced, performance\n",
      "improves, though trade-offs emerge between failure predic-\n",
      "tion accuracy (AUROC) and confidence calibration (ECE). Among two-policy combinations, the combination of Action\n",
      "Sampling with Scenario Reinterpretation (AS + SR) deliv-\n",
      "ers the most balanced improvement, significantly increas-\n",
      "ing AUROC (up to 0.83 for GPT-4V and 0.69 for STEVE)\n",
      "while maintaining the lowest ECE (0.17 for GPT-4V , 0.32\n",
      "for MineLLM). This suggests that jointly exploring multi-\n",
      "ple action paths and reinterpreting environmental cues helps\n",
      "refine confidence estimation without sacrificing calibration. In addition, strategies incorporating Action Sampling (AS)\n",
      "consistently outperform those without it, resulting in better\n",
      "uncertainty estimation and more reliable confidence scores. By generating multiple action plans, AS enhances confi-\n",
      "dence calibration, underscoring the importance of address-\n",
      "ing action planning uncertainty in embodied agents. Com-\n",
      "bining all Execution Policies yields the strongest overall\n",
      "performance across models, achieving the highest AUROC\n",
      "across all three models while maintaining competitive cali-\n",
      "bration, with the lowest ECE for GPT-4V (0.17) and strong\n",
      "values for MineLLM (0.32) and STEVE (0.38). This sug-\n",
      "gests that integrating Action Sampling, Scenario Reinterpre-\n",
      "tation, and Hypothetical Reasoning provides a complemen-\n",
      "tary effect, improving both failure prediction accuracy and\n",
      "confidence estimation. Perception v.s.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 6}\n",
      "Cognition. Embodied agents, when tasked\n",
      "with high-level objectives ( e.g., “find a pig”), often rely\n",
      "on language models to decompose the task into smaller,\n",
      "granular actions (e.g., “step forward 2 steps”). During task\n",
      "execution, the agent generates confidence scores for each\n",
      "granular action. Typically, these scores are aggregated tem-\n",
      "porally to produce a single overall confidence score for the\n",
      "entire task. While this method provides a holistic measure\n",
      "of confidence, it does not differentiate between the confi-\n",
      "dence associated with perception (e.g., recognizing a pig)\n",
      "and cognition (e.g., reasoning about the sequence of steps). To better understand how different sources of uncertainty\n",
      "contribute to overall confidence, we separately analyze per-\n",
      "ception and reasoning confidence. Perception Confidence\n",
      "aggregates scores related to the agent’s ability to interpret its\n",
      "sensory inputs (e.g., detecting objects or understanding en-\n",
      "vironmental cues), while Reasoning Confidence aggregates\n",
      "scores associated with reasoning and decision-making pro-\n",
      "cesses during task execution. Figure 4 reveals that temporal\n",
      "aggregation achieves the lowest ECE (0.18) and a balanced\n",
      "AUROC (0.76). Temporal aggregation smooths over indi-\n",
      "vidual uncertainties, providing robust overall calibration and\n",
      "reliable failure prediction. Perception-based confidence, when aggregated separately,\n",
      "offers a distinct advantage in predictive reliability. With an\n",
      "AUROC of 0.79, the highest among the methods, and strong\n",
      "PR-P (0.85) and PR-N (0.81) scores, perception confidence\n",
      "consistently outperforms reasoning. This highlights the\n",
      "7\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 7}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Execution Strategies GPT-4V MineLLM STEVE\n",
      "ECE ↓ AUROC ↑ ECE ↓ AUROC ↑ ECE ↓ AUROC ↑\n",
      "No Execution Strategy 0.27 0.69 0.49 0.53 0.43 0.58\n",
      "AS + SR 0.18 0.82 0.32 0.59 0.39 0.69\n",
      "AS + HR 0.20 0.79 0.34 0.57 0.37 0.66\n",
      "SR + HR 0.22 0.80 0.37 0.54 0.44 0.58\n",
      "AS + SR + HR 0.17 0.83 0.32 0.62 0.38 0.69\n",
      "Table 3.Performance of Vanilla Elicitation with Combined Execution Strategies. AS = Action Sampling, SR = Scenario Reinterpreta-\n",
      "tion, HR = Hypothetical Reasoning.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 7}\n",
      "ECE and AUROC for each model, GPT-4V , MineLLM, and STEVE.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 7}\n",
      "Best values highlighted inbold. ECE AUROC PR-P PR-N\n",
      "Temporal\n",
      "Aggregation\n",
      "Reasoning\n",
      "Confidence\n",
      "Perception\n",
      "Confidence\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.18\n",
      "0.26\n",
      "0.22\n",
      "0.76\n",
      "0.71\n",
      "0.79\n",
      "0.82\n",
      "0.78\n",
      "0.85\n",
      "0.80\n",
      "0.72\n",
      "0.81\n",
      "Confidence Scores\n",
      "Figure 4.Comparison of Aggregation Methods for Vanilla Elic-\n",
      "itation without Execution Policies. Temporal aggregation pro-\n",
      "vides a holistic score, while separate aggregation evaluates confi-\n",
      "dence in reasoning and perception separately respectively. inherent stability of sensory tasks, where clear input-output\n",
      "mappings and deterministic operations reduce uncertainty. Additionally, perception confidence maintains a competitive\n",
      "ECE (0.22), indicating that it remains well-calibrated. In contrast, reasoning confidence introduces more uncer-\n",
      "tainty, resulting in a higher ECE (0.26) and a lower AU-\n",
      "ROC (0.71). These results reflect the challenges of reason-\n",
      "ing tasks, which often involve multi-step decision-making\n",
      "and are susceptible to cascading errors. The lower PR-P\n",
      "(0.78) and PR-N (0.72) scores suggest reasoning confidence\n",
      "struggles to accurately distinguish correct from incorrect\n",
      "outcomes. In essence, results affirm that reasoning tasks\n",
      "inherently present greater uncertainty, requiring more so-\n",
      "phisticated calibration methods to maintain reliability. Interestingly, the performance gap between perception and\n",
      "reasoning confidence underscores their complementary na-\n",
      "ture. While perception excels in calibration and failure\n",
      "prediction, reasoning provides critical insights into decision-\n",
      "making under uncertainty. Temporal aggregation balances\n",
      "these components effectively for an overall confidence score\n",
      "but sacrifices the interpretability offered by separate aggre-\n",
      "gation. This comparison emphasizes the need to align ag-\n",
      "gregation methods with task complexity and performance\n",
      "priorities, whether for holistic confidence measures or de-\n",
      "tailed insights into perception and cognition. Impact of Execution Iterations. We investigate the impact\n",
      "of repeatedly applying execution policies on calibration and\n",
      "failure prediction accuracy. Iterations range from 0 (i.e., no\n",
      "execution policies employed) to 15, allowing for an analysis\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0 5 10 150.1\n",
      "0.15\n",
      "0.2\n",
      "0.25\n",
      "0.3\n",
      "# Iterations\n",
      "ECE\n",
      "0 5 10 15\n",
      "0.76\n",
      "0.78\n",
      "0.8\n",
      "0.82\n",
      "0.84\n",
      "# Iterations\n",
      "AUROC\n",
      "Figure 5.ECE and AUROC across Execution Policy Iterations. of both the initial benefits and potential diminishing returns\n",
      "of repeated applications. As shown in Figure 5, repeated\n",
      "applications initially improve ECE across all policies but\n",
      "eventually plateau. For instance, Action Sampling reduces\n",
      "ECE from 0.18 (at 0 iterations) to 0.14 (at 15 iterations),\n",
      "with most of the improvement occurring within the first 10\n",
      "iterations. A similar trend is observed for Scenario Rein-\n",
      "terpretation and Hypothetical Reasoning, where ECE drops\n",
      "from 0.25 to 0.18 and from 0.23 to 0.17, respectively. The\n",
      "plateau effect is less pronounced in AUROC, which consis-\n",
      "tently improves across iterations. Action Sampling increases\n",
      "AUROC from 0.77 to 0.83, while Scenario Reinterpretation\n",
      "and Hypothetical Reasoning improve from 0.79 to 0.84 and\n",
      "from 0.78 to 0.84, respectively. Most AUROC gains occur\n",
      "between 0 and 10 iterations, with diminishing returns after\n",
      "15 iterations. Overall, early iterations improve calibration\n",
      "and failure prediction, but excessive repetition yields di-\n",
      "minishing returns. This underscores the need to balance\n",
      "execution policy applications for optimal effectiveness. 7. Conclusion\n",
      "This work presents the first systematic exploration of em-\n",
      "bodied confidence elicitation, introducing elicitation and\n",
      "execution policies that enhance calibration and failure pre-\n",
      "diction in open-ended multimodal embodied tasks. Our\n",
      "findings highlight improvements in confidence estimation\n",
      "using our proposed methods, providing more accurate un-\n",
      "certainty quantification. Future research could improve\n",
      "confidence elicitation in embodied environments by scaling\n",
      "to more diverse and complex environments and exploring\n",
      "their integration with various embodied agent architectures. 8\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "8. Impact Statement\n",
      "This work advances Embodied AI by introducing confidence\n",
      "elicitation and execution policies tailored to multimodal and\n",
      "dynamic environments. By enabling embodied agents to\n",
      "express uncertainty, our approach enhances their calibra-\n",
      "tion, adaptability, and reliability in complex tasks. This\n",
      "contribution supports safer AI deployment in real-world do-\n",
      "mains like robotics, education, and collaborative systems,\n",
      "where accurate self-assessment is critical. However, the\n",
      "reliance on large pre-trained models raises concerns about\n",
      "energy efficiency and ethical considerations in high-stakes\n",
      "applications, which warrant further exploration. References\n",
      "Abdar, M., Pourpanah, F., Hussain, S., Rezazadegan, D.,\n",
      "Liu, L., Ghavamzadeh, M., Fieguth, P., Cao, X., Khos-\n",
      "ravi, A., Acharya, U. R., et al. A review of uncertainty\n",
      "quantification in deep learning: Techniques, applications\n",
      "and challenges. Information Fusion, 2021. Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I.,\n",
      "Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S.,\n",
      "Anadkat, S., et al. Gpt-4 technical report. arXiv preprint\n",
      "arXiv:2303.08774, 2023. Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D.,\n",
      "Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G.,\n",
      "Askell, A., et al. Language models are few-shot learners. In Advances in Neural Information Processing Systems,\n",
      "2020. Chen, B., Shu, C., Shareghi, E., Collier, N., Narasimhan, K.,\n",
      "and Yao, S. Fireact: Toward language agent fine-tuning. arXiv preprint arXiv:2310.05915, 2023. Chen, C., Liu, K., Chen, Z., Gu, Y ., Wu, Y ., Tao, M., Fu, Z.,\n",
      "and Ye, J. INSIDE: LLMs’ internal states retain the power\n",
      "of hallucination detection. In International Conference\n",
      "on Learning Representations, 2024a. Chen, J. and Mueller, J. Quantifying uncertainty in answers\n",
      "from any language model and enhancing their trustwor-\n",
      "thiness. In Association for Computational Linguistics ,\n",
      "2024. Chen, J., Park, S., and Simeone, O. Knowing when to stop:\n",
      "Delay-adaptive spiking neural network classifiers with\n",
      "reliability guarantees. IEEE Journal of Selected Topics in\n",
      "Signal Processing, 2024b. Cheng, K., Yang, J., Jiang, H., Wang, Z., Huang, B., Li,\n",
      "R., Li, S., Li, Z., Gao, Y ., Li, X., et al. Inductive or\n",
      "deductive? rethinking the fundamental reasoning abilities\n",
      "of llms. arXiv preprint arXiv:2408.00114, 2024. Chiang, W.-L., Li, Z., Lin, Z., Sheng, Y ., Wu, Z., Zhang,\n",
      "H., Zheng, L., Zhuang, S., Zhuang, Y ., Gonzalez, J. E.,\n",
      "Stoica, I., and Xing, E.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "P. Vicuna: An open-source chat-\n",
      "bot impressing gpt-4 with 90%* chatgpt quality. See\n",
      "https://lmsys.org/blog/2023-03-30-vicuna/, 2023. Christianos, F., Papoudakis, G., Zimmer, M., Coste, T., Wu,\n",
      "Z., Chen, J., Khandelwal, K., Doran, J., Feng, X., Liu,\n",
      "J., Xiong, Z., Luo, Y ., Hao, J., Shao, K., Bou-Ammar,\n",
      "H., and Wang, J. Pangu-agent: A fine-tunable gener-\n",
      "alist agent with structured reasoning. arXiv preprint\n",
      "arXiv:2312.14878, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "Clark, A. Surfing Uncertainty: Prediction, Action, and the\n",
      "Embodied Mind. Oxford University Press, 2015. Dey, N., Ding, J., Ferrell, J., Kapper, C., Lovig, M., Plan-\n",
      "chon, E., and Williams, J. P. Conformal prediction for text\n",
      "infilling and part-of-speech prediction. The New England\n",
      "Journal of Statistics in Data Science, 2022. Driess, D., Xia, F., Sajjadi, M. S. M., Lynch, C., Chowdhery,\n",
      "A., Ichter, B., Wahid, A., Tompson, J., Vuong, Q., Yu,\n",
      "T., Huang, W., Chebotar, Y ., Sermanet, P., Duckworth,\n",
      "D., Levine, S., Vanhoucke, V ., Hausman, K., Toussaint,\n",
      "M., Greff, K., Zeng, A., Mordatch, I., and Florence, P. Palm-e: An embodied multimodal language model. In\n",
      "International Conference on Machine Learning, 2023. Fan, L., Wang, G., Jiang, Y ., Mandlekar, A., Yang, Y ., Zhu,\n",
      "H., Tang, A., Huang, D.-A., Zhu, Y ., and Anandkumar,\n",
      "A. Minedojo: Building open-ended embodied agents\n",
      "with internet-scale knowledge. In Advances in Neural\n",
      "Information Processing Systems, 2022. Farquhar, S., Kossen, J., Kuhn, L., and Gal, Y . Detecting\n",
      "hallucinations in large language models using semantic\n",
      "entropy. Nature, 2024. Fisch, A., Schuster, T., Jaakkola, T., and Barzilay, R. Effi-\n",
      "cient conformal prediction via cascaded inference with\n",
      "expanded admission. In International Conference on\n",
      "Learning Representations, 2021. Gawlikowski, J., Tassi, C. R. N., Ali, M., Lee, J., Humt, M.,\n",
      "Feng, J., Kruspe, A., Triebel, R., Jung, P., Roscher, R.,\n",
      "et al. A survey of uncertainty in deep neural networks. Artificial Intelligence Review, 2023. Ghasemipour, K., Gu, S.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "S., and Nachum, O. Why so pes-\n",
      "simistic? estimating uncertainties for offline rl through\n",
      "ensembles, and why their independence matters. In Ad-\n",
      "vances in Neural Information Processing Systems, 2022. Giovannotti, P.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 8}\n",
      "and Gammerman, A. Transformer-based\n",
      "conformal predictors for paraphrase detection. In Con-\n",
      "formal and Probabilistic Prediction and Applications ,\n",
      "2021. 9\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Goel, V . Anatomy of deductive reasoning.Trends in cogni-\n",
      "tive sciences, 2007. Groot, T. and Valdenegro Toro, M. Overconfidence is key:\n",
      "Verbalized uncertainty evaluation in large language and\n",
      "vision-language models. In Trustworthy Natural Lan-\n",
      "guage Processing, 2024. Guo, X., Huang, K., Liu, J., Fan, W., V ´elez, N., Wu, Q.,\n",
      "Wang, H., Griffiths, T. L., and Wang, M. Embodied\n",
      "LLM agents learn to cooperate in organized teams. In\n",
      "Language Gamification - NeurIPS 2024 Workshop, 2024. Guss, W. H., Houghton, B., Topin, N., Wang, P., Codel,\n",
      "C. R., Veloso, M.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "M., and Salakhutdinov, R. Minerl:\n",
      "A large-scale dataset of minecraft demonstrations. In\n",
      "International Joint Conference on Artificial Intelligence,\n",
      "2019. Hafner, D., Pasukonis, J., Ba, J., and Lillicrap, T. Mastering\n",
      "diverse domains through world models. arXiv preprint\n",
      "arXiv:2301.04104, 2023. He, S., Han, S., Su, S., Han, S., Zou, S., and Miao, F. Robust\n",
      "multi-agent reinforcement learning with state uncertainty. Transactions on Machine Learning Research, 2023. Huang, J.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "and Chang, K. C.-C. Towards reasoning in large\n",
      "language models: A survey. In Association for Computa-\n",
      "tional Linguistics, 2023. Huang, W., Zhang, J., and Huang, K. Bootstrap estimated\n",
      "uncertainty of the environment model for model-based\n",
      "reinforcement learning. In AAAI Conference on Artificial\n",
      "Intelligence, 2019. Huang, W., Xia, F., Xiao, T., Chan, H., Liang, J., Florence,\n",
      "P., Zeng, A., Tompson, J., Mordatch, I., Chebotar, Y .,\n",
      "et al. Inner monologue: Embodied reasoning through\n",
      "planning with language models. In Conference on Robot\n",
      "Learning, 2023. Jin, L., Chen, X., R ¨uckin, J., and Popovi ´c, M. Neu-nbv:\n",
      "Next best view planning using uncertainty estimation in\n",
      "image-based neural rendering. In International Confer-\n",
      "ence on Intelligent Robots and Systems. IEEE, 2023. Johnson, M., Hofmann, K., Hutton, T., and Bignell, D. The malmo platform for artificial intelligence experimen-\n",
      "tation. In International Joint Conference on Artificial\n",
      "Intelligence, 2016. Johnson-Laird, P. N. Deductive reasoning. Annual review\n",
      "of psychology, 1999. Josephson, J. R. and Josephson, S.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "G. Abductive inference:\n",
      "Computation, philosophy, technology. Cambridge Uni-\n",
      "versity Press, 1996. Kadavath, S., Conerly, T., Askell, A., Henighan, T., Drain,\n",
      "D., Perez, E., Schiefer, N., Hatfield-Dodds, Z., DasSarma,\n",
      "N., Tran-Johnson, E., Johnston, S., El-Showk, S., Jones,\n",
      "A., Elhage, N., Hume, T., Chen, A., Bai, Y ., Bowman,\n",
      "S., Fort, S., Ganguli, D., Hernandez, D., Jacobson, J.,\n",
      "Kernion, J., Kravec, S., Lovitt, L., Ndousse, K., Olsson,\n",
      "C., Ringer, S., Amodei, D., Brown, T., Clark, J., Joseph,\n",
      "N., Mann, B., McCandlish, S., Olah, C., and Kaplan, J. Language models (mostly) know what they know. arXiv\n",
      "preprint arXiv:2207.05221, 2022. Kuhn, L., Gal, Y ., and Farquhar, S. Semantic uncertainty:\n",
      "Linguistic invariances for uncertainty estimation in natu-\n",
      "ral language generation. In International Conference on\n",
      "Learning Representations, 2023. Kuleshov, V . and Deshpande, S. Calibrated and sharp un-\n",
      "certainties in deep learning via density estimation. In\n",
      "International Conference on Machine Learning, 2022. Kumar, B., Lu, C., Gupta, G., Palepu, A., Bellamy, D.,\n",
      "Raskar, R., and Beam, A. Conformal prediction with large\n",
      "language models for multi-choice question answering. In\n",
      "ICML Neural Conversational AI TEACH workshop, 2023. Levine, Y ., Wies, N., Jannai, D., Navon, D., Hoshen, Y ., and\n",
      "Shashua, A. The inductive bias of in-context learning:\n",
      "Rethinking pretraining example design. In International\n",
      "Conference on Learning Representations, 2022. Li, M. and Vit´anyi, P. M.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "B. Inductive reasoning. In Lan-\n",
      "guage Computations, 1992. Li, Z., Xie, Y ., Shao, R., Chen, G., Jiang, D., and Nie,\n",
      "L. Optimus-1: Hybrid multimodal memory empowered\n",
      "agents excel in long-horizon tasks. Advances in Neural\n",
      "Information Processing Systems, 2025. Liang, K., Zhang, Z., and Fisac, J. F. Introspective planning:\n",
      "Aligning robots’ uncertainty with inherent task ambiguity. In Advances in Neural Information Processing Systems,\n",
      "2024. Lin, H., Wang, Z., Ma, J., and Liang, Y . Mcu: A task-centric\n",
      "framework for open-ended agent evaluation in minecraft. arXiv preprint arXiv:2310.08367, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 9}\n",
      "Lin, S., Hilton, J., and Evans, O. Teaching models to express\n",
      "their uncertainty in words. Transactions on Machine\n",
      "Learning Research, 2022a. Lin, Z., Liu, J. Z., and Shang, J. Towards collaborative\n",
      "neural-symbolic graph semantic parsing via uncertainty. In Association for Computational Linguistics, 2022b. Liu, E., Neubig, G., and Andreas, J. An incomplete loop: In-\n",
      "struction inference, instruction following, and in-context\n",
      "learning in language models. In Conference on Language\n",
      "Modeling, 2024. 10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Malinin, A. and Gales, M. Uncertainty estimation in autore-\n",
      "gressive structured prediction. In International Confer-\n",
      "ence on Learning Representations, 2021. Mielke, S. J., Szlam, A., Dinan, E., and Boureau, Y .-L. Reducing conversational agents’ overconfidence through\n",
      "linguistic calibration. Transactions of the Association for\n",
      "Computational Linguistics, 2022. Naeini, M.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "P., Cooper, G., and Hauskrecht, M. Obtaining\n",
      "well calibrated probabilities using bayesian binning. In\n",
      "AAAI Conference on Artificial Intelligence, 2015. Nottingham, K., Ammanabrolu, P., Suhr, A., Choi, Y ., Ha-\n",
      "jishirzi, H., Singh, S., and Fox, R. Do embodied agents\n",
      "dream of pixelated sheep: Embodied decision making\n",
      "using language guided world modelling. In International\n",
      "Conference on Machine Learning, 2023. Okoli, C. Inductive, abductive and deductive theorising. International Journal of Management Concepts and Phi-\n",
      "losophy, 2023. Peirce, C.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "S. Collected papers of charles sanders peirce . Harvard University Press, 1934.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Qin, Y ., Zhou, E., Liu, Q., Yin, Z., Sheng, L., Zhang, R.,\n",
      "Qiao, Y ., and Shao, J. Mp5: A multi-modal open-ended\n",
      "embodied system in minecraft via active perception. In\n",
      "Conference on Computer Vision and Pattern Recognition,\n",
      "2024.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Ren, A. Z., Dixit, A., Bodrova, A., Singh, S., Tu, S., Brown,\n",
      "N., Xu, P., Takayama, L. T., Xia, F., Varley, J., et al. Robots that ask for help: Uncertainty alignment for large\n",
      "language model planners. In Conference on Robot Learn-\n",
      "ing, 2023. Ren, A. Z., Clark, J., Dixit, A., Itkina, M., Majumdar, A.,\n",
      "and Sadigh, D. Explore until confident: Efficient explo-\n",
      "ration for embodied question answering. In Robotics:\n",
      "Science and Systems, 2024. Robinson, J. and Wingate, D. Leveraging large language\n",
      "models for multiple choice question answering. In Inter-\n",
      "national Conference on Learning Representations, 2023. Sagar, S., Taparia, A., and Senanayake, R. Failures are fated,\n",
      "but can be faded: Characterizing and mitigating unwanted\n",
      "behaviors in large-scale vision and language models. In\n",
      "International Conference on Machine Learning, 2024. Shen, Y . and Lourentzou, I. Learning by asking for embod-\n",
      "ied visual navigation and task completion. In IEEE/CVF\n",
      "Winter Conference on Applications of Computer Vision,\n",
      "2025. Shinn, N., Cassano, F., Gopinath, A., Narasimhan, K., and\n",
      "Yao, S. Reflexion: Language agents with verbal rein-\n",
      "forcement learning. In Advances in Neural Information\n",
      "Processing Systems, 2024. Su, W., Wang, C., Ai, Q., Hu, Y ., Wu, Z., Zhou, Y ., and\n",
      "Liu, Y . Unsupervised real-time hallucination detection\n",
      "based on the internal states of large language models. In\n",
      "Association for Computational Linguistics, 2024.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 10}\n",
      "Tian, B., Luo, L., Zhao, H., and Zhou, G. Vibus: Data-\n",
      "efficient 3d scene parsing with viewpoint bottleneck and\n",
      "uncertainty-spectrum modeling. ISPRS Journal of Pho-\n",
      "togrammetry and Remote Sensing, 2022. Tian, K., Mitchell, E., Zhou, A., Sharma, A., Rafailov,\n",
      "R., Yao, H., Finn, C., and Manning, C. D. Just ask for\n",
      "calibration: Strategies for eliciting calibrated confidence\n",
      "scores from language models fine-tuned with human feed-\n",
      "back. In Conference on Empirical Methods in Natural\n",
      "Language Processing, 2023. Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,\n",
      "M.-A., Lacroix, T., Rozi`ere, B., Goyal, N., Hambro, E.,\n",
      "Azhar, F., Rodriguez, A., Joulin, A., Grave, E., and Lam-\n",
      "ple, G. Llama: Open and efficient foundation language\n",
      "models. arXiv preprint arXiv:2302.13971, 2023a. Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi,\n",
      "A., Babaei, Y ., Bashlykov, N., Batra, S., Bhargava, P.,\n",
      "Bhosale, S., et al. Llama 2: Open foundation and fine-\n",
      "tuned chat models. arXiv preprint arXiv:2307.09288 ,\n",
      "2023b. Walton, D. Abductive, presumptive and plausible arguments. Informal Logic, 2001. Walton, D. Abductive reasoning. University of Alabama\n",
      "Press, 2014. Wang, G., Xie, Y ., Jiang, Y ., Mandlekar, A., Xiao, C., Zhu,\n",
      "Y ., Fan, L., and Anandkumar, A. V oyager: An open-\n",
      "ended embodied agent with large language models. In\n",
      "NeurIPS Intrinsically-Motivated and Open-Ended Learn-\n",
      "ing Workshop, 2023a. Wang, L., Xu, W., Lan, Y ., Hu, Z., Lan, Y ., Lee, R. K.-W.,\n",
      "and Lim, E.-P. Plan-and-solve prompting: Improving\n",
      "zero-shot chain-of-thought reasoning by large language\n",
      "models. In Association for Computational Linguistics ,\n",
      "2023b. Wang, Y . and Zou, S. Online robust reinforcement learning\n",
      "with model uncertainty. Advances in Neural Information\n",
      "Processing Systems, 2021. Wang, Z., Cai, S., Chen, G., Liu, A., Ma, X., Liang, Y .,\n",
      "and CraftJarvis, T. Describe, explain, plan and select:\n",
      "11\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Interactive planning with large language models enables\n",
      "open-world multi-task agents. In Advances in Neural\n",
      "Information Processing Systems, 2023c. Wei, J., Tay, Y ., Bommasani, R., Raffel, C., Zoph, B.,\n",
      "Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Met-\n",
      "zler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang,\n",
      "P., Dean, J., and Fedus, W. Emergent abilities of large\n",
      "language models. Transactions on Machine Learning\n",
      "Research, 2022a. Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,\n",
      "E., Le, Q. V ., Zhou, D., et al. Chain-of-thought prompting\n",
      "elicits reasoning in large language models. In Advances\n",
      "in Neural Information Processing Systems, 2022b. Xiao, Y . and Wang, W. Y . On hallucination and predic-\n",
      "tive uncertainty in conditional language generation. In\n",
      "European Chapter of the Association for Computational\n",
      "Linguistics, 2021. Xiong, M., Hu, Z., Lu, X., LI, Y ., Fu, J., He, J., and Hooi, B. Can LLMs express their uncertainty? an empirical evalu-\n",
      "ation of confidence elicitation in LLMs. In International\n",
      "Conference on Learning Representations, 2024. Xu, F., Lin, Q., Han, J., Zhao, T., Liu, J., and Cambria,\n",
      "E. Are large language models really good logical rea-\n",
      "soners? a comprehensive evaluation and beyond. IEEE\n",
      "Transactions on Knowledge and Data Engineering, 2025. Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan,\n",
      "K., and Cao, Y . React: Synergizing reasoning and act-\n",
      "ing in language models. In International Conference on\n",
      "Learning Representations, 2023. Ye, F., Yang, M., Pang, J., Wang, L., Wong, D. F., Yilmaz, E.,\n",
      "Shi, S., and Tu, Z. Benchmarking LLMs via uncertainty\n",
      "quantification. In Neural Information Processing Systems\n",
      "Datasets and Benchmarks Track, 2024. Yildirim, M. Y ., Ozer, M., and Davulcu, H. Leveraging\n",
      "uncertainty in deep learning for selective classification. arXiv preprint arXiv:1905.09509, 2019. Yuan, Z., Yan, Y ., Sonka, M., and Yang, T. Large-scale\n",
      "robust deep auc maximization: A new surrogate loss and\n",
      "empirical studies on medical image classification. In\n",
      "International Conference on Computer Vision, 2021. Zhang, J., Lan, T., Murthy, R., Liu, Z., Yao, W., Tan, J.,\n",
      "Hoang, T., Yang, L., Feng, Y ., Liu, Z., Awalgaonkar, T.,\n",
      "Niebles, J. C., Savarese, S., Heinecke, S., Wang, H., and\n",
      "Xiong, C. Agentohana: Design unified data and train-\n",
      "ing pipeline for effective agent learning. arXiv preprint\n",
      "arXiv:2402.15506, 2024a.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "Zhang, R., Zhang, H., and Zheng, Z. Vl-uncertainty: De-\n",
      "tecting hallucination in large vision-language model via\n",
      "uncertainty estimation. arXiv preprint arXiv:2411.11919,\n",
      "2024b.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "Zhao, Z., Chai, W., Wang, X., Li, B., Hao, S., Cao, S., Ye,\n",
      "T., and Wang, G. See and think: Embodied agent in vir-\n",
      "tual environment. In European Conference on Computer\n",
      "Vision, 2025. Zhu, X., Chen, Y ., Tian, H., Tao, C., Su, W., Yang, C.,\n",
      "Huang, G., Li, B., Lu, L., Wang, X., et al. Ghost\n",
      "in the minecraft: Generally capable agents for open-\n",
      "world environments via large language models with\n",
      "text-based knowledge and memory. arXiv preprint\n",
      "arXiv:2305.17144, 2023.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 11}\n",
      "12\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 12}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "A. Definitions of Uncertainty Types\n",
      "The three fundamental forms of logical reasoning, inductive, deductive, and abductive, have long been recognized and\n",
      "studied (Peirce, 1934; Walton, 2014; Wei et al., 2022b; Levine et al., 2022; Okoli, 2023). As language models demonstrated\n",
      "extraordinary abilities, designing better reasoning mechanisms has become a popular research trend (Cheng et al., 2024; Liu\n",
      "et al., 2024). These reasoning paradigms serve as fundamental frameworks for structuring inference and decision-making\n",
      "processes, particularly in settings where uncertainty arises due to partial observations, ambiguous premises, or multiple\n",
      "plausible explanations (Xu et al., 2025). We adapt these reasoning types to the domain of embodied confidence elicitation\n",
      "and formally define and describe each uncertainty type (See Table 4). Reasoning Type Definition Uncertainty Associated Example Elicitation Method\n",
      "Inductive\n",
      "Inductive reasoning de-\n",
      "rives general principles\n",
      "from a body of observa-\n",
      "tions which means mak-\n",
      "ing broad generalizations\n",
      "based on specific obser-\n",
      "vations (Li & Vit ´anyi,\n",
      "1992). Inductive Uncertainty :\n",
      "Arises when an agent\n",
      "generalizes from limited\n",
      "observations, leading to\n",
      "potential overgeneraliza-\n",
      "tion or misclassification. An agent observes that\n",
      "all previously encoun-\n",
      "tered caves contained hos-\n",
      "tile entities and infers that\n",
      "any future cave is also\n",
      "dangerous.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 12}\n",
      "However, this\n",
      "conclusion is uncertain\n",
      "because it is based on a\n",
      "limited number of obser-\n",
      "vations. Chain-of-Thought (CoT):\n",
      "The agent systematically\n",
      "analyzes observed trends,\n",
      "considers possible excep-\n",
      "tions, and evaluates confi-\n",
      "dence in applying general-\n",
      "izations. Deductive\n",
      "Deductive reasoning is\n",
      "the process of drawing\n",
      "deductive inferences\n",
      "that start from the given\n",
      "premises and reason\n",
      "with logical rules or\n",
      "commonsense to obtain\n",
      "certain conclusions\n",
      "(Johnson-Laird, 1999;\n",
      "Goel, 2007). Deductive Uncertainty :\n",
      "Arises when an agent\n",
      "applies logical rules\n",
      "but encounters missing,\n",
      "conflicting, or incomplete\n",
      "premises, making the\n",
      "outcome uncertain. An agent knows the rule:\n",
      "”If wood is available, then\n",
      "a wooden tool can be\n",
      "crafted.” However, if it is\n",
      "uncertain whether wood\n",
      "is available, it cannot con-\n",
      "fidently conclude whether\n",
      "crafting is possible. Plan-and-Solve (P&S) :\n",
      "The agent formulates a\n",
      "set of premises, identifies\n",
      "missing dependencies,\n",
      "and assesses confidence\n",
      "in executing the task. Abductive\n",
      "The process of inferring\n",
      "the most plausible ex-\n",
      "planation for an obser-\n",
      "vation based on incom-\n",
      "plete evidence.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 12}\n",
      "Abduc-\n",
      "tion generates hypotheses\n",
      "rather than definitive con-\n",
      "clusions (Josephson &\n",
      "Josephson, 1996; Walton,\n",
      "2001). Abductive Uncertainty :\n",
      "Arises when multiple\n",
      "explanations could ac-\n",
      "count for an observation,\n",
      "with no definitive way to\n",
      "determine the correct one. An agent searching for a\n",
      "pig near a river hypothe-\n",
      "sizes that pigs and rivers\n",
      "may exist in any of the\n",
      "four cardinal directions\n",
      "but lacks direct evidence\n",
      "to confirm a single hy-\n",
      "pothesis. Top-K Reasoning : The\n",
      "agent generates multi-\n",
      "ple plausible hypotheses,\n",
      "assigns probability esti-\n",
      "mates to each, and ranks\n",
      "them by likelihood. Table 4.Definitions of reasoning types, their associated uncertainty, examples, and the corresponding elicitation methods. Inductive Uncertainty arises when an agent generalizes from specific observations to broader conclusions based on\n",
      "incomplete data. Induction relies on identifying patterns from limited experiences, leading to inherent uncertainty. This\n",
      "is particularly relevant in open-world environments, where observations are partial, and inferred generalizations may not\n",
      "always hold. For example, an agent navigating an unfamiliar environment may observe that all previously encountered caves\n",
      "contained hostile entities. Based on this pattern, it may infer that any future cave is also dangerous. However, since this\n",
      "conclusion is based on a limited set of observations rather than a deterministic rule, the agent must assess how strongly its\n",
      "past experiences justify this generalization, introducing inductive uncertainty. To elicit inductive uncertainty, we employ Chain-of-Thought (Wei et al., 2022b), which prompts the agent to explicitly reflect\n",
      "on the reliability of its observed patterns. By systematically verbalizing its reasoning, the agent is encouraged to: (1) analyze\n",
      "the strength of observed trends, (2) consider possible exceptions or contradictory evidence, and (3) assess its confidence\n",
      "in applying the generalization to new situations. This structured elicitation enables the agent to express uncertainty in its\n",
      "inductive inferences rather than assuming patterns always hold. Deductive Uncertainty arises when an agent faces ambiguity due to missing, conflicting, or incomplete premises. Deductive\n",
      "13\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 13}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "uncertainty occurs within a structured decision-making process when the available information is insufficient to determine\n",
      "a definitive outcome. Consider an agent tasked with crafting a wooden tool in a survival environment. It knows the rule:\n",
      "”If wood is available, then a wooden tool can be crafted.” However, if the agent is uncertain whether wood is currently\n",
      "accessible, it cannot confidently conclude whether crafting is possible. This scenario exemplifies deductive uncertainty,\n",
      "where the agent’s ability to reason is constrained by unknown or ambiguous premises. To elicit deductive uncertainty, we usePlan-and-Solve prompting (Wang et al., 2023b), which guides the agent through a\n",
      "structured reasoning process. The agent is encouraged to: (1) formulate a comprehensive set of premises relevant to the task,\n",
      "(2) identify any missing premises or dependencies, and (3) assess its confidence in executing each step successfully. This\n",
      "structured elicitation enables the agent to explicitly express uncertainty when premises are incomplete or insufficient to\n",
      "deduce a definitive conclusion. Abductive Uncertainty occurs when an agent must infer the most plausible explanation for an observation without definitive\n",
      "evidence. Abduction involves hypothesis generation under uncertainty. The challenge in abductive reasoning lies in selecting\n",
      "the most probable explanation when multiple interpretations exist, each carrying some degree of uncertainty. A simple\n",
      "example occurs when an agent is tasked with locating a pig near a river for unspecified reasons. Given its environment, the\n",
      "agent may hypothesize that pigs and rivers could exist in any of the four cardinal directions but are unlikely to be present in\n",
      "all directions simultaneously. Since the agent lacks direct evidence to confirm a single hypothesis, it must infer the most\n",
      "plausible explanation, leading to abductive uncertainty. To elicit abductive uncertainty, we implementTop-K reasoning(Robinson & Wingate, 2023), where the agent is instructed\n",
      "to generate multiple plausible hypotheses explaining an observation and assign probability estimates to each. This process\n",
      "forces the agent to explicitly consider alternative interpretations, rank them by likelihood, and communicate the level of\n",
      "confidence in its inferences. By quantifying uncertainty across multiple competing hypotheses, Top-K reasoning reveals the\n",
      "agent’s abductive reasoning capabilities.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 13}\n",
      "B. Task Setting Details\n",
      "Inspired by previous works (Lin et al., 2023; Qin et al., 2024), we define a set of 30 tasks evenly distributed across three\n",
      "difficulty levels: easy, medium, and hard. Categorization is based on the complexity of reasoning required and the extent\n",
      "of contextual information necessary for successful task completion.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 13}\n",
      "Each difficulty level incorporates distinct challenges,\n",
      "ranging from straightforward operations to intricate reasoning across interdependent objectives, with a balanced distribution\n",
      "of complexity within the task set. We present all tasks and highlight entities of different categories in Table 5\n",
      "Easy Tasks are designed to evaluate the agent’s ability to process minimal perceptual information and perform straightfor-\n",
      "ward actions with limited reasoning. These tasks typically require the perception of only one environmental element from\n",
      "predefined categories such as Object, Mob, Ecology, Time, Weather, or Brightness (Qin et al., 2024). For example, tasks\n",
      "at this level may involve identifying a specific object in the environment or recognizing a simple temporal condition (e.g.,\n",
      "daytime or nighttime). The actions required are relatively simple and involve a single reasoning step, such as gathering an\n",
      "object that is readily visible. Medium Tasks introduce moderate complexity by requiring the perception and integration of two to three environmental\n",
      "elements, alongside a corresponding increase in reasoning steps. Tasks at this level involve combining multiple types of\n",
      "perceptual data, such as recognizing a specific biome and locating a particular mob or object within it. For example, the\n",
      "agent might need to identify a forest biome, locate a pig, and gather specific materials. In addition to perceptual challenges,\n",
      "medium tasks often include sequential sub-goals, such as collecting and combining resources to create basic tools. These\n",
      "tasks require the agent to interpret dynamic environmental information, execute plans involving multiple steps, and adapt to\n",
      "minor changes in the environment. This level evaluates the agent’s ability to balance perception, reasoning, and adaptability. Hard Tasks are the most challenging and require the agent to process and integrate multiple layers of perceptual information\n",
      "(up to six elements) while performing complex situation-aware planning and dynamic action execution. These tasks involve\n",
      "a high level of reasoning, such as decomposing long-term objectives into interdependent sub-tasks, managing uncertainties\n",
      "in the environment, and dynamically adjusting strategies in response to real-time changes. For example, a hard task might\n",
      "involve navigating through hazardous biomes, identifying and gathering multiple resources, and crafting advanced tools or\n",
      "items that require sequential processing and the use of specialized platforms. Environmental conditions, such as weather,\n",
      "time of day, or changing brightness, may dynamically impact the task, necessitating constant adaptation by the agent. These\n",
      "tasks often introduce significant challenges, such as hostile mobs or the need to traverse difficult terrain, testing the agent’s\n",
      "14\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 14}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Mine Wood Log\n",
      "Craft Wooden\n",
      "Planks\n",
      "Craft Sticks\n",
      "Craft Wooden\n",
      "Pickaxe\n",
      "Craft Stone\n",
      "Pickaxe\n",
      "Mine\n",
      "Cobblestone\n",
      "Craft\n",
      "CraftingTable\n",
      "Craft Iron\n",
      "Pickaxe\n",
      "Smelt Raw\n",
      "Iron\n",
      "Mine Iron Ore\n",
      "Mine Coal Ore\n",
      "Craft Furnace\n",
      "Obtain Diamond\n",
      "Figure 6.An illustrative diagram of the Obtain Diamond task, featuring five distinct colors to represent the source materials re-\n",
      "quired—wood, stone, iron, coal, and diamond—aligned with the Minecraft tech tree. ability to balance perception, planning, and execution effectively. The (obtain) Diamond Task is one of the most iconic and challenging benchmarks in Minecraft agent research, serving as a\n",
      "comprehensive test of an agent’s long-horizon planning, resource management, and adaptability. The task requires the agent\n",
      "to progress through multiple interdependent steps, including gathering basic resources like wood and stone, crafting tools\n",
      "such as a pickaxe, and locating and mining diamonds deep within underground caves (See Figure 6). Each step presents\n",
      "its own set of challenges, such as navigating complex terrain, managing limited resources, and avoiding environmental\n",
      "hazards like lava or hostile mobs. The randomized nature of Minecraft’s procedural world generation further compounds\n",
      "the difficulty, as the agent must adapt dynamically to new environments while maintaining focus on the ultimate objective. Success in the “Obtain Diamond” task is often seen as a key indicator of an agent’s ability to integrate active perception,\n",
      "situational awareness, and embodied action execution in an open-world setting. This task demonstrates the complexity\n",
      "of open-ended problem-solving and has become a gold standard for evaluating the capabilities of autonomous agents in\n",
      "multi-modal and multi-step scenarios. We added the diamond task as one of our hard tasks.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 14}\n",
      "C. Detailed Model Descriptions\n",
      "GPT-4V:This vision-capable variant of GPT-4 excels at processing both visual and textual inputs, making it a powerful\n",
      "tool for tackling tasks within the visually complex Minecraft environment. Unlike its predecessors, GPT-4V’s ability to\n",
      "seamlessly combine perception and reasoning allows for sophisticated decision-making and planning. The GPT-4 series\n",
      "has already demonstrated its efficacy in Minecraft-based research. For instance, V oyager (Wang et al., 2023a), the first\n",
      "LLM-powered embodied lifelong learning agent, used GPT-4 to facilitate continuous exploration, skill acquisition, and task\n",
      "execution without human intervention. V oyager’s architecture included an automatic curriculum for exploration and a skill\n",
      "library to store and retrieve executable code, allowing agents to adapt and improve iteratively. Similarly, Optimus-1 (Li\n",
      "et al., 2025) employs GPT-4V to refine its planning processes, focusing on logical reasoning and task generalization. These\n",
      "implementations underscore GPT-4V’s pivotal role in advancing embodied AI research, offering exceptional capabilities for\n",
      "both exploration and problem-solving. MineLLM: Tailored specifically for tasks within Minecraft, MineLLM represents a significant leap in AI development\n",
      "for complex embodied environments. As a central component of the MP5 framework (Qin et al., 2024), MineLLM is\n",
      "designed to tackle the unique challenges posed by Minecraft’s open-ended tasks. It combines the image visual encoder\n",
      "from MineCLIP (Fan et al., 2022) with the Vicuna-13B-v1.5 language model for integrating visual perception with natural\n",
      "15\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 15}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Difficulty Task ID Task Description\n",
      "Easy\n",
      "1 Find a pig\n",
      "2 Find a cow\n",
      "3 Find a tree\n",
      "4 Mine log\n",
      "5 Mine sand\n",
      "6 Craft a plank\n",
      "7 Craft a stick\n",
      "8 Craft a chest\n",
      "9 Craft a wooden door\n",
      "10 Craft a wooden boat\n",
      "Medium\n",
      "11 Find a tree\n",
      " in the forest\n",
      "12 Find a pig\n",
      " on grass\n",
      "13 Find a cow\n",
      " in the desert\n",
      "14 Craft a wooden sword\n",
      "15 Craft a wooden pickaxe\n",
      "16 Craft a stone pickaxe\n",
      "17 Smelt an iron ingot\n",
      "18 Smelt glass\n",
      "19 Cook beef\n",
      "20 Cook mutton\n",
      "Hard\n",
      "21 Find a pig\n",
      " near a grass\n",
      " in the forest\n",
      " during the daytime\n",
      "22 Find a cow\n",
      " in the desert\n",
      " during the daytime\n",
      "23 Find a grass\n",
      " near a pig\n",
      " in the forest\n",
      "24 Find a pig\n",
      " while wearing an iron helmet\n",
      "25 Craft an iron door\n",
      "26 Craft an iron pickaxe\n",
      "27 Craft an iron sword\n",
      "28 Craft a compass\n",
      "29 Kill a zombie\n",
      " with an iron sword\n",
      "30 Obtain a diamond\n",
      "Table 5.Full task details. 30 tasks evenly distributed as easy, medium, and hard.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 15}\n",
      "Underlines label different information categories in\n",
      "Minecraft, highlighting how the complexity varies at each level. 16\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 16}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "language understanding. Trained on a vast dataset of 500,000 Minecraft-specific image-text instruction pairs, MineLLM\n",
      "can generate detailed insights about the game environment, answer complex queries, and provide contextual guidance for\n",
      "planning and execution. Its integration into MP5 enables the framework to address context- and process-dependent tasks\n",
      "with remarkable success rates, achieving a 91% success rate on context-dependent tasks and demonstrating exceptional\n",
      "adaptability in novel scenarios. STEVE: The STEVE series represents another advancement in language model-driven embodied agents for the Minecraft\n",
      "environment (Zhao et al., 2025). Built upon the foundation of LLaMA-2 (Touvron et al., 2023b), STEVE integrates powerful\n",
      "language capabilities tailored to enhance task reasoning, contextual understanding, and interaction. At its core, the language\n",
      "model in the STEVE series excels at decomposing complex objectives into actionable subtasks through iterative reasoning\n",
      "and hierarchical planning. This allows STEVE agents to process high-level instructions effectively and generate detailed\n",
      "plans for task execution. The STEVE series relies heavily on its ability to adapt to Minecraft-specific tasks. To this end,\n",
      "Zhao et al. (2025) curated the STEVE-21K dataset, containing 20K knowledge-based question-answering pairs and 200+\n",
      "skill-code pairs that directly enhance the model’s contextual understanding and task reasoning. These adaptations enable the\n",
      "language model to seamlessly integrate with perception and action modules, driving coherent decision-making in real time. Furthermore, STEVE agents leverage advanced contextual awareness to refine their decision-making processes, significantly\n",
      "outperforming prior benchmarks in task decomposition and completion efficiency. The series also demonstrated up to 1.5x\n",
      "faster progression in complex tasks like unlocking tech trees and up to 2.5x quicker performance in block search scenarios\n",
      "compared to other state-of-the-art models. D.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 16}\n",
      "Additional Experiments\n",
      "Do Hard Tasks Lead to Poor Calibration? We use the best-performing GPT-4V as our agent backbone and withhold any\n",
      "execution policies to reduce computation costs. We set the maximum episode length as 12,000 to provide enough coverage\n",
      "for all task difficulties.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 16}\n",
      "Results are shown in Table 6. Task Policies ECE ( ↓) AUROC ( ↑) Success Rate ( ↑)\n",
      "Easy\n",
      "Vanilla 0.26 0.76 84%\n",
      "Self-Intervention 0.26 0.76 92%\n",
      "CoT 0.11 0.78 94%\n",
      "P&S 0.12 0.80 82%\n",
      "Top-K 0.32 0.72 74%\n",
      "Medium\n",
      "Vanilla 0.35 0.54 52%\n",
      "Self-Intervention 0.35 0.51 44%\n",
      "CoT 0.22 0.58 54%\n",
      "P&S 0.22 0.55 48%\n",
      "Top-K 0.40 0.47 32%\n",
      "Hard\n",
      "Vanilla 0.33 0.58 17%\n",
      "Self-Intervention 0.35 0.52 12%\n",
      "CoT 0.31 0.68 18%\n",
      "P&S 0.32 0.71 18%\n",
      "Top-K 0.41 0.49 8%\n",
      "Table 6.ECE, AUROC, and Success Rates for Different Task Difficulties and Elicitation Policies. Lower ECE and higher AUROC/Success\n",
      "Rates indicate better performance. For Easy tasks, CoT demonstrated the best performance, achieving the lowest ECE (0.11) and the highest success rate\n",
      "(94%), followed by P&S, which recorded the highest AUROC of 0.80 and a success rate of 82%. Self-Intervention performed\n",
      "comparably in calibration (ECE = 0.26, AUROC = 0.76). Top-K underperformed, with the highest ECE (0.32) and the\n",
      "lowest success rate (74%), indicating limitations in leveraging task simplicity. For Medium tasks, all policies showed\n",
      "noticeable declines in performance. CoT emerged as the best overall, with an ECE of 0.22, an AUROC of 0.58, and a\n",
      "success rate of 54%, balancing calibration and task success effectively. P&S followed closely with similar calibration (ECE\n",
      "= 0.22) but a slightly lower AUROC (0.55) and success rate (48%). For Hard tasks, performance further degraded across\n",
      "all policies. CoT and P&S maintained relative superiority, with CoT achieving an ECE of 0.31, AUROC of 0.68, and a\n",
      "success rate of 22%, while P&S recorded slightly worse calibration (ECE = 0.32) and the highest AUROC (0.71) but tied for\n",
      "a success rate of 18%. 17\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 17}\n",
      "Confidence Elicitation in Embodied Agents\n",
      "These results confirm our hypothesis that as task difficulty increases, confidence calibration significantly deteriorates, with\n",
      "the ECE gap increasing as high as 0.20 (Easy CoT vs. Hard CoT).\n",
      "----------------------------------------------------------------------------------------------------\n",
      "{'source': 'data/arxiv_paper.pdf', 'page': 17}\n",
      "However, the results also demonstrate that structured\n",
      "elicitation policies, such as CoT and P&S, consistently prove effective in handling calibration, failure prediction, and task\n",
      "success across task difficulties. Additionally, simpler policies like Self-Intervention also show moderate success, particularly\n",
      "in easier tasks, suggesting their utility in less demanding scenarios. 18\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"총 {len(docs)}개 만큼의 문서로 청킹되었습니다.\")\n",
    "\n",
    "# 각 청크의 길이(문자 개수) 출력\n",
    "print([len(i.page_content) for i in docs])\n",
    "\n",
    "# 각 청크의 메타데이터 및 내용 출력\n",
    "for i in docs:\n",
    "    print(i.metadata)       # 문서의 메타데이터 출력 (예: 페이지 번호 등)\n",
    "    print(i.page_content)   # 분할된 청크의 내용 출력\n",
    "    print(\"-\" * 100)       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
