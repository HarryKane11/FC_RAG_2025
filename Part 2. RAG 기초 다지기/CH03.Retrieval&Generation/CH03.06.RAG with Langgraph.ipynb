{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCEL로 RAG 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_qdrant import qdrant\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyPDF로 문서에서 텍스트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader(\n",
    "    file_path=\"data/arxiv_paper.pdf\",\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes.\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "understanding high-level tasks or goals ( e.g., “I am 70%\n",
      "confident I craft a wooden table”). 3) Interactive depen-\n",
      "dencies, where the agent’s actions directly influence the\n",
      "environment, which in turn affects subsequent decisions,\n",
      "requiring ongoing adjustments to confidence estimates as\n",
      "tasks progress. 4) Finally, while state-of-the-art embodied\n",
      "agents leverage proprietary Large Language Models (LLMs)\n",
      "and Vision-Language Models (VLMs) for their strong mu\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 1, 'page_label': '2'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ElicitationPolicies What do you see?How confident are you? \n",
      "I see a pig next to\n",
      "a tree to the left [85% confident]\n",
      "ExecutionPolicies\n",
      "What do you see? Especially\n",
      "around the pig. How\n",
      "confident are you?\n",
      "What do you see? Especially\n",
      "around the trees. Howconfident are you?\n",
      "What do you see? Especially\n",
      "to your right. How confident\n",
      "are you?\n",
      "I see a pig with two trees \n",
      "[80% confident]\n",
      "I see sheeps and cows \n",
      "[90% confident]\n",
      "I see a mountain to the left\n",
      "[70% confide\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Method Prompt\n",
      "Vanilla\n",
      "Read the task (e.g., collect wood, build a shelter), provide your answer, and explain how confident\n",
      "you are in perceiving the environment accurately to complete the task (e.g., recognizing resources,\n",
      "locating structures, identifying threats).\n",
      "Read the task given, provide your answer, and explain how confident you are in planning and executing\n",
      "the actions needed to achieve the goal (e.g., gathering materials, crafting tools, building\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 3, 'page_label': '4'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ter quantify uncertainty and anticipate divergent outcomes.\n",
      "To address this, we introduce a set of policies that gener-\n",
      "ate additional observations and diverse action trajectories,\n",
      "promoting robust confidence assessment:\n",
      "⟳ Action Sampling: The agent can generate multiple pos-\n",
      "sible actions by sampling from a learned policy distribution\n",
      "over the action space, conditioned on the current state and\n",
      "task objectives. By doing so, the agent can explore multiple\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Metric Model Vanilla Self-Intervention CoT (Inductive) P&S (Deductive) Top-K (Abductive)\n",
      "ECE ↓\n",
      "GPT-4V 0.27 0.21 0.16 0.15 0.17\n",
      "MineLLM 0.49 0.41 0.34 0.39 0.43\n",
      "STEVE 0.43 0.32 0.26 0.26 0.35\n",
      "AUROC ↑\n",
      "GPT-4V 0.69 0.76 0.83 0.82 0.73\n",
      "MineLLM 0.53 0.59 0.64 0.61 0.58\n",
      "STEVE 0.58 0.69 0.72 0.67 0.68\n",
      "PR-P ↑\n",
      "GPT-4V 0.66 0.76 0.81 0.79 0.70\n",
      "MineLLM 0.51 0.59 0.63 0.60 0.57\n",
      "STEVE 0.56 0.67 0.69 0.66 0.64\n",
      "PR-N ↑\n",
      "GPT-4V 0.52 0.53 0.58 0.55 0.53\n",
      "MineLLM 0.39 0.42 0.4\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Vanilla Self-Intervention CoT P&S Top-K\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.24\n",
      "0.22\n",
      "0.14\n",
      "0.10\n",
      "0.12\n",
      "0.11\n",
      "0.11\n",
      "0.12\n",
      "0.11\n",
      "0.11\n",
      "0.13\n",
      "0.18\n",
      "0.12\n",
      "0.14\n",
      "0.15\n",
      "ECE ↓\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.50\n",
      "0.53\n",
      "0.52\n",
      "0.35\n",
      "0.42\n",
      "0.50\n",
      "0.32\n",
      "0.44\n",
      "0.33\n",
      "0.30\n",
      "0.45\n",
      "0.38\n",
      "0.42\n",
      "0.47\n",
      "0.43\n",
      "ECE ↓\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.40\n",
      "0.42\n",
      "0.41\n",
      "0.28\n",
      "0.27\n",
      "0.39\n",
      "0.24\n",
      "0.24\n",
      "0.33\n",
      "0.27\n",
      "0.28\n",
      "0.35\n",
      "0.30\n",
      "0.31\n",
      "0.34\n",
      "ECE ↓\n",
      "Action\n",
      "Sampling\n",
      "Scenario\n",
      "Reinterpretation\n",
      "Hypothetical\n",
      "Reasoning\n",
      "0\n",
      "0.2\n",
      "0.4\n",
      "0.6\n",
      "0.8\n",
      "1\n",
      "0.76\n",
      "0.75\n",
      "0.78\n",
      "0.80\n",
      "0.79\n",
      "0.81\n",
      "\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 6, 'page_label': '7'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Execution Strategies GPT-4V MineLLM STEVE\n",
      "ECE ↓ AUROC ↑ ECE ↓ AUROC ↑ ECE ↓ AUROC ↑\n",
      "No Execution Strategy 0.27 0.69 0.49 0.53 0.43 0.58\n",
      "AS + SR 0.18 0.82 0.32 0.59 0.39 0.69\n",
      "AS + HR 0.20 0.79 0.34 0.57 0.37 0.66\n",
      "SR + HR 0.22 0.80 0.37 0.54 0.44 0.58\n",
      "AS + SR + HR 0.17 0.83 0.32 0.62 0.38 0.69\n",
      "Table 3.Performance of Vanilla Elicitation with Combined Execution Strategies. AS = Action Sampling, SR = Scenario Reinterpreta-\n",
      "tion, HR = Hypothetical Reasoning. E\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 7, 'page_label': '8'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "8. Impact Statement\n",
      "This work advances Embodied AI by introducing confidence\n",
      "elicitation and execution policies tailored to multimodal and\n",
      "dynamic environments. By enabling embodied agents to\n",
      "express uncertainty, our approach enhances their calibra-\n",
      "tion, adaptability, and reliability in complex tasks. This\n",
      "contribution supports safer AI deployment in real-world do-\n",
      "mains like robotics, education, and collaborative systems,\n",
      "where accurate self-assessment\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Goel, V . Anatomy of deductive reasoning.Trends in cogni-\n",
      "tive sciences, 2007.\n",
      "Groot, T. and Valdenegro Toro, M. Overconfidence is key:\n",
      "Verbalized uncertainty evaluation in large language and\n",
      "vision-language models. In Trustworthy Natural Lan-\n",
      "guage Processing, 2024.\n",
      "Guo, X., Huang, K., Liu, J., Fan, W., V ´elez, N., Wu, Q.,\n",
      "Wang, H., Griffiths, T. L., and Wang, M. Embodied\n",
      "LLM agents learn to cooperate in organized teams. In\n",
      "Language Gamification - Neur\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 9, 'page_label': '10'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Malinin, A. and Gales, M. Uncertainty estimation in autore-\n",
      "gressive structured prediction. In International Confer-\n",
      "ence on Learning Representations, 2021.\n",
      "Mielke, S. J., Szlam, A., Dinan, E., and Boureau, Y .-L.\n",
      "Reducing conversational agents’ overconfidence through\n",
      "linguistic calibration. Transactions of the Association for\n",
      "Computational Linguistics, 2022.\n",
      "Naeini, M. P., Cooper, G., and Hauskrecht, M. Obtaining\n",
      "well calibrated probabilities using baye\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 10, 'page_label': '11'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Interactive planning with large language models enables\n",
      "open-world multi-task agents. In Advances in Neural\n",
      "Information Processing Systems, 2023c.\n",
      "Wei, J., Tay, Y ., Bommasani, R., Raffel, C., Zoph, B.,\n",
      "Borgeaud, S., Yogatama, D., Bosma, M., Zhou, D., Met-\n",
      "zler, D., Chi, E. H., Hashimoto, T., Vinyals, O., Liang,\n",
      "P., Dean, J., and Fedus, W. Emergent abilities of large\n",
      "language models. Transactions on Machine Learning\n",
      "Research, 2022a.\n",
      "Wei, J., Wang, X., Sc\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 11, 'page_label': '12'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "A. Definitions of Uncertainty Types\n",
      "The three fundamental forms of logical reasoning, inductive, deductive, and abductive, have long been recognized and\n",
      "studied (Peirce, 1934; Walton, 2014; Wei et al., 2022b; Levine et al., 2022; Okoli, 2023). As language models demonstrated\n",
      "extraordinary abilities, designing better reasoning mechanisms has become a popular research trend (Cheng et al., 2024; Liu\n",
      "et al., 2024). These reasoning paradigms serve as fundamen\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 12, 'page_label': '13'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "uncertainty occurs within a structured decision-making process when the available information is insufficient to determine\n",
      "a definitive outcome. Consider an agent tasked with crafting a wooden tool in a survival environment. It knows the rule:\n",
      "”If wood is available, then a wooden tool can be crafted.” However, if the agent is uncertain whether wood is currently\n",
      "accessible, it cannot confidently conclude whether crafting is possible. This scenario exempli\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 13, 'page_label': '14'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Mine Wood Log\n",
      "Craft Wooden\n",
      "Planks\n",
      "Craft Sticks\n",
      "Craft Wooden\n",
      "Pickaxe\n",
      "Craft Stone\n",
      "Pickaxe\n",
      "Mine\n",
      "Cobblestone\n",
      "Craft\n",
      "CraftingTable\n",
      "Craft Iron\n",
      "Pickaxe\n",
      "Smelt Raw\n",
      "Iron\n",
      "Mine Iron Ore\n",
      "Mine Coal Ore\n",
      "Craft Furnace\n",
      "Obtain Diamond\n",
      "Figure 6.An illustrative diagram of the Obtain Diamond task, featuring five distinct colors to represent the source materials re-\n",
      "quired—wood, stone, iron, coal, and diamond—aligned with the Minecraft tech tree.\n",
      "ability to balance perception,\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 14, 'page_label': '15'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "Difficulty Task ID Task Description\n",
      "Easy\n",
      "1 Find a pig\n",
      "2 Find a cow\n",
      "3 Find a tree\n",
      "4 Mine log\n",
      "5 Mine sand\n",
      "6 Craft a plank\n",
      "7 Craft a stick\n",
      "8 Craft a chest\n",
      "9 Craft a wooden door\n",
      "10 Craft a wooden boat\n",
      "Medium\n",
      "11 Find a tree\n",
      " in the forest\n",
      "12 Find a pig\n",
      " on grass\n",
      "13 Find a cow\n",
      " in the desert\n",
      "14 Craft a wooden sword\n",
      "15 Craft a wooden pickaxe\n",
      "16 Craft a stone pickaxe\n",
      "17 Smelt an iron ingot\n",
      "18 Smelt glass\n",
      "19 Cook beef\n",
      "20 Cook mutton\n",
      "Hard\n",
      "21 Find a pig\n",
      " near a gra\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 15, 'page_label': '16'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "language understanding. Trained on a vast dataset of 500,000 Minecraft-specific image-text instruction pairs, MineLLM\n",
      "can generate detailed insights about the game environment, answer complex queries, and provide contextual guidance for\n",
      "planning and execution. Its integration into MP5 enables the framework to address context- and process-dependent tasks\n",
      "with remarkable success rates, achieving a 91% success rate on context-dependent tasks and demonstrati\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 16, 'page_label': '17'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "These results confirm our hypothesis that as task difficulty increases, confidence calibration significantly deteriorates, with\n",
      "the ECE gap increasing as high as 0.20 (Easy CoT vs. Hard CoT). However, the results also demonstrate that structured\n",
      "elicitation policies, such as CoT and P&S, consistently prove effective in handling calibration, failure prediction, and task\n",
      "success across task difficulties. Additionally, simpler policies like Self-Interventio\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 17, 'page_label': '18'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content[:500])\n",
    "    print(doc.metadata)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2}@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes. We\n",
      "present the first work investigating embodied con-\n",
      "fidence elicitation in open-ended multimodal en-\n",
      "vironments. We introduce Elicitation Policies,\n",
      "which structure confidence assessment across\n",
      "inductive, deductive, and abductive reasoning,\n",
      "along with Execution Policies, which enhance\n",
      "confidence calibration through scenario reinter-\n",
      "pretation, action sampling, and hypothetical rea-\n",
      "soning. Evaluating agents in calibration and fail-\n",
      "ure prediction tasks within the Minecraft envi-\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([len(chunk.page_content) for chunk in splits])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ollama Embedding으로 bge-m3 기반 텍스트 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qdrant 벡터DB(인메모리)에 임베딩 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from uuid import uuid4\n",
    "\n",
    "\n",
    "# 로컬 저장소를 위한 Qdrant 클라이언트 생성\n",
    "client = QdrantClient(path=\"/tmp/arxiv_paper\")\n",
    "\n",
    "# # 밀집 벡터로 컬렉션 생성\n",
    "# client.create_collection(\n",
    "#     collection_name=\"embodied_agent_0413\",\n",
    "#     vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    "# )\n",
    "\n",
    "qdrant = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"embodied_agent_0413\",\n",
    "    embedding=embeddings,\n",
    "    retrieval_mode=RetrievalMode.DENSE,\n",
    ")\n",
    "\n",
    "# uuids = [str(uuid4()) for _ in range(len(splits))]\n",
    "\n",
    "# qdrant.add_documents(documents=splits, ids=uuids)\n",
    "\n",
    "# 벡터 저장소를 검색기로 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 벡터DB 기반 Retriever 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir Wahed, Kiet A. Nguyen, Adheesh Juvekar\n",
      "Tal August, Ismini Lourentzou\n",
      "University of Illinois Urbana-Champaign\n",
      "{ty41,vrshah4,mwahed2,kietan2,adheesh2,taugust,lourent2 }@illinois.edu\n",
      "https://plan-lab.github.io/ece\n",
      "Abstract\n",
      "Expressing confidence is challenging for embod-\n",
      "ied agents navigating dynamic multimodal en-\n",
      "vironments, where uncertainty arises from both\n",
      "perception and decision-making processes\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 0, 'page_label': '1', '_id': 'd40b3ddb-0965-4d47-8d44-80a29acf5121', '_collection_name': 'embodied_agent_0413'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "8. Impact Statement\n",
      "This work advances Embodied AI by introducing confidence\n",
      "elicitation and execution policies tailored to multimodal and\n",
      "dynamic environments. By enabling embodied agents to\n",
      "express uncertainty, our approach enhances their calibra-\n",
      "tion, adaptability, and reliability in complex tasks. This\n",
      "contribution supports safer AI deployment in real-world do-\n",
      "mains like robotics, education, and collaborative systems,\n",
      "where accurate self-assessment\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 8, 'page_label': '9', '_id': 'a8c2d274-dae5-4317-86b8-ef534f6530a1', '_collection_name': 'embodied_agent_0413'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tend to yield improved confidence calibration. For instance,\n",
      "MineLLM’s ECE achieves 0.32 and 0.30 paired with CoT\n",
      "and P&S respectively, outperforming other combinations.\n",
      "Hypothetical Reasoning sometimes degrades performance.\n",
      "For instance, STEVE’s ECE worsens when pairing Hypo-\n",
      "thetical Reasoning with all Elicitation Policies, suggesting\n",
      "that while this execution strategy allows models to reason\n",
      "over multiple possible outcomes, it may introduce uncer-\n",
      "tainty, leading to less calibrated confidence\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 5, 'page_label': '6', '_id': '040ae1f1-1371-44d2-a235-23a545587c87', '_collection_name': 'embodied_agent_0413'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Confidence Elicitation in Embodied Agents\n",
      "ter quantify uncertainty and anticipate divergent outcomes.\n",
      "To address this, we introduce a set of policies that gener-\n",
      "ate additional observations and diverse action trajectories,\n",
      "promoting robust confidence assessment:\n",
      "⟳Action Sampling : The agent can generate multiple pos-\n",
      "sible actions by sampling from a learned policy distribution\n",
      "over the action space, conditioned on the current state and\n",
      "task objectives. By doing so, the agent can explore multiple\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 4, 'page_label': '5', '_id': '48f0aa47-5125-45b1-95e5-09a63d6fe176', '_collection_name': 'embodied_agent_0413'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "and other types of language-based guidance. For a given\n",
      "taskT, the agent operates under a policy π:I → A that\n",
      "maps input Ito actions A. The task of embodied confidence\n",
      "elicitation is to enable agents to estimate and articulate a\n",
      "confidence score c∈[0,1], representing their belief in the\n",
      "correctness of their perception and subsequent actions.The challenge lies in systematically identifying, quantify-\n",
      "ing, and articulating uncertainty as the agent interacts with\n",
      "its environment and executes tasks.\n",
      "{'producer': 'pdfTeX-1.40.25', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-03-14T01:17:30+00:00', 'author': 'Tianjiao Yu,, Vedant Shah,, Muntasir Wahed,, Kiet A. Nguyen,, Adheesh Juvekar, Tal August,, Ismini Lourentzou', 'keywords': 'Embodied Agents, Uncertainty in Embodied AI, Verbalized Uncertainty', 'moddate': '2025-03-14T01:17:30+00:00', 'ptex.fullbanner': 'This is pdfTeX, Version 3.141592653-2.6-1.40.25 (TeX Live 2023) kpathsea version 6.3.5', 'subject': 'Proceedings of the International Conference on Machine Learning 2025', 'title': 'Uncertainty in Action: Confidence Elicitation in Embodied Agents', 'trapped': '/False', 'source': 'data/arxiv_paper.pdf', 'total_pages': 18, 'page': 2, 'page_label': '3', '_id': '67e06c28-e160-4552-9115-405401398b8d', '_collection_name': 'embodied_agent_0413'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "retriever = qdrant.as_retriever()\n",
    "\n",
    "search_result=retriever.invoke(\"Embodied Agent가 뭐야?\", k=5)\n",
    "\n",
    "for doc in search_result:\n",
    "    print(doc.page_content[:500])\n",
    "    print(doc.metadata)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG 프롬프트 템플릿 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "당신은 Q&A 전문 AI 어시스턴트입니다. 주어진 컨텍스트를 사용하여 질문에 답변해주세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단순 답변 Streaming하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제공된 컨텍스트에 따르면, Embodied Agent는 다음과 같이 설명할 수 있습니다.\n",
      "\n",
      "*   **불확실성 획득을 위한 정책 생성:** 불확실성을 정량화하고 다양한 결과에 대비하기 위해 여러 관찰을 생성하고 다양한 행동 경로를 생성하는 정책을 생성합니다.\n",
      "*   **행동 샘플링:** 현재 상태와 작업 목표에 따라 학습된 정책 분포에서 여러 가능한 행동을 생성합니다. 이를 통해 다양한 결과를 평가하고 가장 성공할 가능성이 높은 행동을 평가합니다.\n",
      "*   **시나리오 재해석:** 동일한 시나리오를 다른 관점에서 재해석하여 다른 행동 경로를 제안하고 관련 환경 정보를 수집합니다.\n",
      "*   **실행 정책:** 시나리오 재해석, 행동 샘플링, 가설적 추론을 통해 신뢰도 캘리브레이션을 향상시키는 정책입니다.\n",
      "*   **복잡한 환경에서의 신뢰 표현:** 불확실성 평가, 추론, 환경 상호 작용을 통합하여 복잡한 환경에서 신뢰를 표현하는 데 중점을 둡니다.\n",
      "\n",
      "요약하자면, Embodied Agent는 불확실성을 효과적으로 관리하고 표현하여 복잡한 환경에서 신뢰를 획득하고 캘리브레이션하는 데 초점을 맞춘 AI 에이전트입니다."
     ]
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:4b\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain.stream(\"Embodied Agent를 설명해주세요\"):\n",
    "    print(chunk, end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고한 소스를 함께 스트리밍하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Retrieved Documents:\n",
      "소스 [1]: <Uncertainty in Action: Confidence Elicitation in Embodied Agents>\n",
      "참고 내용: Confidence Elicitation in Embodied Agents\n",
      "ter quantify uncertainty and anticipate divergent outcomes...\n",
      "\n",
      "소스 [2]: <Uncertainty in Action: Confidence Elicitation in Embodied Agents>\n",
      "참고 내용: Uncertainty in Action: Confidence Elicitation in Embodied Agents\n",
      "Tianjiao Yu, Vedant Shah, Muntasir ...\n",
      "\n",
      "소스 [3]: <Uncertainty in Action: Confidence Elicitation in Embodied Agents>\n",
      "참고 내용: tend to yield improved confidence calibration. For instance,\n",
      "MineLLM’s ECE achieves 0.32 and 0.30 pa...\n",
      "\n",
      "소스 [4]: <Uncertainty in Action: Confidence Elicitation in Embodied Agents>\n",
      "참고 내용: Confidence Elicitation in Embodied Agents\n",
      "8. Impact Statement\n",
      "This work advances Embodied AI by intr...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "제공된 컨텍스트에 따르면, Embodied Agent는 다음과 같이 설명할 수 있습니다.\n",
      "\n",
      "*   **불확실성 획득을 위한 정책 생성:** 이 에이전트는 현재 상태와 작업 목표를 기반으로 다양한 행동 경로를 생성하여 신뢰도 평가를 촉진하는 정책 세트를 생성합니다.\n",
      "*   **행동 샘플링:** 에이전트는 학습된 정책 분포에서 여러 가능한 행동을 생성하여 다양한 결과를 평가하고 가장 성공할 가능성이 높은 행동을 평가합니다.\n",
      "*   **시나리오 재해석:** 에이전트는 다른 관점에서 동일한 시나리오를 재해석할 수 있습니다. 예를 들어 특정 객체에 집중하거나, 환경 장애물을 재평가하거나, 목표물의 근접성을 재평가할 수 있습니다.\n",
      "*   **실행 정책:** 시나리오 재해석, 행동 샘플링, 가설적 추론을 통해 신뢰도 캘리브레이션을 향상시키는 실행 정책을 사용합니다.\n",
      "\n",
      "요약하면, Embodied Agent는 불확실성을 감지하고 예측하며, 다양한 행동 경로를 생성하여 신뢰도 평가를 촉진하는 에이전트입니다."
     ]
    }
   ],
   "source": [
    "# 문서 컨텍스트를 기반으로 답변을 생성하는 체인 정의\n",
    "rag_chain_from_docs = (\n",
    "    # 입력 데이터에서 context 필드를 추출하여 format_docs 함수로 처리\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    # 포맷된 컨텍스트와 질문을 프롬프트에 전달\n",
    "    | prompt\n",
    "    # 프롬프트를 LLM에 전달하여 응답 생성\n",
    "    | llm\n",
    "    # LLM의 응답을 문자열로 변환\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 검색 결과와 질문을 병렬로 처리하고 답변을 생성하는 최종 체인\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    # 검색기(retriever)로 문서를 가져오고, 질문을 그대로 전달\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "# 위에서 생성된 context와 question을 rag_chain_from_docs에 전달하여 answer 필드 추가\n",
    ").assign(answer=rag_chain_from_docs)\n",
    "\n",
    "for chunk in rag_chain_with_source.stream(\"Embodied Agent를 설명해주세요\"):\n",
    "    if \"context\" in chunk:\n",
    "        print(\"📚 Retrieved Documents:\")\n",
    "        for i, doc in enumerate(chunk[\"context\"]):\n",
    "            print(f\"소스 [{i+1}]: <{doc.metadata['title']}>\")\n",
    "            print(f\"참고 내용: {doc.page_content[:100]}...\\n\")\n",
    "        print(\"-\" * 80)\n",
    "    elif \"answer\" in chunk:\n",
    "        print(chunk[\"answer\"], end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
