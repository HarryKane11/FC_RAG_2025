{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langgraph로 RAG 구축하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gemma3:4b\", model_provider=\"ollama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문서에서 텍스트 추출 및 청킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_qdrant import qdrant\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "loader = PyPDFLoader(\n",
    "    file_path=\"data/arxiv_paper.pdf\",\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 임베딩 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"bge-m3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qdrant 벡터DB 저장 및 검색기 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_qdrant import QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "from uuid import uuid4\n",
    "\n",
    "client = QdrantClient(path=\"/tmp/0416(1)/arxiv_paper\")\n",
    "\n",
    "# 밀집 벡터로 컬렉션 생성\n",
    "client.create_collection(\n",
    "    collection_name=\"embodied_agent_0415\",\n",
    "    vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "qdrant = QdrantVectorStore(\n",
    "    client=client,\n",
    "    collection_name=\"embodied_agent_0415\",\n",
    "    embedding=embeddings,\n",
    "    retrieval_mode=RetrievalMode.DENSE,\n",
    ")\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(splits))]\n",
    "\n",
    "qdrant.add_documents(documents=splits, ids=uuids)\n",
    "\n",
    "# 벡터 저장소를 검색기로 설정\n",
    "retriever = qdrant.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_result=retriever.invoke(\"Embodied Agent가 뭐야?\")\n",
    "\n",
    "for doc in search_result:\n",
    "    print(doc.page_content[:500])\n",
    "    print(doc.metadata)\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 프롬프트 템플릿 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "당신은 Q&A 전문 AI 어시스턴트입니다. 주어진 컨텍스트를 사용하여 질문에 답변해주세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langgraph State, node, edge 선언하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 답변 스트리밍하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message, metadata in graph.stream(\n",
    "    {\"question\": \"Embodied Agent가 뭐야?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Output으로 답변에 주석 달기 - GPT-4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "당신은 Q&A 전문 AI 어시스턴트입니다. 주어진 컨텍스트를 사용하여 질문에 답변해주세요.\n",
    "\n",
    "컨텍스트:\n",
    "{context}\n",
    "\n",
    "질문:\n",
    "{question}\n",
    "\n",
    "답변:\n",
    "\"\"\")\n",
    "\n",
    "# Desired schema for response\n",
    "class AnswerWithSources(TypedDict):\n",
    "    \"\"\"An answer to the question, with sources.\"\"\"\n",
    "\n",
    "    answer: str\n",
    "    sources: Annotated[\n",
    "        List[str],\n",
    "        ...,\n",
    "        \"List of sources (title + page number + year ) used to answer the question\",\n",
    "    ]\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: AnswerWithSources\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(str((doc.metadata,doc.page_content)) for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "    structured_llm = llm.with_structured_output(AnswerWithSources)\n",
    "    response = structured_llm.invoke(messages)\n",
    "    return {\"answer\": response}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result = graph.invoke({\"question\": \"Embodied Agent가 뭐야?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['answer']['sources'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML로 답변에 참고 문서 주석달기 - Gemma3:4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# XML 시스템 프롬프트 정의\n",
    "xml_system = \"\"\"\n",
    "You're a helpful AI assistant. \n",
    "Given a user question and some document snippets,answer the user question and provide citations.\n",
    "If none of the documents answer the question, just say you don't know.\n",
    "\n",
    "Remember,You should return the source information(title, page, year) and answer. \n",
    "A citation consists of a VERBATIM quote that justifies the answer and the source information. \n",
    "Return a citation for every quote across all documents that justifies the answer. \n",
    "\n",
    "Use the following format for your final output:\n",
    "<cited_answer>\n",
    "    <answer></answer>\n",
    "    <citations>\n",
    "        <citation><source></source><quote></quote></citation>\n",
    "        <citation><source></source><quote></quote></citation>\n",
    "        ...\n",
    "    </citations>\n",
    "</cited_answer>\n",
    "\n",
    "Here are the documents:{context}\"\"\"\n",
    "\n",
    "xml_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", xml_system), (\"human\", \"{question}\")]\n",
    ")\n",
    "\n",
    "def format_docs_xml(docs: List[Document]) -> str:\n",
    "    formatted = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        source_info = f\"{doc.metadata.get('title', 'Unknown')}, page {doc.metadata.get('page', 'N/A')}, {doc.metadata.get('creationdate', 'N/A')[:4]}\"\n",
    "        doc_str = f\"\"\"\\\n",
    "        <source id=\\\"{i}\\\">\n",
    "            <source_info>{source_info}</source_info>\n",
    "            <content>{doc.page_content}</content>\n",
    "        </source>\"\"\"\n",
    "        formatted.append(doc_str)\n",
    "    return \"\\n\\n<sources>\" + \"\\n\".join(formatted) + \"</sources>\"\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    citations: List[str]\n",
    "    answer: Dict\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    formatted_docs = format_docs_xml(state[\"context\"])\n",
    "    messages = xml_prompt.invoke(\n",
    "        {\"question\": state[\"question\"], \"context\": formatted_docs}\n",
    "    )\n",
    "    llm = ChatOllama(model=\"gemma3:4b\")\n",
    "    response = llm.invoke(messages)\n",
    "    parsed_response = XMLOutputParser().invoke(response.content)\n",
    "    return {\"answer\": parsed_response, \"citations\": formatted_docs}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result = graph.invoke({\"question\": \"Embodied Agent가 뭐야?\"}, config = {\"configurable\": {\"thread_id\": \"1\"}})\n",
    "print(json.dumps(result[\"answer\"], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for citation in result[\"answer\"]['cited_answer'][1]['citations']:\n",
    "    print(f\"📚 참고 문서: {citation['citation'][0]['source']}\")\n",
    "    print(f\"💬 참고한 부분: {citation['citation'][1]['quote']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"answer\"]['cited_answer'][0]['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
