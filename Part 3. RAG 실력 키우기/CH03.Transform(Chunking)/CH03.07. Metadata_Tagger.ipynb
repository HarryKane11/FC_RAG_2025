{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ğŸ“˜ ë¬¸ì„œ QAìš© ë©”íƒ€ë°ì´í„° ìë™ íƒœê¹… íŠœí† ë¦¬ì–¼\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” `LangChain`ì˜ `create_metadata_tagger`ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œì— ìë™ìœ¼ë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ íƒœê¹…í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
        "\n",
        "ì´ ë°©ì‹ì€ RAG ì‹œìŠ¤í…œì˜ ë¬¸ì„œ ê²€ìƒ‰ í’ˆì§ˆì„ ë†’ì´ëŠ” ë° ìœ ìš©í•©ë‹ˆë‹¤. íŠ¹íˆ Late Chunkingì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ë¬¸ì„œ ì „ì²´ ë§¥ë½ì— ëŒ€í•œ ë©”íƒ€ ì •ë³´ê°€ ë” í’ë¶€í• ìˆ˜ë¡ ê²€ìƒ‰ ì •ë°€ë„ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1ï¸âƒ£ ë©”íƒ€ë°ì´í„° ìŠ¤í‚¤ë§ˆ ì •ì˜\n",
        "ìš°ë¦¬ëŠ” ë¬¸ì„œ ì œëª©, ì–´ì¡°, ê¸¸ì´ ë¶„ë¥˜ë¥¼ ì¶”ì¶œí•˜ëŠ” ìŠ¤í‚¤ë§ˆë¥¼ ì„¤ê³„í•©ë‹ˆë‹¤. ì´ ì •ë³´ëŠ” ë‚˜ì¤‘ì— ë²¡í„° ê²€ìƒ‰ ì‹œ í•„í„°ë§/ì¡°ê±´ ê²€ìƒ‰ì— ì‚¬ìš©ë©ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82def4f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_community.document_transformers.openai_functions import create_metadata_tagger\n",
        "from langchain_core.documents import Document\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class DocumentMetadata(BaseModel):\n",
        "    country: List[str] = Field(\n",
        "        description=\"ë¬¸ì„œì— ì–¸ê¸‰ëœ êµ­ê°€ë“¤ì˜ í•œê¸€ í‘œì¤€í™”ëœ ëª…ì¹­ (ì˜ˆ: 'ë¯¸êµ­', 'ëŒ€í•œë¯¼êµ­', 'ì¼ë³¸')\"\n",
        "    )\n",
        "    organization: List[str] = Field(\n",
        "        description=\"ë¬¸ì„œì— ì–¸ê¸‰ëœ ì¡°ì§ì´ë‚˜ ê¸°ê´€ì˜ ì´ë¦„ì„ ì›ë¬¸ í‘œê¸° ê·¸ëŒ€ë¡œ ì¶”ì¶œ\"\n",
        "    )\n",
        "    policy: List[str] = Field(\n",
        "        description=\"ë¬¸ì„œì— ì–¸ê¸‰ëœ ì •ì±…ì´ë‚˜ ì œë„ì˜ ì´ë¦„ì„ ì›ë¬¸ í‘œê¸° ê·¸ëŒ€ë¡œ ì¶”ì¶œ\"\n",
        "    )\n",
        "    year: List[int] = Field(\n",
        "        description=\"ë¬¸ì„œ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ëª¨ë“  ì—°ë„ (ë¬¸ì„œì˜ ì‘ì„± ì—°ë„ ë° ë¬¸ì„œì—ì„œ ì–¸ê¸‰í•˜ëŠ” ëª¨ë“  ì¤‘ìš”í•œ ì—°ë„)\"\n",
        "    )\n",
        "\n",
        "llm = init_chat_model(\"openai:gpt-4.1-mini\", temperature=0)\n",
        "\n",
        "# OpenAI Function ì§€ì› ëª¨ë¸ ì‚¬ìš©\n",
        "document_transformer = create_metadata_tagger(DocumentMetadata, llm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2ï¸âƒ£ ì˜ˆì‹œ ë¬¸ì„œì— íƒœê¹… ìˆ˜í–‰\n",
        "RAG ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©í•  ë¬¸ì„œ ì˜ˆì‹œë¥¼ êµ¬ì„±í•˜ê³  ìë™ íƒœê¹…ì„ ì ìš©í•´ë´…ë‹ˆë‹¤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(\"./data/êµ­ê°€ë³„ ê³µê³µë¶€ë¬¸ AI ë„ì… ë° í™œìš© ì „ëµ.pdf\")\n",
        "documents = loader.load()\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splitted_documents = splitter.split_documents(documents)\n",
        "\n",
        "test_documents=splitted_documents[10:15]\n",
        "\n",
        "enhanced_documents = document_transformer.transform_documents(test_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78740c9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "for doc in enhanced_documents:\n",
        "    print(doc.page_content[:100])\n",
        "    print(\"\\nğŸ“Œ Metadata:\", json.dumps(doc.metadata, ensure_ascii=False))\n",
        "    print(\"\\n\" + \"-\" * 50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb1ff79c",
      "metadata": {},
      "source": [
        "#### ğŸ·ï¸ ë©”íƒ€ë°ì´í„° íƒœê¹… ë¹„ë™ê¸° í•¨ìˆ˜ êµ¬í˜„í•˜ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "42927795",
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8cf6a0",
      "metadata": {},
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "import asyncio\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# ë¹„ë™ê¸° ë˜í¼ í•¨ìˆ˜ êµ¬í˜„\n",
        "async def async_transform_document(transformer, doc):\n",
        "    \"\"\"ë‹¨ì¼ ë¬¸ì„œì— ëŒ€í•œ ë¹„ë™ê¸° ë³€í™˜ ë˜í¼\"\"\"\n",
        "    loop = asyncio.get_event_loop()\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        return await loop.run_in_executor(\n",
        "            executor, \n",
        "            lambda: transformer.transform_documents([doc])[0]\n",
        "        )\n",
        "\n",
        "async def process_documents_async(transformer, documents, batch_size=5):\n",
        "    \"\"\"ë¬¸ì„œ ë°°ì¹˜ë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì²˜ë¦¬\"\"\"\n",
        "    results = []\n",
        "    \n",
        "    # ë¬¸ì„œë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°\n",
        "    for i in range(0, len(documents), batch_size):\n",
        "        batch = documents[i:i+batch_size]\n",
        "        \n",
        "        # ê° ë°°ì¹˜ì— ëŒ€í•œ íƒœìŠ¤í¬ ìƒì„±\n",
        "        tasks = [async_transform_document(transformer, doc) for doc in batch]\n",
        "        \n",
        "        # ëª¨ë“  íƒœìŠ¤í¬ ë™ì‹œ ì‹¤í–‰\n",
        "        batch_results = await asyncio.gather(*tasks)\n",
        "        results.extend(batch_results)\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afbad64d",
      "metadata": {},
      "outputs": [],
      "source": [
        "async_results = await process_documents_async(document_transformer, test_documents, batch_size=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce4a2f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "async_results"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rag-guide-1QRpMmrn-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
