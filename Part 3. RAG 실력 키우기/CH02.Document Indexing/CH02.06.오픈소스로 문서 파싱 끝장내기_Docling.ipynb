{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docling 기본 활용법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling은 Layout 분석, 테이블 분석, 텍스트 인식 등 딥러닝 모델을 활용하는 모듈이 많습니다.\n",
    "\n",
    "따라서 GPU가 없는 환경에서 테스트하는 경우, 셀의 실행 시간이 길 수 있습니다.\n",
    "\n",
    "강의에서 진행하는 실습 환경은 RAM: 32GB / GPU: RTX 4060 기준으로 진행되었습니다.\n",
    "\n",
    "테스트가 목적인 경우 Colab에서 실행하시기를 추천드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "source = \"data/국가별 공공부문 AI 도입 및 활용 전략.pdf\"  # document per local path or URL\n",
    "converter = DocumentConverter()\n",
    "result = converter.convert(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling의 Converter 결과물은 markdown, html, doctag(docling의 XML 기반 태그)로 출력할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "# 마크다운 형식으로 문서를 내보내기\n",
    "# export_to_markdown() 메서드는 문서를 마크다운 형식으로 변환하여 반환합니다.\n",
    "display(Markdown(result.document.export_to_markdown()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTML 형식으로 문서를 내보내기\n",
    "# export_to_html() 메서드는 문서를 HTML 형식으로 변환하여 반환합니다.\n",
    "result.document.export_to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doctag 형식으로 문서를 내보내기\n",
    "# export_to_doctag() 메서드는 문서를 doctag 형식으로 변환하여 반환합니다.\n",
    "print(result.document.export_to_doctags())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docling의 Custom pipeline 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON 모듈 가져오기 - 데이터 직렬화 및 역직렬화에 사용\n",
    "import json\n",
    "# 로깅 모듈 가져오기 - 디버깅 및 정보 기록에 사용\n",
    "import logging\n",
    "# 시간 측정 모듈 가져오기 - 실행 시간 측정에 사용\n",
    "import time\n",
    "# 파일 경로 처리 모듈 가져오기 - 파일 및 디렉토리 경로 관리에 사용\n",
    "from pathlib import Path\n",
    "# 로거 인스턴스 생성 - 현재 모듈의 로깅을 위해 사용\n",
    "_log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling은 pipeline option을 통해 문서의 OCR 처리 여부나 Table 구조 인식, 셀 매칭과 같은 작업을 쉽게 수행할 수 있습니다.\n",
    "- OCR은 EasyOCR로 구동됩니다.\n",
    "- Table 구조 인식은 Docling에서 개발한 Tableformer 모델을 통해 구동됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 데이터 모델 가져오기 - 입력 형식 정의에 사용\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "# PDF 파이프라인 옵션 가져오기 - PDF 처리 설정에 사용\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    ")\n",
    "# 문서 변환기 및 PDF 형식 옵션 가져오기 - 문서 변환에 사용\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "# PDF 파이프라인 옵션 설정\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "\n",
    "pipeline_options.do_ocr = False  # OCR 기능 비활성화 (이미 텍스트가 있는 PDF 사용)\n",
    "pipeline_options.ocr_options.lang = [\"ko\"]  # OCR 언어를 한국어로 설정 (OCR 사용 시)\n",
    "\n",
    "pipeline_options.do_table_structure = True  # 표 구조 인식 활성화 --> docling의 tableformer 활용해 표 상세 사항 파악\n",
    "pipeline_options.table_structure_options.do_cell_matching = True  # 표 셀 매칭 활성화\n",
    "\n",
    "# 문서 변환기 생성 및 PDF 형식 옵션 설정\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 문서 경로 설정\n",
    "input_doc_path = \"data/국가별 공공부문 AI 도입 및 활용 전략.pdf\"\n",
    "# 변환 시작 시간 기록\n",
    "start_time = time.time()\n",
    "# 문서 변환 실행\n",
    "conv_result = doc_converter.convert(input_doc_path)\n",
    "# 변환 종료 시간 계산\n",
    "end_time = time.time() - start_time\n",
    "\n",
    "# 변환 완료 시간 로깅\n",
    "_log.info(f\"Document converted in {end_time:.2f} seconds.\")\n",
    "\n",
    "## 결과 내보내기\n",
    "# 출력 디렉토리 설정\n",
    "output_dir = Path(\"scratch\")\n",
    "# 출력 디렉토리가 없으면 생성\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# 파일 이름 추출 (확장자 제외)\n",
    "doc_filename = conv_result.input.file.stem\n",
    "\n",
    "# 문서 JSON 형식으로 내보내기:\n",
    "with (output_dir / f\"{doc_filename}.json\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(json.dumps(conv_result.document.export_to_dict()))\n",
    "\n",
    "# 텍스트 형식으로 내보내기:\n",
    "with (output_dir / f\"{doc_filename}.txt\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(conv_result.document.export_to_text())\n",
    "\n",
    "# 마크다운 형식으로 내보내기:\n",
    "with (output_dir / f\"{doc_filename}.md\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(conv_result.document.export_to_markdown())\n",
    "\n",
    "# doctag 형식으로 내보내기:\n",
    "with (output_dir / f\"{doc_filename}.doctags\").open(\"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.write(conv_result.document.export_to_doctags())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docling의 OCR, 테이블 구조 인식 비교해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`do_table_structure` 파라미터는 Docling의 Tableformer 모델로 표를 더 정확히 인식할지 선택하는 옵션입니다.\n",
    "이를 활용하면, 기존 위치기반 테이블 내 텍스트 추출을 넘어서 테이블 내의 정보를 더 정갈하게 출력할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "def convert_with_table_option(pdf_path, enable_table):\n",
    "    opts = PdfPipelineOptions()\n",
    "    opts.do_ocr = False\n",
    "    opts.do_table_structure = enable_table\n",
    "    opts.table_structure_options.do_cell_matching = True\n",
    "\n",
    "    converter = DocumentConverter(\n",
    "        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=opts)}\n",
    "    )\n",
    "    return converter.convert(pdf_path)\n",
    "\n",
    "# 표 추출 꺼짐\n",
    "res_without_table = convert_with_table_option(input_doc_path, enable_table=False)\n",
    "print(f\"❌ Table disabled: tables found = {len(res_without_table.document.tables)}\")\n",
    "\n",
    "# 표 추출 켜짐\n",
    "res_with_table = convert_with_table_option(input_doc_path, enable_table=True)\n",
    "print(f\"✅ Table enabled: tables found = {len(res_with_table.document.tables)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_with_table.document.pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR 기능을 활용하는 것만이 정답은 아닙니다. 텍스트가 디지털로 인식되는(드래그 가능한) PDF의 경우 OCR을 사용하지 않는 것이 추출에 더 좋습니다.\n",
    "OCR은 스캔된 문서의 경우 유용한 선택지이며, 기본 옵션은 EasyOCR입니다. 언어를 ko로 설정하면 한글 OCR에도 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_with_ocr_option(pdf_path, enable_ocr):\n",
    "    opts = PdfPipelineOptions()\n",
    "    opts.do_ocr = enable_ocr\n",
    "    opts.ocr_options.lang = [\"ko\"]\n",
    "    opts.do_table_structure = False  # 표 관련 영향 없게 끔\n",
    "\n",
    "    converter = DocumentConverter(\n",
    "        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=opts)}\n",
    "    )\n",
    "    return converter.convert(pdf_path)\n",
    "\n",
    "# OCR 꺼짐\n",
    "res_without_ocr = convert_with_ocr_option(input_doc_path, enable_ocr=False)\n",
    "print(f\"❌ OCR disabled: text blocks = {len(res_without_ocr.document.texts)}\")\n",
    "\n",
    "# OCR 켜짐\n",
    "res_with_ocr = convert_with_ocr_option(input_doc_path, enable_ocr=True)\n",
    "print(f\"✅ OCR enabled: text blocks = {len(res_with_ocr.document.texts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCR로 텍스트를 추출한 결과, Text block이 더 많은 이유는 단순히 텍스트를 더 잘게 쪼개서 인식했기 때문입니다.\n",
    "OCR은 텍스트 영역에 대해 텍스트 인식 모델을 구동한 결과를 저장하는 것이기 때문에, 그 영역이 디지털 텍스트로 인식되는 것과 달리 중간에 쪼개질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_ocr_comparison(res_with_ocr, res_without_ocr, num_chars=1000):\n",
    "    text_with_ocr = res_with_ocr.document.export_to_text()\n",
    "    text_without_ocr = res_without_ocr.document.export_to_text()\n",
    "\n",
    "    print(\"=\"*30)\n",
    "    print(\"🟢 WITH OCR:\")\n",
    "    print(\"=\"*30)\n",
    "    print(text_with_ocr[:num_chars])\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"🔴 WITHOUT OCR:\")\n",
    "    print(\"=\"*30)\n",
    "    print(text_without_ocr[:num_chars])\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"=\"*30)\n",
    "    print(\"📊 SUMMARY:\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"- OCR 켠 텍스트 길이: {len(text_with_ocr):,} characters\")\n",
    "    print(f\"- OCR 끈 텍스트 길이: {len(text_without_ocr):,} characters\")\n",
    "    \n",
    "    if len(text_with_ocr) > len(text_without_ocr):\n",
    "        print(\"✅ OCR 결과가 더 많은 텍스트를 추출했음 (아마 스캔 PDF거나 이미지 기반 문서)\")\n",
    "    elif len(text_with_ocr) < len(text_without_ocr):\n",
    "        print(\"⚠️ OCR 결과가 오히려 줄었음... OCR 엔진이 대충 찍었거나 원래 텍스트 레이어가 있었던 듯\")\n",
    "    else:\n",
    "        print(\"🤔 두 결과가 비슷함. OCR 옵션이 큰 영향을 주지 않았을 수도 있음.\")\n",
    "\n",
    "# 예시 호출\n",
    "preview_ocr_comparison(res_with_ocr, res_without_ocr, num_chars=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_text_output(result, name=\"result\"):\n",
    "    text = result.document.export_to_text()\n",
    "    print(f\"\\n📄 {name} text length: {len(text)} characters\")\n",
    "    print(f\"Preview (first 300 chars):\\n{text[:300]!r}\")\n",
    "\n",
    "    lines = text.splitlines()\n",
    "    print(f\"🧱 splitlines() count: {len(lines)}\")\n",
    "    for i, line in enumerate(lines[:100]):\n",
    "        print(f\"  {i:02d}: {line}\")\n",
    "\n",
    "# 실행 예시\n",
    "debug_text_output(res_with_ocr, name=\"OCR ON\")\n",
    "debug_text_output(res_without_ocr, name=\"OCR OFF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스캔 문서 OCR 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_with_ocr_option(pdf_path, enable_ocr):\n",
    "    opts = PdfPipelineOptions()\n",
    "    opts.do_ocr = enable_ocr\n",
    "    opts.ocr_options.lang = [\"ko\"]\n",
    "    opts.do_table_structure = True  # 표 관련 영향 없게 끔\n",
    "    opts.table_structure_options.do_cell_matching = True\n",
    "    \n",
    "    converter = DocumentConverter(\n",
    "        format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=opts)}\n",
    "    )\n",
    "    return converter.convert(pdf_path)\n",
    "\n",
    "# OCR 꺼짐\n",
    "res_without_ocr = convert_with_ocr_option(\"data/은행 확인서.pdf\", enable_ocr=False)\n",
    "print(f\"❌ OCR disabled: text blocks = {len(res_without_ocr.document.texts)}\")\n",
    "\n",
    "# OCR 켜짐\n",
    "res_with_ocr = convert_with_ocr_option(\"data/은행 확인서.pdf\", enable_ocr=True)\n",
    "print(f\"✅ OCR enabled: text blocks = {len(res_with_ocr.document.texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_with_ocr.document.export_to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docling으로 이미지까지 처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling의 picture_description_options 옵션을 활용하면, 페이지에서 추출된 이미지에 대한 캡션과 주석을 생성할 수 있습니다.\n",
    "\n",
    "OpenAI나 Claude와 같이 Vision을 지원하는 API를 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    PictureDescriptionApiOptions,\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "import os\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# OpenAI/ChatGPT Vision API를 사용하는 옵션\n",
    "openai_vlm_options = PictureDescriptionApiOptions(\n",
    "    url=\"https://api.openai.com/v1/chat/completions\",  # 예시 URL\n",
    "    params=dict(\n",
    "        model=\"gpt-4.1\",\n",
    "    ),\n",
    "    headers={\"Authorization\": f\"Bearer {openai_api_key}\"},  # 실제 키로 대체할 것\n",
    "    prompt=\"Describe this image in two sentences. Focus on factual accuracy.\",\n",
    "    timeout=30,\n",
    ")\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_picture_description = True\n",
    "pipeline_options.picture_description_options = openai_vlm_options\n",
    "pipeline_options.images_scale = 2.0\n",
    "pipeline_options.generate_picture_images = True\n",
    "pipeline_options.enable_remote_services=True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "doc = converter.convert(\"data/국가별 공공부문 AI 도입 및 활용 전략.pdf\").document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_core.types.doc import PictureItem\n",
    "\n",
    "for element, _level in doc.iterate_items():\n",
    "    if isinstance(element, PictureItem):\n",
    "        print(\n",
    "            f\"Picture {element.self_ref}\\n\"\n",
    "            f\"Caption: {element.caption_text(doc=doc)}\\n\"\n",
    "            f\"Annotations: {element.annotations}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로컬 모델을 통해 이미지 주석을 생성할 때는 Ollama API를 활용하거나 SmolVLM과 granite-vision을 활용할 수 있습니다.\n",
    "\n",
    "*로컬 실행의 경우 CUDA의 Flash attention이 지원되어야 합니다. 해당 모듈은 윈도우에서 타 라이브러리와의 의존성 문제가 심하여 강의 실습에서는 진행하지 않습니다.\n",
    "\n",
    "*이를 테스트하고자 할 경우, Colab 환경에서 GPU 옵션을 키고 실행하시기를 권장드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    smolvlm_picture_description,\n",
    ")\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "\n",
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HARDLINKS\"] = \"false\"\n",
    "\n",
    "\n",
    "# SmolDocling 설정 복사해서 prompt만 맞춤\n",
    "smol_options = smolvlm_picture_description\n",
    "smol_options.prompt = \"Briefly explain what is shown in this image.\"\n",
    "\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_picture_description = True\n",
    "pipeline_options.picture_description_options = smol_options\n",
    "pipeline_options.images_scale = 2.0\n",
    "pipeline_options.generate_picture_images = True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "doc = converter.convert(\"data/국가별 공공부문 AI 도입 및 활용 전략.pdf\").document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데, 모든 이미지를 VLM으로 처리하면 지연 시간이 너무 길어집니다.\n",
    "\n",
    "따라서, 텍스트가 많이 포함된 정보량이 풍부한 이미지에 대해서만 VLM 추론을 실행하는 것이 효과적입니다.\n",
    "\n",
    "이를 위해, Docling으로 추출한 이미지를 폴더에 저장하고, 해당 폴더 내 여러 이미지 중 OCR 결과 텍스트가 많이 포함된 이미지만 처리할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    PdfPipelineOptions,\n",
    "    )\n",
    "\n",
    "# Configure pipeline options\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.generate_picture_images = True\n",
    "pipeline_options.generate_page_images = True\n",
    "pipeline_options.do_table_structure = True\n",
    "pipeline_options.images_scale = 2.0  # Adjust the scale as needed\n",
    "\n",
    "# Set format options\n",
    "format_options = {\n",
    "    InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "}\n",
    "\n",
    "# Initialize the converter with format options\n",
    "converter = DocumentConverter(\n",
    "    format_options=format_options)\n",
    "\n",
    "# Convert the document\n",
    "result = converter.convert(\"data/국가별 공공부문 AI 도입 및 활용 전략.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docling에서 convert 결과로 내놓는 document에서 pictures 속성에 접근하면 이미지 정보를 볼 수 있습니다.\n",
    "\n",
    "아래 코드는 각 이미지 정보를 순회하면서 이미지를 숫자로 표현한 base64 정보를 추출하고\n",
    "\n",
    "페이지 넘버와 함께 하나의 폴더에 저장하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "output_dir = \"extracted_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "pictures = result.document.pictures\n",
    "\n",
    "for idx, picture in enumerate(pictures):\n",
    "    try:\n",
    "        # Url 객체를 문자열로 변환 후 base64 부분 추출\n",
    "        uri_str = str(picture.image.uri)\n",
    "        base64_data = uri_str.split(',')[1]\n",
    "\n",
    "        # 디코딩 및 PIL 변환\n",
    "        image_data = base64.b64decode(base64_data)\n",
    "        image = Image.open(BytesIO(image_data))\n",
    "\n",
    "        # 페이지 번호 기반 파일 이름\n",
    "        page_no = picture.prov[0].page_no if picture.prov else 0\n",
    "        filename = f\"page_{page_no}_img_{idx+1}.png\"\n",
    "\n",
    "        image.save(os.path.join(output_dir, filename))\n",
    "        print(f\"✅ Saved: {filename}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to save image {idx}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 EasyOCR을 활용해 이미지 속 텍스트의 수를 기준으로 정보량이 풍부한 이미지와 그렇지 않은 이미지를 구분할 수 있습니다.\n",
    "\n",
    "그 이후는 이전 예시와 마찬가지로 VLM 추론을 통해 이미지 캡션을 수행하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import easyocr\n",
    "\n",
    "# EasyOCR reader\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=True)\n",
    "\n",
    "# 이미지 폴더 경로\n",
    "image_folder = \"extracted_images\"\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "rich_images = []   # 정보 풍부\n",
    "poor_images = []   # 정보 부족\n",
    "\n",
    "# 폴더 내 이미지 순회\n",
    "for filename in os.listdir(image_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "\n",
    "        try:\n",
    "            # 이미지 불러오기\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_np = np.array(img)\n",
    "\n",
    "            # OCR 수행\n",
    "            results = reader.readtext(img_np)\n",
    "\n",
    "            texts = [res[1] for res in results]\n",
    "            total_text = ''.join(texts)\n",
    "\n",
    "            # 조건 검사\n",
    "            if len(texts) >= 3 and len(total_text) >= 30:\n",
    "                rich_images.append((filename, len(texts), len(total_text)))\n",
    "            else:\n",
    "                poor_images.append((filename, len(texts), len(total_text)))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류 발생 - {filename}: {e}\")\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n📘 정보량 많은 이미지:\")\n",
    "for name, blocks, chars in rich_images:\n",
    "    print(f\"✔ {name} - 블럭 {blocks}개, 총 글자수 {chars}\")\n",
    "\n",
    "print(\"\\n📄 정보 부족한 이미지:\")\n",
    "for name, blocks, chars in poor_images:\n",
    "    print(f\"✖ {name} - 블럭 {blocks}개, 총 글자수 {chars}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
